{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a dcgan on cifar10\n",
    "from numpy import ones\n",
    "from numpy.random import randint, randn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import sqrtm\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU, Conv2D, Conv2DTranspose, Embedding, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets.cifar10 import load_data\n",
    "\n",
    " \n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(32,32,3), n_classes=10):\n",
    "    # Label input\n",
    "    label_input = Input(shape=(1,))\n",
    "    li = Embedding(n_classes, 50)(label_input)\n",
    "    n_nodes = in_shape[0] * in_shape[1]\n",
    "    li = Dense(n_nodes)(li)\n",
    "    li = Reshape((in_shape[0], in_shape[1], 1))(li)\n",
    "\n",
    "    # Image input\n",
    "    image_input = Input(shape=in_shape)\n",
    "\n",
    "    # Merge inputs\n",
    "    merge = Concatenate()([image_input, li])\n",
    "\n",
    "    # Downsample\n",
    "    fe = Conv2D(64, (3,3), strides=(2,2), padding='same')(merge)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "\n",
    "    # Downsample\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "\n",
    "    # Flatten and output\n",
    "    fe = Flatten()(fe)\n",
    "    fe = Dropout(0.7)(fe)\n",
    "    out_layer = Dense(1, activation='sigmoid')(fe)\n",
    "\n",
    "    # Define model\n",
    "    model = Model([image_input, label_input], out_layer)\n",
    "    return model\n",
    "\n",
    " \n",
    "# define the standalone generator model\n",
    "def define_generator(latent_dim, n_classes=10):\n",
    "    # Label input\n",
    "    label_input = Input(shape=(1,))\n",
    "    li = Embedding(n_classes, 50)(label_input)\n",
    "    n_nodes = 8 * 8\n",
    "    li = Dense(n_nodes)(li)\n",
    "    li = Reshape((8, 8, 1))(li)\n",
    "\n",
    "    # Latent input\n",
    "    latent_input = Input(shape=(latent_dim,))\n",
    "    gen = Dense(256 * 8 * 8)(latent_input)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = Reshape((8, 8, 256))(gen)\n",
    "\n",
    "    # Merge inputs\n",
    "    merge = Concatenate()([gen, li])\n",
    "\n",
    "    # Upsample to 16x16\n",
    "    gen = Conv2DTranspose(256, (4,4), strides=(2,2), padding='same')(merge)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "\n",
    "    # Upsample to 32x32\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "\n",
    "    # Output layer 32x32x3\n",
    "    out_layer = Conv2D(3, (3,3), activation='tanh', padding='same')(gen)\n",
    "\n",
    "    # Define model\n",
    "    model = Model([latent_input, label_input], out_layer)\n",
    "    return model\n",
    "    \n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model):\n",
    "    d_model.trainable = False\n",
    "    gen_noise, gen_label = g_model.input\n",
    "    gen_output = g_model.output\n",
    "    gan_output = d_model([gen_output, gen_label])\n",
    "    model = Model([gen_noise, gen_label], gan_output)\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model\n",
    "    \n",
    "# load and prepare cifar10 training images\n",
    "def load_real_samples():\n",
    "    (trainX, trainy), (_, _) = load_data()\n",
    "    X = trainX.astype('float32')\n",
    "    X = (X - 127.5) / 127.5\n",
    "    return [X, trainy]\n",
    "\n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # Verify that dataset is a list or tuple with two items\n",
    "    if not isinstance(dataset, (list, tuple)) or len(dataset) != 2:\n",
    "        raise ValueError(\"Expected dataset to be a list or tuple of [images, labels]\")\n",
    "\n",
    "    images, labels = dataset\n",
    "    ix = randint(0, images.shape[0], n_samples)\n",
    "    X, labels = images[ix], labels[ix]\n",
    "    y = ones((n_samples, 1))\n",
    "    return [X, labels], y\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples, n_classes=10):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    labels = randint(0, n_classes, n_samples)\n",
    "    images = g_model.predict([z_input, labels])\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return [images, labels], y\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    labels = randint(0, 10, n_samples)\n",
    "    return [z_input, labels]\n",
    "\n",
    "# create and save a plot of generated images\n",
    "def save_plot(examples, epoch, n=7):\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    examples = (examples + 1) / 2.0\n",
    "    # plot images\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(examples[i])\n",
    "        # save plot to file\n",
    "        filename = 'generated_plot_e%03d.png' % (epoch+1)\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "\n",
    "def calculate_fid(dataset, generated_images):\n",
    "    real_images = dataset[0]  # Extracting real images from dataset\n",
    "    generated_images = np.array(generated_images[0]) \n",
    "    # Flatten images to 2D\n",
    "    real_images_2d = real_images.reshape(real_images.shape[0], -1)\n",
    "    generated_images_2d = generated_images.reshape(generated_images.shape[0], -1)\n",
    "\n",
    "    # Calculate the mean and covariance of real and generated images\n",
    "    mu1, sigma1 = real_images_2d.mean(axis=0), np.cov(real_images_2d, rowvar=False)\n",
    "    mu2, sigma2 = generated_images_2d.mean(axis=0), np.cov(generated_images_2d, rowvar=False)\n",
    "\n",
    "    # Calculate the sum of the squared difference of the means\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "\n",
    "    # Calculate sqrt of product of covariances\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    \n",
    "    # Check for imaginary numbers and convert to real\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "\n",
    "    # Calculate FID\n",
    "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid\n",
    "\n",
    "\n",
    "def calculate_precision_recall(dataset, generated_images):\n",
    "    real_images = dataset[0]  # Extracting real images from dataset\n",
    "\n",
    "    # Ensure generated_images is a numpy array\n",
    "    generated_images = np.array(generated_images[0])  # Extracting only images from generated samples\n",
    "\n",
    "    # Ensure the same number of samples in both sets\n",
    "    min_samples = min(real_images.shape[0], generated_images.shape[0])\n",
    "    real_images = real_images[:min_samples]\n",
    "    generated_images = generated_images[:min_samples]\n",
    "\n",
    "    # Flatten images\n",
    "    real_images_2d = real_images.reshape(min_samples, -1)\n",
    "    generated_images_2d = generated_images.reshape(min_samples, -1)\n",
    "\n",
    "    # Binarize images (assuming values are in 0-255 range)\n",
    "    threshold = 128\n",
    "    real_images_binarized = (real_images_2d > threshold).astype(int)\n",
    "    generated_images_binarized = (generated_images_2d > threshold).astype(int)\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision = precision_score(real_images_binarized, generated_images_binarized, average='micro', zero_division=0)\n",
    "    recall = recall_score(real_images_binarized, generated_images_binarized, average='micro', zero_division=0)\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "# evaluate the discriminator, plot generated images, save generator model\n",
    "def summarize_performance(g_model, d_model, dataset, latent_dim, n_samples=100):\n",
    "    # Prepare real samples\n",
    "    [X_real, labels_real], y_real = generate_real_samples(dataset, n_samples)\n",
    "    # Evaluate discriminator on real examples\n",
    "    _, acc_real = d_model.evaluate([X_real, labels_real], y_real, verbose=0)\n",
    "    \n",
    "    # Prepare fake examples\n",
    "    [x_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # Evaluate discriminator on fake examples\n",
    "    _, acc_fake = d_model.evaluate([x_fake, labels_fake], y_fake, verbose=0)\n",
    "    \n",
    "    # Summarize discriminator performance\n",
    "    print(f'>Accuracy | real: {acc_real*100:.0f}%, fake: {acc_fake*100:.0f}%')\n",
    "    return acc_real, acc_fake\n",
    "    \n",
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch):\n",
    "    metrics = {'acc_real': [], 'acc_fake': [], 'd_loss': [], 'g_loss': [], 'fid': [], 'precision': [], 'recall': []}\n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epo):\n",
    "            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
    "            d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
    "            [X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            d_loss2, _ = d_model.train_on_batch([X_fake, labels_fake], y_fake)\n",
    "            [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = np.ones((n_batch, 1))\n",
    "            g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "            print(f'Epoch: {i+1}/{n_epochs}, Batch: {j+1}/{bat_per_epo}, D loss: {d_loss1:.3f}, G loss: {g_loss:.3f}')\n",
    "        # evaluate\n",
    "        if (i+1) % 5 == 0:\n",
    "            acc_real, acc_fake = summarize_performance(g_model, d_model, dataset, latent_dim)\n",
    "            generated_fake_images, _ = generate_fake_samples(g_model, latent_dim, 100)\n",
    "            fid = calculate_fid(dataset, generated_fake_images)\n",
    "            precision, recall = calculate_precision_recall(dataset, generated_fake_images)\n",
    "            metrics['acc_real'].append(acc_real)\n",
    "            metrics['acc_fake'].append(acc_fake)\n",
    "            metrics['d_loss'].append((d_loss1 + d_loss2) / 2)\n",
    "            metrics['g_loss'].append(g_loss)\n",
    "            metrics['fid'].append(fid)\n",
    "            metrics['precision'].append(precision)\n",
    "            metrics['recall'].append(recall)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics, epochs):\n",
    "    # Plotting Loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, metrics['acc_real'], label='Accuracy Real')\n",
    "    plt.plot(epochs, metrics['acc_fake'], label='Accuracy Fake')\n",
    "    plt.title('Discriminator Accuracy During Training')\n",
    "    plt.xlabel('Eval')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, metrics['d_loss'], label='Discriminator Loss')\n",
    "    plt.plot(epochs, metrics['g_loss'], label='Generator Loss')\n",
    "    plt.title('Discriminator and Generator Loss During Training')\n",
    "    plt.xlabel('Eval')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting FID, sFID, Class-aware-FID, and MiFID\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, metrics['fid'], label='FID')\n",
    "    plt.title('FID During Training')\n",
    "    plt.xlabel('Eval')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting PPL, Precision, and Recall\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, metrics['precision'], label='Precision')\n",
    "    plt.plot(epochs, metrics['recall'], label='Recall')\n",
    "    plt.title('Precision and Recall During Training')\n",
    "    plt.xlabel('Eval')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 6ms/step\n",
      "Epoch: 1/200, Batch: 1/390, D loss: 0.704, G loss: 0.692\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 2/390, D loss: 0.669, G loss: 0.684\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 3/390, D loss: 0.620, G loss: 0.673\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 4/390, D loss: 0.583, G loss: 0.661\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 5/390, D loss: 0.519, G loss: 0.645\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 1/200, Batch: 6/390, D loss: 0.492, G loss: 0.642\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 7/390, D loss: 0.456, G loss: 0.647\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 8/390, D loss: 0.419, G loss: 0.668\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 9/390, D loss: 0.388, G loss: 0.686\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 10/390, D loss: 0.368, G loss: 0.705\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 11/390, D loss: 0.357, G loss: 0.696\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 1/200, Batch: 12/390, D loss: 0.315, G loss: 0.697\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 13/390, D loss: 0.294, G loss: 0.693\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 14/390, D loss: 0.267, G loss: 0.682\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 15/390, D loss: 0.264, G loss: 0.644\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 16/390, D loss: 0.272, G loss: 0.557\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 17/390, D loss: 0.286, G loss: 0.541\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 18/390, D loss: 0.291, G loss: 0.631\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 19/390, D loss: 0.330, G loss: 0.752\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 20/390, D loss: 0.362, G loss: 0.893\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 21/390, D loss: 0.400, G loss: 0.933\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 22/390, D loss: 0.463, G loss: 0.915\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 23/390, D loss: 0.504, G loss: 0.864\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 24/390, D loss: 0.539, G loss: 0.774\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 25/390, D loss: 0.461, G loss: 0.737\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 26/390, D loss: 0.574, G loss: 0.717\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 27/390, D loss: 0.557, G loss: 0.717\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 28/390, D loss: 0.475, G loss: 0.737\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 29/390, D loss: 0.476, G loss: 0.714\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 30/390, D loss: 0.473, G loss: 0.630\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 1/200, Batch: 31/390, D loss: 0.461, G loss: 0.582\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 32/390, D loss: 0.483, G loss: 0.609\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 33/390, D loss: 0.355, G loss: 0.665\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 34/390, D loss: 0.425, G loss: 0.824\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 1/200, Batch: 35/390, D loss: 0.417, G loss: 0.938\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 36/390, D loss: 0.402, G loss: 1.055\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 1/200, Batch: 37/390, D loss: 0.416, G loss: 1.023\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 38/390, D loss: 0.424, G loss: 0.992\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 1/200, Batch: 39/390, D loss: 0.417, G loss: 0.952\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 40/390, D loss: 0.417, G loss: 0.922\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 41/390, D loss: 0.434, G loss: 0.898\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 42/390, D loss: 0.475, G loss: 0.870\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 1/200, Batch: 43/390, D loss: 0.447, G loss: 0.857\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 44/390, D loss: 0.451, G loss: 0.850\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 45/390, D loss: 0.378, G loss: 0.806\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 46/390, D loss: 0.404, G loss: 0.750\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 47/390, D loss: 0.455, G loss: 0.726\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 48/390, D loss: 0.481, G loss: 0.794\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 49/390, D loss: 0.477, G loss: 0.904\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 50/390, D loss: 0.527, G loss: 1.072\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 51/390, D loss: 0.617, G loss: 1.153\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 52/390, D loss: 0.675, G loss: 1.133\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 53/390, D loss: 0.732, G loss: 1.041\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 54/390, D loss: 0.683, G loss: 1.014\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 55/390, D loss: 0.660, G loss: 0.984\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 56/390, D loss: 0.689, G loss: 0.922\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 1/200, Batch: 57/390, D loss: 0.608, G loss: 0.891\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 58/390, D loss: 0.577, G loss: 0.857\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 59/390, D loss: 0.605, G loss: 0.838\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 60/390, D loss: 0.608, G loss: 0.839\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 61/390, D loss: 0.534, G loss: 0.851\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 62/390, D loss: 0.456, G loss: 0.883\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 63/390, D loss: 0.476, G loss: 0.905\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 64/390, D loss: 0.425, G loss: 0.913\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 1/200, Batch: 65/390, D loss: 0.422, G loss: 0.889\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 66/390, D loss: 0.434, G loss: 0.847\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 67/390, D loss: 0.324, G loss: 0.757\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 68/390, D loss: 0.329, G loss: 0.680\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 69/390, D loss: 0.358, G loss: 0.637\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 70/390, D loss: 0.387, G loss: 0.703\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 71/390, D loss: 0.387, G loss: 0.826\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 1/200, Batch: 72/390, D loss: 0.396, G loss: 0.984\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 73/390, D loss: 0.356, G loss: 1.143\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 74/390, D loss: 0.442, G loss: 1.238\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 75/390, D loss: 0.424, G loss: 1.193\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 76/390, D loss: 0.396, G loss: 1.136\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 77/390, D loss: 0.453, G loss: 1.069\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 78/390, D loss: 0.418, G loss: 1.064\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 79/390, D loss: 0.484, G loss: 1.084\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 80/390, D loss: 0.364, G loss: 1.071\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 1/200, Batch: 81/390, D loss: 0.451, G loss: 1.068\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 1/200, Batch: 82/390, D loss: 0.527, G loss: 1.062\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 83/390, D loss: 0.275, G loss: 0.994\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 84/390, D loss: 0.212, G loss: 0.925\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 85/390, D loss: 0.330, G loss: 0.803\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 86/390, D loss: 0.302, G loss: 0.680\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 87/390, D loss: 0.229, G loss: 0.591\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 88/390, D loss: 0.275, G loss: 0.538\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 89/390, D loss: 0.230, G loss: 0.541\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 90/390, D loss: 0.301, G loss: 0.568\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 91/390, D loss: 0.317, G loss: 0.649\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 92/390, D loss: 0.378, G loss: 0.748\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 93/390, D loss: 0.452, G loss: 0.827\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 94/390, D loss: 0.535, G loss: 0.877\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 95/390, D loss: 0.565, G loss: 0.988\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 96/390, D loss: 0.649, G loss: 1.047\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 97/390, D loss: 0.686, G loss: 1.055\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 98/390, D loss: 0.686, G loss: 1.072\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 99/390, D loss: 0.604, G loss: 1.105\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 100/390, D loss: 0.602, G loss: 1.096\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 101/390, D loss: 0.506, G loss: 1.061\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 1/200, Batch: 102/390, D loss: 0.516, G loss: 0.995\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 1/200, Batch: 103/390, D loss: 0.550, G loss: 0.938\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 104/390, D loss: 0.523, G loss: 0.892\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 105/390, D loss: 0.418, G loss: 0.893\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 106/390, D loss: 0.397, G loss: 0.901\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 1/200, Batch: 107/390, D loss: 0.454, G loss: 0.922\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 1/200, Batch: 108/390, D loss: 0.480, G loss: 0.938\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 109/390, D loss: 0.315, G loss: 0.995\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 110/390, D loss: 0.368, G loss: 1.101\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 111/390, D loss: 0.340, G loss: 1.188\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 112/390, D loss: 0.285, G loss: 1.286\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 113/390, D loss: 0.242, G loss: 1.359\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 1/200, Batch: 114/390, D loss: 0.283, G loss: 1.366\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 115/390, D loss: 0.240, G loss: 1.255\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 1/200, Batch: 116/390, D loss: 0.212, G loss: 1.109\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 117/390, D loss: 0.208, G loss: 0.933\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 118/390, D loss: 0.171, G loss: 0.803\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 119/390, D loss: 0.219, G loss: 0.847\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 1/200, Batch: 120/390, D loss: 0.199, G loss: 1.070\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 121/390, D loss: 0.346, G loss: 1.280\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 122/390, D loss: 0.434, G loss: 1.353\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 123/390, D loss: 0.583, G loss: 1.391\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 124/390, D loss: 0.573, G loss: 1.438\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 125/390, D loss: 0.563, G loss: 1.400\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 126/390, D loss: 0.498, G loss: 1.322\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 127/390, D loss: 0.547, G loss: 1.259\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 1/200, Batch: 128/390, D loss: 0.544, G loss: 1.177\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 129/390, D loss: 0.497, G loss: 1.152\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 130/390, D loss: 0.408, G loss: 1.110\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 131/390, D loss: 0.295, G loss: 1.036\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 132/390, D loss: 0.313, G loss: 0.909\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 133/390, D loss: 0.372, G loss: 0.858\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 134/390, D loss: 0.377, G loss: 1.057\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 135/390, D loss: 0.501, G loss: 1.408\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 136/390, D loss: 0.636, G loss: 1.731\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 137/390, D loss: 0.865, G loss: 1.701\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 138/390, D loss: 0.897, G loss: 1.551\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 139/390, D loss: 0.898, G loss: 1.337\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 140/390, D loss: 0.958, G loss: 1.355\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 141/390, D loss: 0.868, G loss: 1.404\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 1/200, Batch: 142/390, D loss: 0.804, G loss: 1.470\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 1/200, Batch: 143/390, D loss: 0.666, G loss: 1.358\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 144/390, D loss: 0.594, G loss: 1.374\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 145/390, D loss: 0.683, G loss: 1.281\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 146/390, D loss: 0.538, G loss: 1.296\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 147/390, D loss: 0.587, G loss: 1.308\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 148/390, D loss: 0.405, G loss: 1.337\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 149/390, D loss: 0.436, G loss: 1.350\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 150/390, D loss: 0.417, G loss: 1.353\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 151/390, D loss: 0.462, G loss: 1.314\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 1/200, Batch: 152/390, D loss: 0.407, G loss: 1.323\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 153/390, D loss: 0.501, G loss: 1.302\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 154/390, D loss: 0.526, G loss: 1.315\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 155/390, D loss: 0.483, G loss: 1.282\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 156/390, D loss: 0.447, G loss: 1.334\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 1/200, Batch: 157/390, D loss: 0.475, G loss: 1.270\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 158/390, D loss: 0.358, G loss: 1.282\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 1/200, Batch: 159/390, D loss: 0.347, G loss: 1.360\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 160/390, D loss: 0.614, G loss: 1.277\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 161/390, D loss: 0.477, G loss: 1.223\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 162/390, D loss: 0.382, G loss: 1.238\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 163/390, D loss: 0.501, G loss: 1.199\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 164/390, D loss: 0.250, G loss: 1.214\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 165/390, D loss: 0.353, G loss: 1.249\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 166/390, D loss: 0.363, G loss: 1.203\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 1/200, Batch: 167/390, D loss: 0.476, G loss: 1.132\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 168/390, D loss: 0.248, G loss: 1.148\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 1/200, Batch: 169/390, D loss: 0.288, G loss: 1.115\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 170/390, D loss: 0.345, G loss: 1.072\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 171/390, D loss: 0.307, G loss: 1.015\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 172/390, D loss: 0.308, G loss: 0.954\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 173/390, D loss: 0.308, G loss: 0.873\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 174/390, D loss: 0.275, G loss: 0.774\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 175/390, D loss: 0.183, G loss: 0.657\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 176/390, D loss: 0.181, G loss: 0.537\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 177/390, D loss: 0.163, G loss: 0.419\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 178/390, D loss: 0.227, G loss: 0.281\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 1/200, Batch: 179/390, D loss: 0.221, G loss: 0.234\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 180/390, D loss: 0.274, G loss: 0.334\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 181/390, D loss: 0.259, G loss: 0.871\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 182/390, D loss: 0.344, G loss: 1.726\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 183/390, D loss: 0.444, G loss: 2.155\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 184/390, D loss: 0.464, G loss: 2.182\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 185/390, D loss: 0.627, G loss: 1.841\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 186/390, D loss: 0.421, G loss: 1.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 187/390, D loss: 0.432, G loss: 1.585\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 188/390, D loss: 0.438, G loss: 1.512\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 189/390, D loss: 0.421, G loss: 1.470\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 190/390, D loss: 0.429, G loss: 1.441\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 191/390, D loss: 0.492, G loss: 1.377\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 192/390, D loss: 0.324, G loss: 1.359\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 1/200, Batch: 193/390, D loss: 0.468, G loss: 1.297\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 194/390, D loss: 0.347, G loss: 1.220\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 195/390, D loss: 0.221, G loss: 1.209\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 196/390, D loss: 0.220, G loss: 1.155\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 197/390, D loss: 0.281, G loss: 1.079\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 198/390, D loss: 0.200, G loss: 1.020\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 199/390, D loss: 0.237, G loss: 0.953\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 200/390, D loss: 0.283, G loss: 0.891\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 201/390, D loss: 0.314, G loss: 0.919\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 1/200, Batch: 202/390, D loss: 0.340, G loss: 1.057\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 203/390, D loss: 0.264, G loss: 1.580\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 204/390, D loss: 0.516, G loss: 2.192\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 205/390, D loss: 0.835, G loss: 2.585\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 206/390, D loss: 1.234, G loss: 2.300\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 207/390, D loss: 1.120, G loss: 2.161\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 208/390, D loss: 0.982, G loss: 2.079\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 209/390, D loss: 0.868, G loss: 2.140\n",
      "2/2 [==============================] - 0s 983us/step\n",
      "Epoch: 1/200, Batch: 210/390, D loss: 0.888, G loss: 2.123\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 211/390, D loss: 0.960, G loss: 1.954\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 212/390, D loss: 0.945, G loss: 1.872\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 213/390, D loss: 0.815, G loss: 1.797\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 1/200, Batch: 214/390, D loss: 0.783, G loss: 1.696\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 215/390, D loss: 0.955, G loss: 1.469\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 1/200, Batch: 216/390, D loss: 0.653, G loss: 1.478\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 1/200, Batch: 217/390, D loss: 0.722, G loss: 1.511\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 1/200, Batch: 218/390, D loss: 0.859, G loss: 1.473\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 219/390, D loss: 0.842, G loss: 1.468\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 220/390, D loss: 0.660, G loss: 1.340\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 1/200, Batch: 221/390, D loss: 0.755, G loss: 1.325\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 222/390, D loss: 0.665, G loss: 1.317\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 223/390, D loss: 0.530, G loss: 1.320\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 224/390, D loss: 0.546, G loss: 1.363\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 1/200, Batch: 225/390, D loss: 0.523, G loss: 1.484\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch: 1/200, Batch: 226/390, D loss: 0.426, G loss: 1.409\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 227/390, D loss: 0.382, G loss: 1.441\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 228/390, D loss: 0.319, G loss: 1.815\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 229/390, D loss: 0.477, G loss: 1.982\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 230/390, D loss: 0.476, G loss: 2.231\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 231/390, D loss: 0.539, G loss: 2.339\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 1/200, Batch: 232/390, D loss: 0.638, G loss: 2.528\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 233/390, D loss: 0.802, G loss: 2.288\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 234/390, D loss: 0.751, G loss: 2.062\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 235/390, D loss: 0.803, G loss: 1.824\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 236/390, D loss: 0.713, G loss: 1.694\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 237/390, D loss: 0.648, G loss: 1.683\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 238/390, D loss: 0.557, G loss: 1.711\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 239/390, D loss: 0.695, G loss: 1.593\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 1/200, Batch: 240/390, D loss: 0.557, G loss: 1.590\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 241/390, D loss: 0.664, G loss: 1.634\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 242/390, D loss: 0.549, G loss: 1.617\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 243/390, D loss: 0.576, G loss: 1.575\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 1/200, Batch: 244/390, D loss: 0.399, G loss: 1.557\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 1/200, Batch: 245/390, D loss: 0.518, G loss: 1.543\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 246/390, D loss: 0.540, G loss: 1.479\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 247/390, D loss: 0.309, G loss: 1.478\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 248/390, D loss: 0.279, G loss: 1.507\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 249/390, D loss: 0.285, G loss: 1.525\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 250/390, D loss: 0.253, G loss: 1.537\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 1/200, Batch: 251/390, D loss: 0.206, G loss: 1.546\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 252/390, D loss: 0.388, G loss: 1.522\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 1/200, Batch: 253/390, D loss: 0.264, G loss: 1.492\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 254/390, D loss: 0.237, G loss: 1.534\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 255/390, D loss: 0.274, G loss: 1.482\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 256/390, D loss: 0.269, G loss: 1.474\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 257/390, D loss: 0.314, G loss: 1.436\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 258/390, D loss: 0.244, G loss: 1.363\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 259/390, D loss: 0.232, G loss: 1.360\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 260/390, D loss: 0.179, G loss: 1.285\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 261/390, D loss: 0.248, G loss: 1.173\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 1/200, Batch: 262/390, D loss: 0.317, G loss: 1.023\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 263/390, D loss: 0.282, G loss: 0.935\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 264/390, D loss: 0.277, G loss: 0.827\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 265/390, D loss: 0.357, G loss: 0.706\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 1/200, Batch: 266/390, D loss: 0.441, G loss: 0.597\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 267/390, D loss: 0.285, G loss: 0.610\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 268/390, D loss: 0.314, G loss: 0.762\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 1/200, Batch: 269/390, D loss: 0.436, G loss: 0.978\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 1/200, Batch: 270/390, D loss: 0.634, G loss: 1.260\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 271/390, D loss: 0.697, G loss: 1.378\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 272/390, D loss: 0.887, G loss: 1.512\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 1/200, Batch: 273/390, D loss: 0.812, G loss: 1.715\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 274/390, D loss: 0.927, G loss: 1.501\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 275/390, D loss: 0.930, G loss: 1.502\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 276/390, D loss: 0.986, G loss: 1.368\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 277/390, D loss: 0.960, G loss: 1.378\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 278/390, D loss: 0.984, G loss: 1.296\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 1/200, Batch: 279/390, D loss: 0.939, G loss: 1.164\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 280/390, D loss: 0.951, G loss: 1.097\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 281/390, D loss: 0.832, G loss: 1.113\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 282/390, D loss: 0.766, G loss: 1.110\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 283/390, D loss: 0.870, G loss: 1.156\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 284/390, D loss: 0.832, G loss: 1.055\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 285/390, D loss: 0.766, G loss: 1.135\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 286/390, D loss: 0.664, G loss: 1.174\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 287/390, D loss: 0.823, G loss: 1.037\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 288/390, D loss: 0.971, G loss: 0.984\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 289/390, D loss: 0.860, G loss: 1.006\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 1/200, Batch: 290/390, D loss: 0.778, G loss: 1.033\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 291/390, D loss: 0.893, G loss: 1.054\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 292/390, D loss: 0.824, G loss: 1.059\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 1/200, Batch: 293/390, D loss: 0.890, G loss: 1.059\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 1/200, Batch: 294/390, D loss: 0.887, G loss: 1.024\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 295/390, D loss: 0.863, G loss: 0.949\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 296/390, D loss: 0.914, G loss: 0.995\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 297/390, D loss: 0.933, G loss: 0.956\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 298/390, D loss: 0.934, G loss: 1.077\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 299/390, D loss: 0.899, G loss: 0.996\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 300/390, D loss: 0.973, G loss: 1.032\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 301/390, D loss: 0.950, G loss: 1.007\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 302/390, D loss: 0.998, G loss: 1.060\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 303/390, D loss: 0.975, G loss: 1.054\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 304/390, D loss: 1.011, G loss: 1.023\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 305/390, D loss: 0.949, G loss: 1.014\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 1/200, Batch: 306/390, D loss: 0.908, G loss: 1.059\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 307/390, D loss: 0.914, G loss: 1.098\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 1/200, Batch: 308/390, D loss: 0.968, G loss: 1.077\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 309/390, D loss: 1.024, G loss: 1.110\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 1/200, Batch: 310/390, D loss: 1.025, G loss: 1.091\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 311/390, D loss: 0.959, G loss: 1.085\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 312/390, D loss: 0.942, G loss: 1.059\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 313/390, D loss: 0.885, G loss: 0.976\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 314/390, D loss: 0.909, G loss: 1.085\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 315/390, D loss: 0.928, G loss: 1.089\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 316/390, D loss: 0.921, G loss: 1.072\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 317/390, D loss: 0.994, G loss: 0.984\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 1/200, Batch: 318/390, D loss: 0.989, G loss: 1.055\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 1/200, Batch: 319/390, D loss: 0.964, G loss: 1.036\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 320/390, D loss: 0.892, G loss: 0.941\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 321/390, D loss: 0.946, G loss: 0.999\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 322/390, D loss: 0.865, G loss: 0.913\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 323/390, D loss: 0.873, G loss: 0.990\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 1/200, Batch: 324/390, D loss: 0.907, G loss: 0.924\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 325/390, D loss: 0.880, G loss: 0.931\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 326/390, D loss: 0.896, G loss: 0.951\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 1/200, Batch: 327/390, D loss: 0.831, G loss: 0.917\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 328/390, D loss: 0.774, G loss: 0.965\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 329/390, D loss: 0.809, G loss: 0.970\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 330/390, D loss: 0.857, G loss: 0.872\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 1/200, Batch: 331/390, D loss: 0.775, G loss: 0.965\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 332/390, D loss: 0.766, G loss: 0.894\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 333/390, D loss: 0.806, G loss: 0.901\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 334/390, D loss: 0.829, G loss: 0.920\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 335/390, D loss: 0.830, G loss: 0.889\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 336/390, D loss: 0.874, G loss: 0.938\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 1/200, Batch: 337/390, D loss: 0.827, G loss: 1.006\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 1/200, Batch: 338/390, D loss: 0.801, G loss: 0.956\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 339/390, D loss: 0.765, G loss: 1.018\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 340/390, D loss: 0.816, G loss: 0.985\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 341/390, D loss: 0.834, G loss: 1.101\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 342/390, D loss: 0.780, G loss: 1.063\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 343/390, D loss: 0.856, G loss: 1.072\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 1/200, Batch: 344/390, D loss: 0.872, G loss: 1.003\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 345/390, D loss: 0.830, G loss: 1.112\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 346/390, D loss: 0.791, G loss: 1.051\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 347/390, D loss: 0.770, G loss: 1.102\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 348/390, D loss: 0.782, G loss: 1.087\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 349/390, D loss: 0.805, G loss: 1.051\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 350/390, D loss: 0.705, G loss: 1.008\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 351/390, D loss: 0.812, G loss: 0.975\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 352/390, D loss: 0.831, G loss: 0.974\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 1/200, Batch: 353/390, D loss: 0.762, G loss: 0.856\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 354/390, D loss: 0.794, G loss: 0.874\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 355/390, D loss: 0.796, G loss: 0.834\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 356/390, D loss: 0.777, G loss: 0.826\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 357/390, D loss: 0.726, G loss: 0.832\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 358/390, D loss: 0.773, G loss: 0.843\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 1/200, Batch: 359/390, D loss: 0.742, G loss: 0.862\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 360/390, D loss: 0.771, G loss: 0.834\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 361/390, D loss: 0.815, G loss: 0.886\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 1/200, Batch: 362/390, D loss: 0.793, G loss: 0.924\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 363/390, D loss: 0.794, G loss: 0.910\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 364/390, D loss: 0.771, G loss: 0.916\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 365/390, D loss: 0.703, G loss: 0.920\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 366/390, D loss: 0.734, G loss: 0.932\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 367/390, D loss: 0.741, G loss: 0.931\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Epoch: 1/200, Batch: 368/390, D loss: 0.700, G loss: 0.950\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 369/390, D loss: 0.713, G loss: 0.916\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 370/390, D loss: 0.745, G loss: 0.910\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 371/390, D loss: 0.761, G loss: 0.881\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 372/390, D loss: 0.721, G loss: 0.867\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 373/390, D loss: 0.721, G loss: 0.875\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 1/200, Batch: 374/390, D loss: 0.755, G loss: 0.877\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 375/390, D loss: 0.749, G loss: 0.871\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 376/390, D loss: 0.758, G loss: 0.863\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 1/200, Batch: 377/390, D loss: 0.758, G loss: 0.830\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 378/390, D loss: 0.759, G loss: 0.875\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 379/390, D loss: 0.768, G loss: 0.883\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 1/200, Batch: 380/390, D loss: 0.840, G loss: 0.864\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 381/390, D loss: 0.825, G loss: 0.845\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 382/390, D loss: 0.826, G loss: 0.823\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 383/390, D loss: 0.868, G loss: 0.808\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 1/200, Batch: 384/390, D loss: 0.848, G loss: 0.809\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 1/200, Batch: 385/390, D loss: 0.781, G loss: 0.811\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 1/200, Batch: 386/390, D loss: 0.802, G loss: 0.801\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 387/390, D loss: 0.796, G loss: 0.820\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 1/200, Batch: 388/390, D loss: 0.836, G loss: 0.797\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 1/200, Batch: 389/390, D loss: 0.794, G loss: 0.835\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 1/200, Batch: 390/390, D loss: 0.786, G loss: 0.808\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 1/390, D loss: 0.830, G loss: 0.795\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 2/390, D loss: 0.772, G loss: 0.823\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 3/390, D loss: 0.789, G loss: 0.857\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 2/200, Batch: 4/390, D loss: 0.788, G loss: 0.846\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 5/390, D loss: 0.801, G loss: 0.824\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 6/390, D loss: 0.682, G loss: 0.879\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 7/390, D loss: 0.743, G loss: 0.845\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 2/200, Batch: 8/390, D loss: 0.689, G loss: 0.874\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 2/200, Batch: 9/390, D loss: 0.680, G loss: 0.836\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 10/390, D loss: 0.737, G loss: 0.791\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 2/200, Batch: 11/390, D loss: 0.707, G loss: 0.859\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 2/200, Batch: 12/390, D loss: 0.717, G loss: 0.826\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 13/390, D loss: 0.700, G loss: 0.811\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 14/390, D loss: 0.692, G loss: 0.817\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 15/390, D loss: 0.729, G loss: 0.805\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 16/390, D loss: 0.721, G loss: 0.789\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 17/390, D loss: 0.736, G loss: 0.762\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 18/390, D loss: 0.715, G loss: 0.758\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 19/390, D loss: 0.716, G loss: 0.747\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 2/200, Batch: 20/390, D loss: 0.737, G loss: 0.771\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 21/390, D loss: 0.769, G loss: 0.776\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 22/390, D loss: 0.793, G loss: 0.788\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 23/390, D loss: 0.741, G loss: 0.784\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 24/390, D loss: 0.787, G loss: 0.777\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 2/200, Batch: 25/390, D loss: 0.782, G loss: 0.793\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 26/390, D loss: 0.816, G loss: 0.816\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 27/390, D loss: 0.815, G loss: 0.788\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 28/390, D loss: 0.836, G loss: 0.802\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 29/390, D loss: 0.838, G loss: 0.806\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 30/390, D loss: 0.849, G loss: 0.832\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 2/200, Batch: 31/390, D loss: 0.830, G loss: 0.864\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 32/390, D loss: 0.800, G loss: 0.855\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 33/390, D loss: 0.840, G loss: 0.857\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 34/390, D loss: 0.779, G loss: 0.828\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 35/390, D loss: 0.794, G loss: 0.878\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 36/390, D loss: 0.815, G loss: 0.882\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 37/390, D loss: 0.802, G loss: 0.851\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 38/390, D loss: 0.734, G loss: 0.790\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 39/390, D loss: 0.765, G loss: 0.818\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 40/390, D loss: 0.764, G loss: 0.838\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 41/390, D loss: 0.790, G loss: 0.761\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 42/390, D loss: 0.800, G loss: 0.771\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 43/390, D loss: 0.834, G loss: 0.753\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 44/390, D loss: 0.778, G loss: 0.739\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 45/390, D loss: 0.808, G loss: 0.769\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 46/390, D loss: 0.773, G loss: 0.798\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 47/390, D loss: 0.779, G loss: 0.773\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 48/390, D loss: 0.862, G loss: 0.784\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 49/390, D loss: 0.804, G loss: 0.798\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 50/390, D loss: 0.789, G loss: 0.797\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 51/390, D loss: 0.814, G loss: 0.794\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 52/390, D loss: 0.802, G loss: 0.827\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 53/390, D loss: 0.823, G loss: 0.830\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 54/390, D loss: 0.808, G loss: 0.828\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 55/390, D loss: 0.797, G loss: 0.856\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 56/390, D loss: 0.799, G loss: 0.864\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 57/390, D loss: 0.785, G loss: 0.869\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 58/390, D loss: 0.798, G loss: 0.877\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 59/390, D loss: 0.784, G loss: 0.844\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 60/390, D loss: 0.771, G loss: 0.824\n",
      "2/2 [==============================] - 0s 19ms/step\n",
      "Epoch: 2/200, Batch: 61/390, D loss: 0.793, G loss: 0.821\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch: 2/200, Batch: 62/390, D loss: 0.783, G loss: 0.830\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 2/200, Batch: 63/390, D loss: 0.792, G loss: 0.816\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 64/390, D loss: 0.746, G loss: 0.795\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 65/390, D loss: 0.806, G loss: 0.799\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 2/200, Batch: 66/390, D loss: 0.769, G loss: 0.760\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 67/390, D loss: 0.776, G loss: 0.800\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 68/390, D loss: 0.800, G loss: 0.818\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 69/390, D loss: 0.791, G loss: 0.779\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 70/390, D loss: 0.785, G loss: 0.783\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 71/390, D loss: 0.826, G loss: 0.758\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 72/390, D loss: 0.795, G loss: 0.790\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 73/390, D loss: 0.813, G loss: 0.790\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 74/390, D loss: 0.836, G loss: 0.801\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 75/390, D loss: 0.834, G loss: 0.797\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 76/390, D loss: 0.831, G loss: 0.759\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 2/200, Batch: 77/390, D loss: 0.791, G loss: 0.751\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 78/390, D loss: 0.780, G loss: 0.774\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 79/390, D loss: 0.819, G loss: 0.742\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 80/390, D loss: 0.835, G loss: 0.740\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 81/390, D loss: 0.784, G loss: 0.769\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 2/200, Batch: 82/390, D loss: 0.831, G loss: 0.735\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 83/390, D loss: 0.789, G loss: 0.742\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 84/390, D loss: 0.750, G loss: 0.766\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 85/390, D loss: 0.743, G loss: 0.754\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 86/390, D loss: 0.734, G loss: 0.740\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 87/390, D loss: 0.779, G loss: 0.742\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 88/390, D loss: 0.745, G loss: 0.801\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 89/390, D loss: 0.748, G loss: 0.782\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 90/390, D loss: 0.771, G loss: 0.764\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 91/390, D loss: 0.746, G loss: 0.791\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 92/390, D loss: 0.755, G loss: 0.777\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 93/390, D loss: 0.775, G loss: 0.783\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 94/390, D loss: 0.749, G loss: 0.792\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 95/390, D loss: 0.734, G loss: 0.800\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 2/200, Batch: 96/390, D loss: 0.781, G loss: 0.829\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 2/200, Batch: 97/390, D loss: 0.778, G loss: 0.791\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 98/390, D loss: 0.768, G loss: 0.796\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 99/390, D loss: 0.775, G loss: 0.804\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 100/390, D loss: 0.812, G loss: 0.818\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 101/390, D loss: 0.792, G loss: 0.831\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 102/390, D loss: 0.804, G loss: 0.842\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 103/390, D loss: 0.839, G loss: 0.831\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 104/390, D loss: 0.868, G loss: 0.831\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Epoch: 2/200, Batch: 105/390, D loss: 0.864, G loss: 0.844\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 106/390, D loss: 0.850, G loss: 0.831\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 2/200, Batch: 107/390, D loss: 0.829, G loss: 0.859\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 108/390, D loss: 0.810, G loss: 0.840\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 109/390, D loss: 0.799, G loss: 0.827\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 2/200, Batch: 110/390, D loss: 0.883, G loss: 0.831\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 111/390, D loss: 0.853, G loss: 0.832\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 112/390, D loss: 0.815, G loss: 0.824\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 113/390, D loss: 0.847, G loss: 0.841\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 114/390, D loss: 0.843, G loss: 0.816\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 2/200, Batch: 115/390, D loss: 0.856, G loss: 0.833\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 116/390, D loss: 0.801, G loss: 0.817\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 117/390, D loss: 0.729, G loss: 0.813\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 118/390, D loss: 0.804, G loss: 0.809\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 119/390, D loss: 0.820, G loss: 0.821\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 120/390, D loss: 0.785, G loss: 0.805\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 121/390, D loss: 0.766, G loss: 0.821\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 122/390, D loss: 0.790, G loss: 0.797\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 123/390, D loss: 0.785, G loss: 0.800\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 124/390, D loss: 0.802, G loss: 0.789\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 2/200, Batch: 125/390, D loss: 0.745, G loss: 0.833\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 126/390, D loss: 0.713, G loss: 0.779\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 127/390, D loss: 0.787, G loss: 0.744\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 2/200, Batch: 128/390, D loss: 0.794, G loss: 0.742\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 129/390, D loss: 0.747, G loss: 0.746\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 130/390, D loss: 0.770, G loss: 0.680\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 2/200, Batch: 131/390, D loss: 0.856, G loss: 0.722\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 2/200, Batch: 132/390, D loss: 0.751, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 133/390, D loss: 0.725, G loss: 0.710\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 134/390, D loss: 0.744, G loss: 0.712\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 135/390, D loss: 0.771, G loss: 0.728\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 136/390, D loss: 0.756, G loss: 0.738\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 137/390, D loss: 0.741, G loss: 0.765\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 138/390, D loss: 0.735, G loss: 0.756\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 139/390, D loss: 0.752, G loss: 0.772\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 140/390, D loss: 0.777, G loss: 0.775\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 141/390, D loss: 0.728, G loss: 0.801\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 142/390, D loss: 0.757, G loss: 0.817\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 143/390, D loss: 0.718, G loss: 0.809\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 144/390, D loss: 0.730, G loss: 0.821\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 2/200, Batch: 145/390, D loss: 0.717, G loss: 0.830\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 146/390, D loss: 0.742, G loss: 0.807\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 147/390, D loss: 0.741, G loss: 0.790\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 2/200, Batch: 148/390, D loss: 0.714, G loss: 0.790\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 149/390, D loss: 0.695, G loss: 0.754\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 2/200, Batch: 150/390, D loss: 0.699, G loss: 0.764\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 2/200, Batch: 151/390, D loss: 0.659, G loss: 0.723\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 152/390, D loss: 0.731, G loss: 0.711\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 153/390, D loss: 0.690, G loss: 0.671\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 154/390, D loss: 0.712, G loss: 0.657\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 155/390, D loss: 0.690, G loss: 0.645\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 156/390, D loss: 0.702, G loss: 0.642\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 157/390, D loss: 0.707, G loss: 0.646\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 158/390, D loss: 0.712, G loss: 0.650\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 159/390, D loss: 0.741, G loss: 0.664\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 160/390, D loss: 0.754, G loss: 0.645\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 161/390, D loss: 0.752, G loss: 0.679\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 162/390, D loss: 0.759, G loss: 0.712\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 163/390, D loss: 0.747, G loss: 0.722\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 164/390, D loss: 0.782, G loss: 0.738\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 165/390, D loss: 0.746, G loss: 0.751\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 166/390, D loss: 0.765, G loss: 0.808\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 167/390, D loss: 0.747, G loss: 0.832\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 168/390, D loss: 0.754, G loss: 0.830\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 169/390, D loss: 0.752, G loss: 0.829\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 170/390, D loss: 0.729, G loss: 0.843\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 171/390, D loss: 0.758, G loss: 0.857\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 2/200, Batch: 172/390, D loss: 0.728, G loss: 0.867\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 173/390, D loss: 0.771, G loss: 0.844\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 174/390, D loss: 0.731, G loss: 0.851\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 175/390, D loss: 0.742, G loss: 0.831\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 176/390, D loss: 0.721, G loss: 0.788\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 177/390, D loss: 0.714, G loss: 0.793\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 178/390, D loss: 0.688, G loss: 0.747\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 179/390, D loss: 0.692, G loss: 0.722\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 180/390, D loss: 0.687, G loss: 0.675\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 181/390, D loss: 0.737, G loss: 0.672\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 182/390, D loss: 0.702, G loss: 0.671\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 183/390, D loss: 0.687, G loss: 0.633\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 184/390, D loss: 0.707, G loss: 0.607\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 185/390, D loss: 0.747, G loss: 0.614\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 186/390, D loss: 0.733, G loss: 0.591\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 187/390, D loss: 0.741, G loss: 0.607\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 188/390, D loss: 0.725, G loss: 0.624\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 189/390, D loss: 0.701, G loss: 0.624\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 190/390, D loss: 0.736, G loss: 0.658\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 191/390, D loss: 0.727, G loss: 0.667\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 192/390, D loss: 0.731, G loss: 0.680\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 193/390, D loss: 0.716, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 194/390, D loss: 0.729, G loss: 0.733\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 195/390, D loss: 0.750, G loss: 0.755\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 196/390, D loss: 0.713, G loss: 0.792\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 197/390, D loss: 0.706, G loss: 0.789\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 2/200, Batch: 198/390, D loss: 0.708, G loss: 0.802\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 199/390, D loss: 0.684, G loss: 0.809\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 200/390, D loss: 0.702, G loss: 0.779\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 2/200, Batch: 201/390, D loss: 0.680, G loss: 0.797\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 202/390, D loss: 0.712, G loss: 0.759\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 203/390, D loss: 0.664, G loss: 0.741\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 204/390, D loss: 0.667, G loss: 0.728\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 205/390, D loss: 0.674, G loss: 0.708\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 206/390, D loss: 0.694, G loss: 0.685\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 207/390, D loss: 0.673, G loss: 0.684\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 208/390, D loss: 0.671, G loss: 0.648\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 209/390, D loss: 0.698, G loss: 0.674\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 210/390, D loss: 0.703, G loss: 0.649\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 211/390, D loss: 0.676, G loss: 0.662\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 212/390, D loss: 0.694, G loss: 0.656\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 2/200, Batch: 213/390, D loss: 0.714, G loss: 0.666\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 214/390, D loss: 0.723, G loss: 0.655\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 215/390, D loss: 0.705, G loss: 0.666\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 216/390, D loss: 0.682, G loss: 0.662\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 2/200, Batch: 217/390, D loss: 0.714, G loss: 0.660\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 218/390, D loss: 0.732, G loss: 0.680\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 219/390, D loss: 0.770, G loss: 0.705\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 220/390, D loss: 0.753, G loss: 0.727\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 2/200, Batch: 221/390, D loss: 0.775, G loss: 0.713\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 222/390, D loss: 0.753, G loss: 0.735\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 223/390, D loss: 0.770, G loss: 0.755\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 224/390, D loss: 0.787, G loss: 0.784\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 225/390, D loss: 0.781, G loss: 0.802\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 226/390, D loss: 0.807, G loss: 0.782\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 227/390, D loss: 0.772, G loss: 0.818\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 228/390, D loss: 0.786, G loss: 0.797\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 229/390, D loss: 0.767, G loss: 0.805\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 2/200, Batch: 230/390, D loss: 0.764, G loss: 0.815\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 231/390, D loss: 0.799, G loss: 0.806\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 232/390, D loss: 0.767, G loss: 0.818\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 233/390, D loss: 0.772, G loss: 0.823\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 234/390, D loss: 0.770, G loss: 0.800\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 235/390, D loss: 0.753, G loss: 0.810\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 236/390, D loss: 0.778, G loss: 0.795\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 237/390, D loss: 0.749, G loss: 0.788\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 238/390, D loss: 0.763, G loss: 0.791\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 239/390, D loss: 0.777, G loss: 0.773\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 240/390, D loss: 0.748, G loss: 0.763\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 241/390, D loss: 0.812, G loss: 0.776\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 242/390, D loss: 0.795, G loss: 0.739\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 243/390, D loss: 0.765, G loss: 0.737\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 244/390, D loss: 0.761, G loss: 0.720\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 245/390, D loss: 0.771, G loss: 0.734\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 246/390, D loss: 0.778, G loss: 0.705\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 247/390, D loss: 0.734, G loss: 0.707\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 248/390, D loss: 0.736, G loss: 0.701\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 249/390, D loss: 0.751, G loss: 0.696\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 250/390, D loss: 0.738, G loss: 0.690\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 251/390, D loss: 0.760, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 252/390, D loss: 0.753, G loss: 0.687\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 253/390, D loss: 0.741, G loss: 0.695\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 2/200, Batch: 254/390, D loss: 0.737, G loss: 0.719\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 255/390, D loss: 0.750, G loss: 0.716\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 256/390, D loss: 0.738, G loss: 0.734\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 257/390, D loss: 0.754, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 258/390, D loss: 0.739, G loss: 0.742\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 259/390, D loss: 0.728, G loss: 0.742\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 2/200, Batch: 260/390, D loss: 0.743, G loss: 0.756\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 261/390, D loss: 0.728, G loss: 0.743\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 2/200, Batch: 262/390, D loss: 0.713, G loss: 0.758\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 263/390, D loss: 0.707, G loss: 0.751\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 264/390, D loss: 0.713, G loss: 0.735\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 265/390, D loss: 0.699, G loss: 0.723\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 266/390, D loss: 0.685, G loss: 0.723\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 267/390, D loss: 0.674, G loss: 0.717\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 268/390, D loss: 0.678, G loss: 0.720\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 269/390, D loss: 0.663, G loss: 0.698\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 270/390, D loss: 0.699, G loss: 0.689\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 271/390, D loss: 0.697, G loss: 0.662\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 272/390, D loss: 0.679, G loss: 0.668\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 2/200, Batch: 273/390, D loss: 0.698, G loss: 0.651\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 274/390, D loss: 0.705, G loss: 0.666\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 275/390, D loss: 0.678, G loss: 0.655\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 276/390, D loss: 0.684, G loss: 0.630\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch: 2/200, Batch: 277/390, D loss: 0.678, G loss: 0.646\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 278/390, D loss: 0.684, G loss: 0.648\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 279/390, D loss: 0.693, G loss: 0.659\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 280/390, D loss: 0.713, G loss: 0.652\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 281/390, D loss: 0.682, G loss: 0.667\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 2/200, Batch: 282/390, D loss: 0.687, G loss: 0.664\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 283/390, D loss: 0.710, G loss: 0.674\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 284/390, D loss: 0.715, G loss: 0.684\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 285/390, D loss: 0.712, G loss: 0.691\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 286/390, D loss: 0.712, G loss: 0.710\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 287/390, D loss: 0.722, G loss: 0.728\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 288/390, D loss: 0.715, G loss: 0.727\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 289/390, D loss: 0.714, G loss: 0.742\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 290/390, D loss: 0.731, G loss: 0.756\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 291/390, D loss: 0.716, G loss: 0.774\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 292/390, D loss: 0.709, G loss: 0.785\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 293/390, D loss: 0.723, G loss: 0.788\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 2/200, Batch: 294/390, D loss: 0.732, G loss: 0.772\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 295/390, D loss: 0.710, G loss: 0.785\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 296/390, D loss: 0.719, G loss: 0.763\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 297/390, D loss: 0.743, G loss: 0.781\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 298/390, D loss: 0.737, G loss: 0.748\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 299/390, D loss: 0.736, G loss: 0.737\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 300/390, D loss: 0.749, G loss: 0.736\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 301/390, D loss: 0.756, G loss: 0.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 302/390, D loss: 0.722, G loss: 0.688\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 2/200, Batch: 303/390, D loss: 0.727, G loss: 0.681\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 304/390, D loss: 0.720, G loss: 0.673\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 305/390, D loss: 0.735, G loss: 0.684\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 306/390, D loss: 0.723, G loss: 0.670\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 307/390, D loss: 0.730, G loss: 0.679\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 308/390, D loss: 0.699, G loss: 0.668\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 309/390, D loss: 0.723, G loss: 0.682\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 310/390, D loss: 0.748, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 311/390, D loss: 0.716, G loss: 0.696\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 312/390, D loss: 0.756, G loss: 0.714\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 313/390, D loss: 0.747, G loss: 0.726\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 314/390, D loss: 0.723, G loss: 0.751\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 315/390, D loss: 0.735, G loss: 0.772\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 316/390, D loss: 0.738, G loss: 0.775\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 317/390, D loss: 0.732, G loss: 0.775\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 2/200, Batch: 318/390, D loss: 0.708, G loss: 0.800\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 319/390, D loss: 0.777, G loss: 0.781\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 320/390, D loss: 0.725, G loss: 0.783\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 321/390, D loss: 0.739, G loss: 0.771\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 322/390, D loss: 0.715, G loss: 0.750\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 323/390, D loss: 0.707, G loss: 0.750\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 2/200, Batch: 324/390, D loss: 0.710, G loss: 0.726\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 325/390, D loss: 0.694, G loss: 0.707\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 326/390, D loss: 0.693, G loss: 0.686\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 327/390, D loss: 0.716, G loss: 0.678\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 328/390, D loss: 0.686, G loss: 0.661\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 329/390, D loss: 0.687, G loss: 0.652\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 2/200, Batch: 330/390, D loss: 0.687, G loss: 0.645\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 331/390, D loss: 0.688, G loss: 0.629\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 2/200, Batch: 332/390, D loss: 0.688, G loss: 0.650\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 2/200, Batch: 333/390, D loss: 0.688, G loss: 0.626\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 334/390, D loss: 0.697, G loss: 0.648\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 335/390, D loss: 0.692, G loss: 0.642\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 336/390, D loss: 0.699, G loss: 0.646\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 337/390, D loss: 0.680, G loss: 0.675\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 338/390, D loss: 0.687, G loss: 0.684\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 339/390, D loss: 0.669, G loss: 0.723\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 340/390, D loss: 0.716, G loss: 0.735\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 341/390, D loss: 0.713, G loss: 0.747\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 2/200, Batch: 342/390, D loss: 0.699, G loss: 0.772\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 343/390, D loss: 0.690, G loss: 0.779\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 344/390, D loss: 0.698, G loss: 0.780\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 345/390, D loss: 0.700, G loss: 0.754\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 346/390, D loss: 0.687, G loss: 0.743\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 347/390, D loss: 0.691, G loss: 0.730\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 348/390, D loss: 0.667, G loss: 0.715\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 349/390, D loss: 0.718, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 350/390, D loss: 0.692, G loss: 0.672\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 351/390, D loss: 0.673, G loss: 0.673\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 352/390, D loss: 0.697, G loss: 0.662\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 353/390, D loss: 0.728, G loss: 0.667\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 354/390, D loss: 0.696, G loss: 0.669\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 355/390, D loss: 0.674, G loss: 0.674\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 356/390, D loss: 0.687, G loss: 0.674\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 357/390, D loss: 0.704, G loss: 0.700\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 358/390, D loss: 0.717, G loss: 0.696\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 359/390, D loss: 0.708, G loss: 0.701\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 360/390, D loss: 0.725, G loss: 0.692\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 361/390, D loss: 0.696, G loss: 0.721\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 362/390, D loss: 0.719, G loss: 0.713\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch: 2/200, Batch: 363/390, D loss: 0.748, G loss: 0.720\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 364/390, D loss: 0.708, G loss: 0.747\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 2/200, Batch: 365/390, D loss: 0.717, G loss: 0.733\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 2/200, Batch: 366/390, D loss: 0.714, G loss: 0.746\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 367/390, D loss: 0.742, G loss: 0.762\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 368/390, D loss: 0.764, G loss: 0.727\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 369/390, D loss: 0.742, G loss: 0.745\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 370/390, D loss: 0.744, G loss: 0.741\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 371/390, D loss: 0.742, G loss: 0.744\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 372/390, D loss: 0.773, G loss: 0.740\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 373/390, D loss: 0.752, G loss: 0.739\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 374/390, D loss: 0.786, G loss: 0.754\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 2/200, Batch: 375/390, D loss: 0.767, G loss: 0.768\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 376/390, D loss: 0.768, G loss: 0.763\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 377/390, D loss: 0.766, G loss: 0.755\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 2/200, Batch: 378/390, D loss: 0.777, G loss: 0.774\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 379/390, D loss: 0.777, G loss: 0.767\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 380/390, D loss: 0.758, G loss: 0.769\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 381/390, D loss: 0.741, G loss: 0.788\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 2/200, Batch: 382/390, D loss: 0.743, G loss: 0.785\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 2/200, Batch: 383/390, D loss: 0.754, G loss: 0.787\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 384/390, D loss: 0.736, G loss: 0.796\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 385/390, D loss: 0.781, G loss: 0.789\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 2/200, Batch: 386/390, D loss: 0.781, G loss: 0.770\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 2/200, Batch: 387/390, D loss: 0.752, G loss: 0.770\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 388/390, D loss: 0.745, G loss: 0.747\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 2/200, Batch: 389/390, D loss: 0.737, G loss: 0.756\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 2/200, Batch: 390/390, D loss: 0.770, G loss: 0.736\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 1/390, D loss: 0.734, G loss: 0.721\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 2/390, D loss: 0.743, G loss: 0.716\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 3/200, Batch: 3/390, D loss: 0.734, G loss: 0.709\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 3/200, Batch: 4/390, D loss: 0.711, G loss: 0.709\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 5/390, D loss: 0.732, G loss: 0.699\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 3/200, Batch: 6/390, D loss: 0.712, G loss: 0.697\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 7/390, D loss: 0.704, G loss: 0.700\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 8/390, D loss: 0.728, G loss: 0.696\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 9/390, D loss: 0.685, G loss: 0.702\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 3/200, Batch: 10/390, D loss: 0.712, G loss: 0.706\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 11/390, D loss: 0.689, G loss: 0.706\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 12/390, D loss: 0.688, G loss: 0.725\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch: 3/200, Batch: 13/390, D loss: 0.688, G loss: 0.728\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 14/390, D loss: 0.694, G loss: 0.717\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 3/200, Batch: 15/390, D loss: 0.680, G loss: 0.716\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 16/390, D loss: 0.700, G loss: 0.706\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 17/390, D loss: 0.696, G loss: 0.699\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 18/390, D loss: 0.705, G loss: 0.705\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 19/390, D loss: 0.695, G loss: 0.687\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 20/390, D loss: 0.699, G loss: 0.671\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 21/390, D loss: 0.683, G loss: 0.668\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 22/390, D loss: 0.694, G loss: 0.657\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 23/390, D loss: 0.673, G loss: 0.646\n",
      "2/2 [==============================] - 0s 21ms/step\n",
      "Epoch: 3/200, Batch: 24/390, D loss: 0.684, G loss: 0.653\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 25/390, D loss: 0.673, G loss: 0.648\n",
      "2/2 [==============================] - 0s 482us/step\n",
      "Epoch: 3/200, Batch: 26/390, D loss: 0.681, G loss: 0.663\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 27/390, D loss: 0.667, G loss: 0.667\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 28/390, D loss: 0.671, G loss: 0.669\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 29/390, D loss: 0.664, G loss: 0.679\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 30/390, D loss: 0.699, G loss: 0.669\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 31/390, D loss: 0.685, G loss: 0.683\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 32/390, D loss: 0.670, G loss: 0.692\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 33/390, D loss: 0.669, G loss: 0.689\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 34/390, D loss: 0.684, G loss: 0.705\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 35/390, D loss: 0.680, G loss: 0.701\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 36/390, D loss: 0.676, G loss: 0.719\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 37/390, D loss: 0.682, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 38/390, D loss: 0.682, G loss: 0.710\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 39/390, D loss: 0.674, G loss: 0.717\n",
      "2/2 [==============================] - 0s 557us/step\n",
      "Epoch: 3/200, Batch: 40/390, D loss: 0.673, G loss: 0.710\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 3/200, Batch: 41/390, D loss: 0.649, G loss: 0.716\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 42/390, D loss: 0.673, G loss: 0.729\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 43/390, D loss: 0.673, G loss: 0.707\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 44/390, D loss: 0.685, G loss: 0.726\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 45/390, D loss: 0.670, G loss: 0.719\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 46/390, D loss: 0.715, G loss: 0.706\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 47/390, D loss: 0.682, G loss: 0.708\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 48/390, D loss: 0.674, G loss: 0.712\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 49/390, D loss: 0.634, G loss: 0.708\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 50/390, D loss: 0.658, G loss: 0.716\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 3/200, Batch: 51/390, D loss: 0.692, G loss: 0.711\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 52/390, D loss: 0.698, G loss: 0.707\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 53/390, D loss: 0.687, G loss: 0.712\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 3/200, Batch: 54/390, D loss: 0.707, G loss: 0.685\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 55/390, D loss: 0.674, G loss: 0.704\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 56/390, D loss: 0.683, G loss: 0.694\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 57/390, D loss: 0.704, G loss: 0.696\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 58/390, D loss: 0.704, G loss: 0.696\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 59/390, D loss: 0.712, G loss: 0.689\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 60/390, D loss: 0.690, G loss: 0.690\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 61/390, D loss: 0.689, G loss: 0.702\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 62/390, D loss: 0.694, G loss: 0.712\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 63/390, D loss: 0.713, G loss: 0.719\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 64/390, D loss: 0.691, G loss: 0.707\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 65/390, D loss: 0.695, G loss: 0.729\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 66/390, D loss: 0.703, G loss: 0.738\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 67/390, D loss: 0.677, G loss: 0.727\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 68/390, D loss: 0.707, G loss: 0.724\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 3/200, Batch: 69/390, D loss: 0.708, G loss: 0.721\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 70/390, D loss: 0.717, G loss: 0.716\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 71/390, D loss: 0.718, G loss: 0.707\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 72/390, D loss: 0.708, G loss: 0.695\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 73/390, D loss: 0.719, G loss: 0.682\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 74/390, D loss: 0.723, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 75/390, D loss: 0.719, G loss: 0.712\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 76/390, D loss: 0.696, G loss: 0.716\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 77/390, D loss: 0.731, G loss: 0.716\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 78/390, D loss: 0.695, G loss: 0.743\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 79/390, D loss: 0.734, G loss: 0.752\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 80/390, D loss: 0.724, G loss: 0.777\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 81/390, D loss: 0.741, G loss: 0.776\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 3/200, Batch: 82/390, D loss: 0.742, G loss: 0.765\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 83/390, D loss: 0.726, G loss: 0.793\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 84/390, D loss: 0.734, G loss: 0.790\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 85/390, D loss: 0.755, G loss: 0.792\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 86/390, D loss: 0.748, G loss: 0.781\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 87/390, D loss: 0.742, G loss: 0.776\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 88/390, D loss: 0.764, G loss: 0.758\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 3/200, Batch: 89/390, D loss: 0.736, G loss: 0.769\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 90/390, D loss: 0.719, G loss: 0.760\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 91/390, D loss: 0.714, G loss: 0.767\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 92/390, D loss: 0.724, G loss: 0.748\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 93/390, D loss: 0.748, G loss: 0.734\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 94/390, D loss: 0.710, G loss: 0.744\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 95/390, D loss: 0.772, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 96/390, D loss: 0.741, G loss: 0.712\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 97/390, D loss: 0.725, G loss: 0.698\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 98/390, D loss: 0.696, G loss: 0.696\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 99/390, D loss: 0.699, G loss: 0.695\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 100/390, D loss: 0.731, G loss: 0.694\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 101/390, D loss: 0.726, G loss: 0.689\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 102/390, D loss: 0.719, G loss: 0.701\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 103/390, D loss: 0.701, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 104/390, D loss: 0.715, G loss: 0.718\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 105/390, D loss: 0.664, G loss: 0.711\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 106/390, D loss: 0.699, G loss: 0.720\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 107/390, D loss: 0.699, G loss: 0.719\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 3/200, Batch: 108/390, D loss: 0.698, G loss: 0.719\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 109/390, D loss: 0.690, G loss: 0.706\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 110/390, D loss: 0.682, G loss: 0.701\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 111/390, D loss: 0.689, G loss: 0.686\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 3/200, Batch: 112/390, D loss: 0.679, G loss: 0.667\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 113/390, D loss: 0.689, G loss: 0.659\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 114/390, D loss: 0.691, G loss: 0.660\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 3/200, Batch: 115/390, D loss: 0.676, G loss: 0.653\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 116/390, D loss: 0.659, G loss: 0.651\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 117/390, D loss: 0.690, G loss: 0.672\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 118/390, D loss: 0.668, G loss: 0.683\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 119/390, D loss: 0.689, G loss: 0.701\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 120/390, D loss: 0.729, G loss: 0.720\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 121/390, D loss: 0.689, G loss: 0.730\n",
      "2/2 [==============================] - 0s 682us/step\n",
      "Epoch: 3/200, Batch: 122/390, D loss: 0.703, G loss: 0.733\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 123/390, D loss: 0.693, G loss: 0.712\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 124/390, D loss: 0.733, G loss: 0.717\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 125/390, D loss: 0.704, G loss: 0.682\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 126/390, D loss: 0.693, G loss: 0.670\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 127/390, D loss: 0.716, G loss: 0.666\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 3/200, Batch: 128/390, D loss: 0.700, G loss: 0.664\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 129/390, D loss: 0.720, G loss: 0.674\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 130/390, D loss: 0.721, G loss: 0.680\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 131/390, D loss: 0.719, G loss: 0.682\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 132/390, D loss: 0.711, G loss: 0.713\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 3/200, Batch: 133/390, D loss: 0.719, G loss: 0.728\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 134/390, D loss: 0.736, G loss: 0.763\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 3/200, Batch: 135/390, D loss: 0.750, G loss: 0.779\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 136/390, D loss: 0.729, G loss: 0.791\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 137/390, D loss: 0.734, G loss: 0.828\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 138/390, D loss: 0.712, G loss: 0.818\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 139/390, D loss: 0.718, G loss: 0.831\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 140/390, D loss: 0.724, G loss: 0.824\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 141/390, D loss: 0.720, G loss: 0.797\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 142/390, D loss: 0.692, G loss: 0.769\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 143/390, D loss: 0.715, G loss: 0.740\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 144/390, D loss: 0.685, G loss: 0.697\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 145/390, D loss: 0.699, G loss: 0.640\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 146/390, D loss: 0.695, G loss: 0.626\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 147/390, D loss: 0.712, G loss: 0.621\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 148/390, D loss: 0.743, G loss: 0.607\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 149/390, D loss: 0.720, G loss: 0.644\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 150/390, D loss: 0.720, G loss: 0.664\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 151/390, D loss: 0.709, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 152/390, D loss: 0.718, G loss: 0.709\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 153/390, D loss: 0.733, G loss: 0.763\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 3/200, Batch: 154/390, D loss: 0.715, G loss: 0.790\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 155/390, D loss: 0.746, G loss: 0.820\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 156/390, D loss: 0.724, G loss: 0.826\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 157/390, D loss: 0.715, G loss: 0.838\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 3/200, Batch: 158/390, D loss: 0.702, G loss: 0.854\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 159/390, D loss: 0.728, G loss: 0.824\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 3/200, Batch: 160/390, D loss: 0.748, G loss: 0.787\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 161/390, D loss: 0.700, G loss: 0.772\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 162/390, D loss: 0.700, G loss: 0.766\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 3/200, Batch: 163/390, D loss: 0.719, G loss: 0.712\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 164/390, D loss: 0.737, G loss: 0.699\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 165/390, D loss: 0.705, G loss: 0.668\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 166/390, D loss: 0.708, G loss: 0.672\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 167/390, D loss: 0.786, G loss: 0.642\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 3/200, Batch: 168/390, D loss: 0.712, G loss: 0.663\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 169/390, D loss: 0.730, G loss: 0.649\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 170/390, D loss: 0.754, G loss: 0.677\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 171/390, D loss: 0.735, G loss: 0.677\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 3/200, Batch: 172/390, D loss: 0.742, G loss: 0.690\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 173/390, D loss: 0.755, G loss: 0.720\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 174/390, D loss: 0.757, G loss: 0.737\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 175/390, D loss: 0.747, G loss: 0.758\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 176/390, D loss: 0.768, G loss: 0.775\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 177/390, D loss: 0.775, G loss: 0.799\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 178/390, D loss: 0.764, G loss: 0.812\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 179/390, D loss: 0.749, G loss: 0.811\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 180/390, D loss: 0.769, G loss: 0.825\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 181/390, D loss: 0.758, G loss: 0.809\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 182/390, D loss: 0.748, G loss: 0.817\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 3/200, Batch: 183/390, D loss: 0.757, G loss: 0.797\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 184/390, D loss: 0.745, G loss: 0.779\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 3/200, Batch: 185/390, D loss: 0.750, G loss: 0.777\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 186/390, D loss: 0.757, G loss: 0.763\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 187/390, D loss: 0.745, G loss: 0.739\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 3/200, Batch: 188/390, D loss: 0.760, G loss: 0.750\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 189/390, D loss: 0.761, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 190/390, D loss: 0.733, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 191/390, D loss: 0.747, G loss: 0.701\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 192/390, D loss: 0.730, G loss: 0.687\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 193/390, D loss: 0.739, G loss: 0.697\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 194/390, D loss: 0.724, G loss: 0.690\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 195/390, D loss: 0.723, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 196/390, D loss: 0.714, G loss: 0.704\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 197/390, D loss: 0.735, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 198/390, D loss: 0.736, G loss: 0.719\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 199/390, D loss: 0.721, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 200/390, D loss: 0.725, G loss: 0.728\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 201/390, D loss: 0.717, G loss: 0.738\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 3/200, Batch: 202/390, D loss: 0.705, G loss: 0.746\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 203/390, D loss: 0.728, G loss: 0.744\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 3/200, Batch: 204/390, D loss: 0.693, G loss: 0.734\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 205/390, D loss: 0.735, G loss: 0.756\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 206/390, D loss: 0.722, G loss: 0.744\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 207/390, D loss: 0.707, G loss: 0.721\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 208/390, D loss: 0.706, G loss: 0.711\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 209/390, D loss: 0.739, G loss: 0.715\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 210/390, D loss: 0.704, G loss: 0.699\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 211/390, D loss: 0.706, G loss: 0.674\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 212/390, D loss: 0.700, G loss: 0.681\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 213/390, D loss: 0.694, G loss: 0.678\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 214/390, D loss: 0.679, G loss: 0.666\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 215/390, D loss: 0.676, G loss: 0.671\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 216/390, D loss: 0.693, G loss: 0.660\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 3/200, Batch: 217/390, D loss: 0.693, G loss: 0.666\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 218/390, D loss: 0.692, G loss: 0.662\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 219/390, D loss: 0.674, G loss: 0.655\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 220/390, D loss: 0.719, G loss: 0.666\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 221/390, D loss: 0.679, G loss: 0.673\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 222/390, D loss: 0.692, G loss: 0.681\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 223/390, D loss: 0.685, G loss: 0.692\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 224/390, D loss: 0.690, G loss: 0.689\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 225/390, D loss: 0.683, G loss: 0.716\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 226/390, D loss: 0.692, G loss: 0.723\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 227/390, D loss: 0.687, G loss: 0.725\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 3/200, Batch: 228/390, D loss: 0.676, G loss: 0.720\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 229/390, D loss: 0.701, G loss: 0.732\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 230/390, D loss: 0.699, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 231/390, D loss: 0.711, G loss: 0.719\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 232/390, D loss: 0.687, G loss: 0.705\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 233/390, D loss: 0.663, G loss: 0.693\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 3/200, Batch: 234/390, D loss: 0.667, G loss: 0.696\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 235/390, D loss: 0.696, G loss: 0.679\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 236/390, D loss: 0.677, G loss: 0.664\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 237/390, D loss: 0.655, G loss: 0.646\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 238/390, D loss: 0.672, G loss: 0.641\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 239/390, D loss: 0.664, G loss: 0.636\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 240/390, D loss: 0.658, G loss: 0.636\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 241/390, D loss: 0.703, G loss: 0.637\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 242/390, D loss: 0.678, G loss: 0.643\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 243/390, D loss: 0.674, G loss: 0.652\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 244/390, D loss: 0.670, G loss: 0.661\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 245/390, D loss: 0.695, G loss: 0.673\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 3/200, Batch: 246/390, D loss: 0.666, G loss: 0.705\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 247/390, D loss: 0.677, G loss: 0.715\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 248/390, D loss: 0.682, G loss: 0.725\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 249/390, D loss: 0.686, G loss: 0.749\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 250/390, D loss: 0.687, G loss: 0.760\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 3/200, Batch: 251/390, D loss: 0.677, G loss: 0.755\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 3/200, Batch: 252/390, D loss: 0.694, G loss: 0.745\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 253/390, D loss: 0.705, G loss: 0.751\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 254/390, D loss: 0.687, G loss: 0.740\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 3/200, Batch: 255/390, D loss: 0.687, G loss: 0.726\n",
      "2/2 [==============================] - 0s 528us/step\n",
      "Epoch: 3/200, Batch: 256/390, D loss: 0.684, G loss: 0.704\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 257/390, D loss: 0.664, G loss: 0.687\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 258/390, D loss: 0.678, G loss: 0.669\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 259/390, D loss: 0.659, G loss: 0.651\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 260/390, D loss: 0.660, G loss: 0.648\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 261/390, D loss: 0.679, G loss: 0.629\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 262/390, D loss: 0.680, G loss: 0.639\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 263/390, D loss: 0.712, G loss: 0.635\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 264/390, D loss: 0.668, G loss: 0.640\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 265/390, D loss: 0.692, G loss: 0.639\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 266/390, D loss: 0.702, G loss: 0.655\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 3/200, Batch: 267/390, D loss: 0.679, G loss: 0.679\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 268/390, D loss: 0.685, G loss: 0.692\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 269/390, D loss: 0.690, G loss: 0.725\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 270/390, D loss: 0.697, G loss: 0.717\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 271/390, D loss: 0.698, G loss: 0.725\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 272/390, D loss: 0.675, G loss: 0.744\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 273/390, D loss: 0.696, G loss: 0.747\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch: 3/200, Batch: 274/390, D loss: 0.692, G loss: 0.755\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 275/390, D loss: 0.686, G loss: 0.758\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 276/390, D loss: 0.698, G loss: 0.753\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 277/390, D loss: 0.701, G loss: 0.738\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 278/390, D loss: 0.714, G loss: 0.731\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 279/390, D loss: 0.674, G loss: 0.717\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 280/390, D loss: 0.706, G loss: 0.705\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 281/390, D loss: 0.692, G loss: 0.696\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 3/200, Batch: 282/390, D loss: 0.696, G loss: 0.680\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 283/390, D loss: 0.709, G loss: 0.688\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 284/390, D loss: 0.688, G loss: 0.674\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 285/390, D loss: 0.711, G loss: 0.660\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 3/200, Batch: 286/390, D loss: 0.711, G loss: 0.661\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 287/390, D loss: 0.713, G loss: 0.676\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 3/200, Batch: 288/390, D loss: 0.707, G loss: 0.675\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 289/390, D loss: 0.711, G loss: 0.673\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 3/200, Batch: 290/390, D loss: 0.724, G loss: 0.702\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 3/200, Batch: 291/390, D loss: 0.715, G loss: 0.711\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 292/390, D loss: 0.719, G loss: 0.735\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 293/390, D loss: 0.718, G loss: 0.739\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 294/390, D loss: 0.735, G loss: 0.749\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 295/390, D loss: 0.730, G loss: 0.763\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 296/390, D loss: 0.723, G loss: 0.765\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 297/390, D loss: 0.719, G loss: 0.756\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 3/200, Batch: 298/390, D loss: 0.713, G loss: 0.765\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 299/390, D loss: 0.728, G loss: 0.772\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 300/390, D loss: 0.712, G loss: 0.754\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 301/390, D loss: 0.729, G loss: 0.750\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 302/390, D loss: 0.737, G loss: 0.738\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 303/390, D loss: 0.716, G loss: 0.729\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 304/390, D loss: 0.745, G loss: 0.708\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 305/390, D loss: 0.714, G loss: 0.709\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 306/390, D loss: 0.729, G loss: 0.714\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 307/390, D loss: 0.741, G loss: 0.695\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 3/200, Batch: 308/390, D loss: 0.731, G loss: 0.705\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 309/390, D loss: 0.704, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 310/390, D loss: 0.697, G loss: 0.694\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 311/390, D loss: 0.720, G loss: 0.703\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 312/390, D loss: 0.728, G loss: 0.713\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 313/390, D loss: 0.728, G loss: 0.715\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 314/390, D loss: 0.722, G loss: 0.719\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 315/390, D loss: 0.725, G loss: 0.726\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 316/390, D loss: 0.738, G loss: 0.736\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 317/390, D loss: 0.737, G loss: 0.749\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 318/390, D loss: 0.719, G loss: 0.748\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 319/390, D loss: 0.725, G loss: 0.746\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 320/390, D loss: 0.727, G loss: 0.754\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 321/390, D loss: 0.736, G loss: 0.759\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 322/390, D loss: 0.730, G loss: 0.747\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 3/200, Batch: 323/390, D loss: 0.729, G loss: 0.748\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 324/390, D loss: 0.736, G loss: 0.729\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 325/390, D loss: 0.744, G loss: 0.722\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 326/390, D loss: 0.710, G loss: 0.715\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 327/390, D loss: 0.733, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 328/390, D loss: 0.722, G loss: 0.700\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 329/390, D loss: 0.723, G loss: 0.701\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 330/390, D loss: 0.716, G loss: 0.694\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 331/390, D loss: 0.724, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 332/390, D loss: 0.715, G loss: 0.712\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 3/200, Batch: 333/390, D loss: 0.725, G loss: 0.727\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 334/390, D loss: 0.703, G loss: 0.730\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 335/390, D loss: 0.706, G loss: 0.750\n",
      "2/2 [==============================] - 0s 816us/step\n",
      "Epoch: 3/200, Batch: 336/390, D loss: 0.724, G loss: 0.763\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 337/390, D loss: 0.723, G loss: 0.760\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 338/390, D loss: 0.716, G loss: 0.760\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 339/390, D loss: 0.715, G loss: 0.761\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 340/390, D loss: 0.725, G loss: 0.755\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 341/390, D loss: 0.726, G loss: 0.739\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 342/390, D loss: 0.721, G loss: 0.739\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 343/390, D loss: 0.719, G loss: 0.727\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 344/390, D loss: 0.729, G loss: 0.718\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 345/390, D loss: 0.700, G loss: 0.706\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 346/390, D loss: 0.713, G loss: 0.688\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 347/390, D loss: 0.705, G loss: 0.684\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 348/390, D loss: 0.700, G loss: 0.681\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 349/390, D loss: 0.707, G loss: 0.671\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 350/390, D loss: 0.723, G loss: 0.669\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 351/390, D loss: 0.722, G loss: 0.666\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 3/200, Batch: 352/390, D loss: 0.694, G loss: 0.673\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 3/200, Batch: 353/390, D loss: 0.718, G loss: 0.677\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 354/390, D loss: 0.711, G loss: 0.675\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 355/390, D loss: 0.708, G loss: 0.696\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 356/390, D loss: 0.710, G loss: 0.698\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 3/200, Batch: 357/390, D loss: 0.718, G loss: 0.713\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 3/200, Batch: 358/390, D loss: 0.707, G loss: 0.716\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 359/390, D loss: 0.704, G loss: 0.734\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 360/390, D loss: 0.698, G loss: 0.742\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 3/200, Batch: 361/390, D loss: 0.701, G loss: 0.749\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 3/200, Batch: 362/390, D loss: 0.702, G loss: 0.737\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 363/390, D loss: 0.696, G loss: 0.736\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 364/390, D loss: 0.700, G loss: 0.734\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 3/200, Batch: 365/390, D loss: 0.700, G loss: 0.725\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 366/390, D loss: 0.723, G loss: 0.696\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 367/390, D loss: 0.704, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 368/390, D loss: 0.700, G loss: 0.682\n",
      "2/2 [==============================] - 0s 395us/step\n",
      "Epoch: 3/200, Batch: 369/390, D loss: 0.704, G loss: 0.666\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 3/200, Batch: 370/390, D loss: 0.676, G loss: 0.652\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 371/390, D loss: 0.698, G loss: 0.661\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 372/390, D loss: 0.705, G loss: 0.667\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 373/390, D loss: 0.705, G loss: 0.660\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 374/390, D loss: 0.716, G loss: 0.663\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 375/390, D loss: 0.704, G loss: 0.675\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 3/200, Batch: 376/390, D loss: 0.707, G loss: 0.687\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 3/200, Batch: 377/390, D loss: 0.704, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 378/390, D loss: 0.710, G loss: 0.721\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 3/200, Batch: 379/390, D loss: 0.736, G loss: 0.743\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 3/200, Batch: 380/390, D loss: 0.711, G loss: 0.741\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 381/390, D loss: 0.724, G loss: 0.748\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 382/390, D loss: 0.713, G loss: 0.750\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 383/390, D loss: 0.708, G loss: 0.754\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 384/390, D loss: 0.680, G loss: 0.744\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 3/200, Batch: 385/390, D loss: 0.716, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 3/200, Batch: 386/390, D loss: 0.708, G loss: 0.721\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 3/200, Batch: 387/390, D loss: 0.721, G loss: 0.701\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 3/200, Batch: 388/390, D loss: 0.715, G loss: 0.697\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 3/200, Batch: 389/390, D loss: 0.709, G loss: 0.702\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 3/200, Batch: 390/390, D loss: 0.713, G loss: 0.697\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 1/390, D loss: 0.705, G loss: 0.689\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 4/200, Batch: 2/390, D loss: 0.716, G loss: 0.687\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 3/390, D loss: 0.720, G loss: 0.680\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 4/390, D loss: 0.720, G loss: 0.680\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 5/390, D loss: 0.719, G loss: 0.691\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 4/200, Batch: 6/390, D loss: 0.700, G loss: 0.681\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 7/390, D loss: 0.710, G loss: 0.697\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 8/390, D loss: 0.710, G loss: 0.704\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 9/390, D loss: 0.723, G loss: 0.713\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 10/390, D loss: 0.701, G loss: 0.716\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 4/200, Batch: 11/390, D loss: 0.716, G loss: 0.724\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 12/390, D loss: 0.709, G loss: 0.727\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 4/200, Batch: 13/390, D loss: 0.701, G loss: 0.721\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 14/390, D loss: 0.701, G loss: 0.732\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 15/390, D loss: 0.702, G loss: 0.723\n",
      "2/2 [==============================] - 0s 20ms/step\n",
      "Epoch: 4/200, Batch: 16/390, D loss: 0.703, G loss: 0.716\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 4/200, Batch: 17/390, D loss: 0.682, G loss: 0.707\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 4/200, Batch: 18/390, D loss: 0.720, G loss: 0.713\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 4/200, Batch: 19/390, D loss: 0.701, G loss: 0.709\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 20/390, D loss: 0.693, G loss: 0.705\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 21/390, D loss: 0.703, G loss: 0.696\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 4/200, Batch: 22/390, D loss: 0.718, G loss: 0.695\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 23/390, D loss: 0.717, G loss: 0.700\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 24/390, D loss: 0.715, G loss: 0.693\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 25/390, D loss: 0.730, G loss: 0.697\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 26/390, D loss: 0.718, G loss: 0.706\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 27/390, D loss: 0.701, G loss: 0.707\n",
      "2/2 [==============================] - 0s 819us/step\n",
      "Epoch: 4/200, Batch: 28/390, D loss: 0.726, G loss: 0.717\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 4/200, Batch: 29/390, D loss: 0.723, G loss: 0.735\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 4/200, Batch: 30/390, D loss: 0.730, G loss: 0.734\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 31/390, D loss: 0.705, G loss: 0.742\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 4/200, Batch: 32/390, D loss: 0.703, G loss: 0.746\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 33/390, D loss: 0.745, G loss: 0.751\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 34/390, D loss: 0.742, G loss: 0.753\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 35/390, D loss: 0.727, G loss: 0.744\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 36/390, D loss: 0.739, G loss: 0.738\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 37/390, D loss: 0.748, G loss: 0.735\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 38/390, D loss: 0.726, G loss: 0.730\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 39/390, D loss: 0.698, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 40/390, D loss: 0.736, G loss: 0.714\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 41/390, D loss: 0.730, G loss: 0.715\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 4/200, Batch: 42/390, D loss: 0.708, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 43/390, D loss: 0.714, G loss: 0.700\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 44/390, D loss: 0.706, G loss: 0.689\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 4/200, Batch: 45/390, D loss: 0.720, G loss: 0.687\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 46/390, D loss: 0.703, G loss: 0.690\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 47/390, D loss: 0.700, G loss: 0.690\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 48/390, D loss: 0.705, G loss: 0.695\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 49/390, D loss: 0.704, G loss: 0.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 50/390, D loss: 0.699, G loss: 0.695\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 51/390, D loss: 0.696, G loss: 0.703\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 52/390, D loss: 0.691, G loss: 0.702\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 53/390, D loss: 0.681, G loss: 0.709\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 54/390, D loss: 0.688, G loss: 0.706\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 4/200, Batch: 55/390, D loss: 0.687, G loss: 0.709\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 56/390, D loss: 0.693, G loss: 0.716\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 57/390, D loss: 0.678, G loss: 0.703\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 58/390, D loss: 0.681, G loss: 0.691\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 59/390, D loss: 0.677, G loss: 0.683\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 60/390, D loss: 0.696, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 61/390, D loss: 0.698, G loss: 0.678\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 62/390, D loss: 0.695, G loss: 0.680\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 4/200, Batch: 63/390, D loss: 0.685, G loss: 0.671\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 4/200, Batch: 64/390, D loss: 0.681, G loss: 0.665\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 65/390, D loss: 0.688, G loss: 0.671\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 66/390, D loss: 0.699, G loss: 0.669\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 67/390, D loss: 0.688, G loss: 0.676\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 68/390, D loss: 0.677, G loss: 0.687\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 69/390, D loss: 0.689, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 70/390, D loss: 0.697, G loss: 0.716\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 4/200, Batch: 71/390, D loss: 0.703, G loss: 0.717\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 72/390, D loss: 0.695, G loss: 0.728\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 73/390, D loss: 0.705, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 74/390, D loss: 0.715, G loss: 0.725\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 75/390, D loss: 0.711, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 76/390, D loss: 0.687, G loss: 0.732\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 4/200, Batch: 77/390, D loss: 0.713, G loss: 0.725\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 78/390, D loss: 0.722, G loss: 0.722\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 79/390, D loss: 0.712, G loss: 0.724\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 80/390, D loss: 0.713, G loss: 0.703\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 4/200, Batch: 81/390, D loss: 0.725, G loss: 0.703\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 82/390, D loss: 0.705, G loss: 0.697\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 83/390, D loss: 0.695, G loss: 0.697\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 84/390, D loss: 0.707, G loss: 0.689\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 4/200, Batch: 85/390, D loss: 0.714, G loss: 0.695\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 86/390, D loss: 0.697, G loss: 0.690\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 87/390, D loss: 0.680, G loss: 0.695\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 88/390, D loss: 0.701, G loss: 0.695\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 4/200, Batch: 89/390, D loss: 0.707, G loss: 0.681\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 4/200, Batch: 90/390, D loss: 0.689, G loss: 0.687\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 91/390, D loss: 0.706, G loss: 0.720\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 92/390, D loss: 0.704, G loss: 0.712\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 4/200, Batch: 93/390, D loss: 0.687, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 94/390, D loss: 0.694, G loss: 0.732\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 95/390, D loss: 0.700, G loss: 0.723\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 96/390, D loss: 0.695, G loss: 0.721\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 97/390, D loss: 0.692, G loss: 0.713\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 4/200, Batch: 98/390, D loss: 0.680, G loss: 0.710\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 99/390, D loss: 0.691, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 100/390, D loss: 0.716, G loss: 0.696\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 101/390, D loss: 0.686, G loss: 0.683\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 102/390, D loss: 0.688, G loss: 0.682\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 103/390, D loss: 0.664, G loss: 0.680\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 104/390, D loss: 0.675, G loss: 0.677\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 105/390, D loss: 0.690, G loss: 0.677\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 106/390, D loss: 0.684, G loss: 0.667\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 107/390, D loss: 0.688, G loss: 0.673\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 108/390, D loss: 0.699, G loss: 0.683\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 109/390, D loss: 0.701, G loss: 0.698\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 4/200, Batch: 110/390, D loss: 0.683, G loss: 0.691\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 111/390, D loss: 0.697, G loss: 0.701\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 112/390, D loss: 0.687, G loss: 0.708\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 4/200, Batch: 113/390, D loss: 0.688, G loss: 0.723\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 114/390, D loss: 0.695, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 115/390, D loss: 0.676, G loss: 0.719\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 4/200, Batch: 116/390, D loss: 0.697, G loss: 0.727\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 117/390, D loss: 0.708, G loss: 0.723\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 118/390, D loss: 0.676, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 119/390, D loss: 0.678, G loss: 0.712\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 4/200, Batch: 120/390, D loss: 0.682, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 121/390, D loss: 0.694, G loss: 0.697\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 122/390, D loss: 0.704, G loss: 0.692\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 123/390, D loss: 0.670, G loss: 0.691\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 124/390, D loss: 0.700, G loss: 0.683\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 125/390, D loss: 0.689, G loss: 0.681\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 126/390, D loss: 0.688, G loss: 0.689\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 127/390, D loss: 0.695, G loss: 0.699\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 4/200, Batch: 128/390, D loss: 0.680, G loss: 0.693\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 129/390, D loss: 0.679, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 130/390, D loss: 0.682, G loss: 0.708\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 4/200, Batch: 131/390, D loss: 0.683, G loss: 0.704\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 132/390, D loss: 0.683, G loss: 0.714\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 133/390, D loss: 0.698, G loss: 0.710\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 4/200, Batch: 134/390, D loss: 0.671, G loss: 0.718\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 135/390, D loss: 0.687, G loss: 0.715\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 136/390, D loss: 0.688, G loss: 0.709\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 137/390, D loss: 0.676, G loss: 0.703\n",
      "2/2 [==============================] - 0s 844us/step\n",
      "Epoch: 4/200, Batch: 138/390, D loss: 0.683, G loss: 0.703\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 4/200, Batch: 139/390, D loss: 0.690, G loss: 0.701\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 140/390, D loss: 0.691, G loss: 0.687\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 4/200, Batch: 141/390, D loss: 0.673, G loss: 0.693\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 142/390, D loss: 0.688, G loss: 0.689\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 143/390, D loss: 0.685, G loss: 0.700\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 144/390, D loss: 0.677, G loss: 0.686\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 4/200, Batch: 145/390, D loss: 0.685, G loss: 0.699\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 146/390, D loss: 0.684, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 147/390, D loss: 0.685, G loss: 0.714\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 148/390, D loss: 0.684, G loss: 0.711\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 149/390, D loss: 0.689, G loss: 0.714\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 150/390, D loss: 0.692, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 151/390, D loss: 0.663, G loss: 0.707\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 152/390, D loss: 0.685, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 153/390, D loss: 0.698, G loss: 0.699\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 154/390, D loss: 0.699, G loss: 0.700\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 4/200, Batch: 155/390, D loss: 0.696, G loss: 0.692\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 156/390, D loss: 0.684, G loss: 0.688\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 157/390, D loss: 0.696, G loss: 0.675\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 158/390, D loss: 0.679, G loss: 0.694\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 159/390, D loss: 0.680, G loss: 0.688\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 160/390, D loss: 0.692, G loss: 0.689\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 161/390, D loss: 0.685, G loss: 0.691\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 162/390, D loss: 0.690, G loss: 0.695\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 4/200, Batch: 163/390, D loss: 0.699, G loss: 0.707\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 164/390, D loss: 0.692, G loss: 0.693\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 165/390, D loss: 0.689, G loss: 0.706\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 4/200, Batch: 166/390, D loss: 0.697, G loss: 0.715\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 167/390, D loss: 0.702, G loss: 0.714\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 168/390, D loss: 0.693, G loss: 0.708\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 169/390, D loss: 0.697, G loss: 0.708\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 170/390, D loss: 0.694, G loss: 0.701\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 171/390, D loss: 0.696, G loss: 0.701\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 172/390, D loss: 0.701, G loss: 0.689\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 173/390, D loss: 0.700, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 174/390, D loss: 0.691, G loss: 0.694\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 4/200, Batch: 175/390, D loss: 0.700, G loss: 0.696\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 176/390, D loss: 0.702, G loss: 0.706\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 177/390, D loss: 0.689, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 178/390, D loss: 0.709, G loss: 0.713\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 179/390, D loss: 0.714, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 180/390, D loss: 0.711, G loss: 0.709\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 181/390, D loss: 0.707, G loss: 0.720\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 182/390, D loss: 0.698, G loss: 0.713\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 183/390, D loss: 0.696, G loss: 0.727\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 184/390, D loss: 0.717, G loss: 0.739\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 4/200, Batch: 185/390, D loss: 0.700, G loss: 0.723\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 186/390, D loss: 0.688, G loss: 0.728\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 187/390, D loss: 0.702, G loss: 0.724\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 188/390, D loss: 0.703, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 189/390, D loss: 0.701, G loss: 0.714\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 190/390, D loss: 0.699, G loss: 0.717\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 191/390, D loss: 0.713, G loss: 0.710\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 4/200, Batch: 192/390, D loss: 0.690, G loss: 0.714\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 193/390, D loss: 0.719, G loss: 0.695\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 194/390, D loss: 0.707, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 195/390, D loss: 0.699, G loss: 0.715\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 196/390, D loss: 0.695, G loss: 0.719\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 197/390, D loss: 0.711, G loss: 0.718\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 198/390, D loss: 0.708, G loss: 0.736\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 4/200, Batch: 199/390, D loss: 0.700, G loss: 0.728\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 200/390, D loss: 0.723, G loss: 0.733\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 201/390, D loss: 0.700, G loss: 0.731\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 202/390, D loss: 0.699, G loss: 0.742\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 203/390, D loss: 0.690, G loss: 0.730\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 204/390, D loss: 0.701, G loss: 0.727\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 205/390, D loss: 0.693, G loss: 0.724\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 206/390, D loss: 0.719, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 207/390, D loss: 0.728, G loss: 0.720\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 208/390, D loss: 0.715, G loss: 0.709\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 209/390, D loss: 0.704, G loss: 0.721\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 210/390, D loss: 0.715, G loss: 0.725\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 211/390, D loss: 0.700, G loss: 0.706\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 4/200, Batch: 212/390, D loss: 0.704, G loss: 0.724\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 4/200, Batch: 213/390, D loss: 0.695, G loss: 0.724\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 214/390, D loss: 0.749, G loss: 0.729\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 215/390, D loss: 0.729, G loss: 0.724\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 216/390, D loss: 0.731, G loss: 0.726\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 217/390, D loss: 0.709, G loss: 0.726\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 4/200, Batch: 218/390, D loss: 0.716, G loss: 0.739\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 219/390, D loss: 0.715, G loss: 0.730\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 220/390, D loss: 0.708, G loss: 0.733\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 221/390, D loss: 0.734, G loss: 0.726\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 222/390, D loss: 0.691, G loss: 0.723\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 223/390, D loss: 0.715, G loss: 0.747\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 224/390, D loss: 0.712, G loss: 0.731\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 225/390, D loss: 0.715, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 226/390, D loss: 0.702, G loss: 0.733\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 4/200, Batch: 227/390, D loss: 0.711, G loss: 0.728\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 228/390, D loss: 0.708, G loss: 0.747\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 229/390, D loss: 0.706, G loss: 0.733\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 230/390, D loss: 0.703, G loss: 0.733\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 4/200, Batch: 231/390, D loss: 0.701, G loss: 0.723\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 232/390, D loss: 0.701, G loss: 0.722\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Epoch: 4/200, Batch: 233/390, D loss: 0.698, G loss: 0.716\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 234/390, D loss: 0.692, G loss: 0.727\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 235/390, D loss: 0.709, G loss: 0.720\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 236/390, D loss: 0.684, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 237/390, D loss: 0.687, G loss: 0.716\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 238/390, D loss: 0.689, G loss: 0.713\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 4/200, Batch: 239/390, D loss: 0.678, G loss: 0.718\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 240/390, D loss: 0.690, G loss: 0.720\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 241/390, D loss: 0.682, G loss: 0.726\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 242/390, D loss: 0.671, G loss: 0.725\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 243/390, D loss: 0.686, G loss: 0.713\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 4/200, Batch: 244/390, D loss: 0.701, G loss: 0.719\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 245/390, D loss: 0.682, G loss: 0.732\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 246/390, D loss: 0.697, G loss: 0.716\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 247/390, D loss: 0.658, G loss: 0.710\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 4/200, Batch: 248/390, D loss: 0.685, G loss: 0.710\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 249/390, D loss: 0.679, G loss: 0.710\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 250/390, D loss: 0.710, G loss: 0.718\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 251/390, D loss: 0.686, G loss: 0.702\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 252/390, D loss: 0.670, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 253/390, D loss: 0.675, G loss: 0.707\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 254/390, D loss: 0.683, G loss: 0.707\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 4/200, Batch: 255/390, D loss: 0.696, G loss: 0.707\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 256/390, D loss: 0.673, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 257/390, D loss: 0.705, G loss: 0.724\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 258/390, D loss: 0.681, G loss: 0.728\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 4/200, Batch: 259/390, D loss: 0.674, G loss: 0.721\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 260/390, D loss: 0.681, G loss: 0.729\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 261/390, D loss: 0.694, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 262/390, D loss: 0.712, G loss: 0.734\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 263/390, D loss: 0.680, G loss: 0.720\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 264/390, D loss: 0.687, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 265/390, D loss: 0.668, G loss: 0.704\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 266/390, D loss: 0.647, G loss: 0.708\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 267/390, D loss: 0.687, G loss: 0.715\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 268/390, D loss: 0.672, G loss: 0.723\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 269/390, D loss: 0.704, G loss: 0.711\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 4/200, Batch: 270/390, D loss: 0.691, G loss: 0.730\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 271/390, D loss: 0.680, G loss: 0.724\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 272/390, D loss: 0.681, G loss: 0.743\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 273/390, D loss: 0.666, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 274/390, D loss: 0.687, G loss: 0.742\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 4/200, Batch: 275/390, D loss: 0.687, G loss: 0.722\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 276/390, D loss: 0.681, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 277/390, D loss: 0.699, G loss: 0.728\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 278/390, D loss: 0.674, G loss: 0.712\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 279/390, D loss: 0.676, G loss: 0.717\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 280/390, D loss: 0.683, G loss: 0.717\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 281/390, D loss: 0.663, G loss: 0.722\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 4/200, Batch: 282/390, D loss: 0.661, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 283/390, D loss: 0.675, G loss: 0.720\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 284/390, D loss: 0.695, G loss: 0.737\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 285/390, D loss: 0.670, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 286/390, D loss: 0.658, G loss: 0.711\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 4/200, Batch: 287/390, D loss: 0.696, G loss: 0.738\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 288/390, D loss: 0.669, G loss: 0.721\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 289/390, D loss: 0.684, G loss: 0.722\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 290/390, D loss: 0.665, G loss: 0.709\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 291/390, D loss: 0.677, G loss: 0.723\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 292/390, D loss: 0.683, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 293/390, D loss: 0.679, G loss: 0.740\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 4/200, Batch: 294/390, D loss: 0.662, G loss: 0.753\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 295/390, D loss: 0.671, G loss: 0.762\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 296/390, D loss: 0.707, G loss: 0.757\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 297/390, D loss: 0.686, G loss: 0.753\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 4/200, Batch: 298/390, D loss: 0.671, G loss: 0.781\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 299/390, D loss: 0.709, G loss: 0.783\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 300/390, D loss: 0.727, G loss: 0.769\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 301/390, D loss: 0.700, G loss: 0.752\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 302/390, D loss: 0.701, G loss: 0.728\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 303/390, D loss: 0.679, G loss: 0.744\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 304/390, D loss: 0.675, G loss: 0.764\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 4/200, Batch: 305/390, D loss: 0.675, G loss: 0.762\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 306/390, D loss: 0.702, G loss: 0.751\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 307/390, D loss: 0.695, G loss: 0.768\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 4/200, Batch: 308/390, D loss: 0.711, G loss: 0.758\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 309/390, D loss: 0.712, G loss: 0.751\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 310/390, D loss: 0.666, G loss: 0.756\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 4/200, Batch: 311/390, D loss: 0.679, G loss: 0.760\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 312/390, D loss: 0.667, G loss: 0.761\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 313/390, D loss: 0.698, G loss: 0.765\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 314/390, D loss: 0.663, G loss: 0.751\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 315/390, D loss: 0.670, G loss: 0.760\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 316/390, D loss: 0.710, G loss: 0.769\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 317/390, D loss: 0.706, G loss: 0.755\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 318/390, D loss: 0.722, G loss: 0.733\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 319/390, D loss: 0.713, G loss: 0.760\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 320/390, D loss: 0.691, G loss: 0.746\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 321/390, D loss: 0.673, G loss: 0.746\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 322/390, D loss: 0.694, G loss: 0.757\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 323/390, D loss: 0.693, G loss: 0.765\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 324/390, D loss: 0.693, G loss: 0.746\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 4/200, Batch: 325/390, D loss: 0.707, G loss: 0.743\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 326/390, D loss: 0.677, G loss: 0.740\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 4/200, Batch: 327/390, D loss: 0.714, G loss: 0.759\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 328/390, D loss: 0.689, G loss: 0.759\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 329/390, D loss: 0.753, G loss: 0.766\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 330/390, D loss: 0.651, G loss: 0.778\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 331/390, D loss: 0.721, G loss: 0.761\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 332/390, D loss: 0.699, G loss: 0.752\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 4/200, Batch: 333/390, D loss: 0.709, G loss: 0.760\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 334/390, D loss: 0.654, G loss: 0.776\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 4/200, Batch: 335/390, D loss: 0.664, G loss: 0.773\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 336/390, D loss: 0.667, G loss: 0.756\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 337/390, D loss: 0.700, G loss: 0.744\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 338/390, D loss: 0.676, G loss: 0.739\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 339/390, D loss: 0.707, G loss: 0.736\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 340/390, D loss: 0.721, G loss: 0.732\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 341/390, D loss: 0.699, G loss: 0.727\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 4/200, Batch: 342/390, D loss: 0.642, G loss: 0.727\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 343/390, D loss: 0.666, G loss: 0.725\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 4/200, Batch: 344/390, D loss: 0.663, G loss: 0.742\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 4/200, Batch: 345/390, D loss: 0.641, G loss: 0.731\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 346/390, D loss: 0.693, G loss: 0.746\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 4/200, Batch: 347/390, D loss: 0.642, G loss: 0.727\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 4/200, Batch: 348/390, D loss: 0.682, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 349/390, D loss: 0.673, G loss: 0.726\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 4/200, Batch: 350/390, D loss: 0.623, G loss: 0.764\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 351/390, D loss: 0.702, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 352/390, D loss: 0.688, G loss: 0.731\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 353/390, D loss: 0.654, G loss: 0.724\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 354/390, D loss: 0.685, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 355/390, D loss: 0.685, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 356/390, D loss: 0.680, G loss: 0.707\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 357/390, D loss: 0.690, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 358/390, D loss: 0.653, G loss: 0.692\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 359/390, D loss: 0.670, G loss: 0.700\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 360/390, D loss: 0.688, G loss: 0.684\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 361/390, D loss: 0.707, G loss: 0.713\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 4/200, Batch: 362/390, D loss: 0.635, G loss: 0.714\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 363/390, D loss: 0.678, G loss: 0.733\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 364/390, D loss: 0.670, G loss: 0.729\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 4/200, Batch: 365/390, D loss: 0.705, G loss: 0.731\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 366/390, D loss: 0.671, G loss: 0.714\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 367/390, D loss: 0.703, G loss: 0.699\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 368/390, D loss: 0.694, G loss: 0.696\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 369/390, D loss: 0.697, G loss: 0.691\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 370/390, D loss: 0.702, G loss: 0.680\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 4/200, Batch: 371/390, D loss: 0.718, G loss: 0.663\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 372/390, D loss: 0.705, G loss: 0.651\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 373/390, D loss: 0.686, G loss: 0.649\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 4/200, Batch: 374/390, D loss: 0.639, G loss: 0.627\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 375/390, D loss: 0.681, G loss: 0.623\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 376/390, D loss: 0.716, G loss: 0.617\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 377/390, D loss: 0.695, G loss: 0.628\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 378/390, D loss: 0.675, G loss: 0.639\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 4/200, Batch: 379/390, D loss: 0.681, G loss: 0.618\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 4/200, Batch: 380/390, D loss: 0.696, G loss: 0.645\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 4/200, Batch: 381/390, D loss: 0.708, G loss: 0.652\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 382/390, D loss: 0.656, G loss: 0.659\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 383/390, D loss: 0.717, G loss: 0.654\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 4/200, Batch: 384/390, D loss: 0.692, G loss: 0.653\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 4/200, Batch: 385/390, D loss: 0.689, G loss: 0.655\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 4/200, Batch: 386/390, D loss: 0.679, G loss: 0.644\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 4/200, Batch: 387/390, D loss: 0.690, G loss: 0.630\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 4/200, Batch: 388/390, D loss: 0.702, G loss: 0.643\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 4/200, Batch: 389/390, D loss: 0.703, G loss: 0.656\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 4/200, Batch: 390/390, D loss: 0.700, G loss: 0.662\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 1/390, D loss: 0.734, G loss: 0.669\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 2/390, D loss: 0.710, G loss: 0.674\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 3/390, D loss: 0.733, G loss: 0.697\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 4/390, D loss: 0.720, G loss: 0.735\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 5/390, D loss: 0.707, G loss: 0.734\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 6/390, D loss: 0.768, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 7/390, D loss: 0.730, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 8/390, D loss: 0.737, G loss: 0.703\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 9/390, D loss: 0.740, G loss: 0.709\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 10/390, D loss: 0.734, G loss: 0.688\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 11/390, D loss: 0.744, G loss: 0.670\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 12/390, D loss: 0.722, G loss: 0.675\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 13/390, D loss: 0.728, G loss: 0.673\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 14/390, D loss: 0.738, G loss: 0.675\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 15/390, D loss: 0.742, G loss: 0.681\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 16/390, D loss: 0.734, G loss: 0.692\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 17/390, D loss: 0.747, G loss: 0.703\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 18/390, D loss: 0.728, G loss: 0.717\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 19/390, D loss: 0.746, G loss: 0.702\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 20/390, D loss: 0.726, G loss: 0.720\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 21/390, D loss: 0.730, G loss: 0.706\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 22/390, D loss: 0.747, G loss: 0.701\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 23/390, D loss: 0.742, G loss: 0.696\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 5/200, Batch: 24/390, D loss: 0.724, G loss: 0.691\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 25/390, D loss: 0.726, G loss: 0.680\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 26/390, D loss: 0.757, G loss: 0.669\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 27/390, D loss: 0.749, G loss: 0.670\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 5/200, Batch: 28/390, D loss: 0.734, G loss: 0.681\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 29/390, D loss: 0.723, G loss: 0.681\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 30/390, D loss: 0.722, G loss: 0.705\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 31/390, D loss: 0.745, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 32/390, D loss: 0.750, G loss: 0.729\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 33/390, D loss: 0.758, G loss: 0.737\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 5/200, Batch: 34/390, D loss: 0.745, G loss: 0.753\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 35/390, D loss: 0.734, G loss: 0.752\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 36/390, D loss: 0.759, G loss: 0.756\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 37/390, D loss: 0.788, G loss: 0.757\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 38/390, D loss: 0.740, G loss: 0.723\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 39/390, D loss: 0.735, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 40/390, D loss: 0.730, G loss: 0.721\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 5/200, Batch: 41/390, D loss: 0.750, G loss: 0.709\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 5/200, Batch: 42/390, D loss: 0.732, G loss: 0.715\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 5/200, Batch: 43/390, D loss: 0.744, G loss: 0.711\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 44/390, D loss: 0.732, G loss: 0.703\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 5/200, Batch: 45/390, D loss: 0.746, G loss: 0.703\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 46/390, D loss: 0.739, G loss: 0.724\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 47/390, D loss: 0.746, G loss: 0.721\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 48/390, D loss: 0.750, G loss: 0.726\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 49/390, D loss: 0.725, G loss: 0.732\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 50/390, D loss: 0.739, G loss: 0.739\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 51/390, D loss: 0.750, G loss: 0.745\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 52/390, D loss: 0.742, G loss: 0.739\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 53/390, D loss: 0.730, G loss: 0.734\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 54/390, D loss: 0.747, G loss: 0.731\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 55/390, D loss: 0.739, G loss: 0.723\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 5/200, Batch: 56/390, D loss: 0.735, G loss: 0.721\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 57/390, D loss: 0.738, G loss: 0.715\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 58/390, D loss: 0.733, G loss: 0.717\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 59/390, D loss: 0.732, G loss: 0.705\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 60/390, D loss: 0.717, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 61/390, D loss: 0.724, G loss: 0.699\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 62/390, D loss: 0.737, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 63/390, D loss: 0.748, G loss: 0.696\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 64/390, D loss: 0.720, G loss: 0.705\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch: 5/200, Batch: 65/390, D loss: 0.735, G loss: 0.701\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 66/390, D loss: 0.723, G loss: 0.708\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 5/200, Batch: 67/390, D loss: 0.730, G loss: 0.720\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 68/390, D loss: 0.721, G loss: 0.733\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 69/390, D loss: 0.732, G loss: 0.737\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 70/390, D loss: 0.728, G loss: 0.732\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 71/390, D loss: 0.740, G loss: 0.732\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 72/390, D loss: 0.726, G loss: 0.724\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 73/390, D loss: 0.728, G loss: 0.718\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 74/390, D loss: 0.722, G loss: 0.718\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 5/200, Batch: 75/390, D loss: 0.719, G loss: 0.708\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 76/390, D loss: 0.721, G loss: 0.707\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 77/390, D loss: 0.727, G loss: 0.697\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 78/390, D loss: 0.728, G loss: 0.690\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 79/390, D loss: 0.716, G loss: 0.689\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 80/390, D loss: 0.714, G loss: 0.681\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 5/200, Batch: 81/390, D loss: 0.700, G loss: 0.677\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 5/200, Batch: 82/390, D loss: 0.724, G loss: 0.688\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 83/390, D loss: 0.715, G loss: 0.696\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 5/200, Batch: 84/390, D loss: 0.703, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 85/390, D loss: 0.701, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 86/390, D loss: 0.724, G loss: 0.728\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 5/200, Batch: 87/390, D loss: 0.711, G loss: 0.721\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 88/390, D loss: 0.693, G loss: 0.725\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 89/390, D loss: 0.697, G loss: 0.710\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 90/390, D loss: 0.694, G loss: 0.705\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 91/390, D loss: 0.702, G loss: 0.685\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 92/390, D loss: 0.678, G loss: 0.695\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 93/390, D loss: 0.693, G loss: 0.680\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 5/200, Batch: 94/390, D loss: 0.691, G loss: 0.679\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 5/200, Batch: 95/390, D loss: 0.693, G loss: 0.678\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 96/390, D loss: 0.681, G loss: 0.671\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 97/390, D loss: 0.700, G loss: 0.670\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 5/200, Batch: 98/390, D loss: 0.690, G loss: 0.676\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 99/390, D loss: 0.669, G loss: 0.665\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 100/390, D loss: 0.685, G loss: 0.682\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 5/200, Batch: 101/390, D loss: 0.691, G loss: 0.672\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 102/390, D loss: 0.705, G loss: 0.680\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 5/200, Batch: 103/390, D loss: 0.695, G loss: 0.692\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 104/390, D loss: 0.708, G loss: 0.700\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 105/390, D loss: 0.723, G loss: 0.699\n",
      "2/2 [==============================] - 0s 744us/step\n",
      "Epoch: 5/200, Batch: 106/390, D loss: 0.692, G loss: 0.714\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 107/390, D loss: 0.705, G loss: 0.716\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 108/390, D loss: 0.704, G loss: 0.720\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 5/200, Batch: 109/390, D loss: 0.715, G loss: 0.718\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 110/390, D loss: 0.716, G loss: 0.720\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 111/390, D loss: 0.705, G loss: 0.722\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 112/390, D loss: 0.724, G loss: 0.708\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 113/390, D loss: 0.722, G loss: 0.718\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 114/390, D loss: 0.715, G loss: 0.714\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 115/390, D loss: 0.716, G loss: 0.712\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 116/390, D loss: 0.723, G loss: 0.701\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 117/390, D loss: 0.706, G loss: 0.697\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 118/390, D loss: 0.717, G loss: 0.688\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 119/390, D loss: 0.714, G loss: 0.693\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 120/390, D loss: 0.705, G loss: 0.680\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 121/390, D loss: 0.719, G loss: 0.682\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 122/390, D loss: 0.714, G loss: 0.684\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 123/390, D loss: 0.713, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 124/390, D loss: 0.706, G loss: 0.715\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 5/200, Batch: 125/390, D loss: 0.728, G loss: 0.705\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 126/390, D loss: 0.700, G loss: 0.728\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 127/390, D loss: 0.714, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 128/390, D loss: 0.719, G loss: 0.715\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 129/390, D loss: 0.713, G loss: 0.716\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 130/390, D loss: 0.715, G loss: 0.718\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 131/390, D loss: 0.718, G loss: 0.721\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 132/390, D loss: 0.711, G loss: 0.729\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 5/200, Batch: 133/390, D loss: 0.724, G loss: 0.726\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 134/390, D loss: 0.719, G loss: 0.722\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 5/200, Batch: 135/390, D loss: 0.719, G loss: 0.722\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 136/390, D loss: 0.721, G loss: 0.711\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 137/390, D loss: 0.726, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 138/390, D loss: 0.722, G loss: 0.706\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 139/390, D loss: 0.723, G loss: 0.702\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 5/200, Batch: 140/390, D loss: 0.718, G loss: 0.715\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 141/390, D loss: 0.717, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 142/390, D loss: 0.725, G loss: 0.712\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 143/390, D loss: 0.736, G loss: 0.710\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 144/390, D loss: 0.724, G loss: 0.714\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 145/390, D loss: 0.730, G loss: 0.714\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 146/390, D loss: 0.717, G loss: 0.723\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 5/200, Batch: 147/390, D loss: 0.732, G loss: 0.729\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 148/390, D loss: 0.721, G loss: 0.717\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 5/200, Batch: 149/390, D loss: 0.733, G loss: 0.729\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 150/390, D loss: 0.723, G loss: 0.736\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 151/390, D loss: 0.734, G loss: 0.735\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 152/390, D loss: 0.718, G loss: 0.726\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 153/390, D loss: 0.724, G loss: 0.728\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 154/390, D loss: 0.719, G loss: 0.721\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 155/390, D loss: 0.709, G loss: 0.719\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 156/390, D loss: 0.709, G loss: 0.716\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 157/390, D loss: 0.717, G loss: 0.695\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 158/390, D loss: 0.689, G loss: 0.688\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 159/390, D loss: 0.707, G loss: 0.691\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 5/200, Batch: 160/390, D loss: 0.732, G loss: 0.690\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Epoch: 5/200, Batch: 161/390, D loss: 0.691, G loss: 0.688\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 162/390, D loss: 0.710, G loss: 0.698\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 163/390, D loss: 0.686, G loss: 0.701\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 5/200, Batch: 164/390, D loss: 0.711, G loss: 0.704\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 165/390, D loss: 0.711, G loss: 0.696\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 166/390, D loss: 0.711, G loss: 0.701\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 5/200, Batch: 167/390, D loss: 0.700, G loss: 0.701\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 168/390, D loss: 0.695, G loss: 0.705\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 169/390, D loss: 0.711, G loss: 0.712\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 5/200, Batch: 170/390, D loss: 0.702, G loss: 0.713\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 171/390, D loss: 0.709, G loss: 0.715\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 172/390, D loss: 0.703, G loss: 0.727\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 173/390, D loss: 0.719, G loss: 0.725\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 174/390, D loss: 0.705, G loss: 0.714\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 5/200, Batch: 175/390, D loss: 0.675, G loss: 0.709\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 176/390, D loss: 0.702, G loss: 0.698\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch: 5/200, Batch: 177/390, D loss: 0.693, G loss: 0.690\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 178/390, D loss: 0.697, G loss: 0.687\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 179/390, D loss: 0.694, G loss: 0.682\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 180/390, D loss: 0.693, G loss: 0.669\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 181/390, D loss: 0.682, G loss: 0.667\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 5/200, Batch: 182/390, D loss: 0.671, G loss: 0.673\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 183/390, D loss: 0.692, G loss: 0.677\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 184/390, D loss: 0.685, G loss: 0.692\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 185/390, D loss: 0.704, G loss: 0.698\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 186/390, D loss: 0.685, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 187/390, D loss: 0.680, G loss: 0.694\n",
      "2/2 [==============================] - 0s 20ms/step\n",
      "Epoch: 5/200, Batch: 188/390, D loss: 0.684, G loss: 0.702\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 189/390, D loss: 0.705, G loss: 0.707\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 190/390, D loss: 0.684, G loss: 0.686\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 191/390, D loss: 0.694, G loss: 0.706\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 192/390, D loss: 0.684, G loss: 0.694\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 193/390, D loss: 0.695, G loss: 0.691\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 194/390, D loss: 0.670, G loss: 0.688\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 195/390, D loss: 0.690, G loss: 0.706\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 196/390, D loss: 0.691, G loss: 0.707\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 5/200, Batch: 197/390, D loss: 0.680, G loss: 0.703\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 198/390, D loss: 0.697, G loss: 0.702\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 199/390, D loss: 0.698, G loss: 0.702\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 200/390, D loss: 0.682, G loss: 0.694\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 201/390, D loss: 0.688, G loss: 0.687\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 202/390, D loss: 0.688, G loss: 0.678\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 203/390, D loss: 0.690, G loss: 0.673\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 204/390, D loss: 0.700, G loss: 0.674\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 205/390, D loss: 0.691, G loss: 0.682\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 206/390, D loss: 0.697, G loss: 0.688\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 207/390, D loss: 0.702, G loss: 0.708\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 208/390, D loss: 0.709, G loss: 0.712\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 209/390, D loss: 0.693, G loss: 0.720\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 210/390, D loss: 0.720, G loss: 0.714\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 211/390, D loss: 0.710, G loss: 0.725\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 5/200, Batch: 212/390, D loss: 0.715, G loss: 0.710\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 213/390, D loss: 0.700, G loss: 0.709\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 214/390, D loss: 0.709, G loss: 0.706\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 5/200, Batch: 215/390, D loss: 0.708, G loss: 0.694\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 5/200, Batch: 216/390, D loss: 0.704, G loss: 0.702\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 217/390, D loss: 0.713, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 218/390, D loss: 0.714, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 219/390, D loss: 0.713, G loss: 0.711\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 220/390, D loss: 0.701, G loss: 0.708\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 5/200, Batch: 221/390, D loss: 0.713, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 222/390, D loss: 0.727, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 223/390, D loss: 0.706, G loss: 0.699\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 5/200, Batch: 224/390, D loss: 0.717, G loss: 0.701\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 225/390, D loss: 0.715, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 226/390, D loss: 0.718, G loss: 0.716\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 227/390, D loss: 0.717, G loss: 0.718\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 5/200, Batch: 228/390, D loss: 0.726, G loss: 0.714\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 5/200, Batch: 229/390, D loss: 0.714, G loss: 0.724\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 230/390, D loss: 0.744, G loss: 0.725\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 231/390, D loss: 0.728, G loss: 0.746\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 232/390, D loss: 0.740, G loss: 0.724\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 233/390, D loss: 0.735, G loss: 0.737\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 5/200, Batch: 234/390, D loss: 0.727, G loss: 0.739\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 235/390, D loss: 0.726, G loss: 0.744\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 236/390, D loss: 0.729, G loss: 0.734\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 237/390, D loss: 0.734, G loss: 0.743\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 5/200, Batch: 238/390, D loss: 0.748, G loss: 0.736\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 239/390, D loss: 0.751, G loss: 0.739\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 5/200, Batch: 240/390, D loss: 0.742, G loss: 0.734\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 5/200, Batch: 241/390, D loss: 0.730, G loss: 0.741\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 242/390, D loss: 0.733, G loss: 0.739\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 243/390, D loss: 0.724, G loss: 0.731\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 244/390, D loss: 0.729, G loss: 0.721\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 245/390, D loss: 0.748, G loss: 0.740\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 246/390, D loss: 0.740, G loss: 0.726\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 5/200, Batch: 247/390, D loss: 0.738, G loss: 0.725\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 248/390, D loss: 0.723, G loss: 0.732\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 249/390, D loss: 0.749, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 250/390, D loss: 0.737, G loss: 0.732\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 5/200, Batch: 251/390, D loss: 0.745, G loss: 0.731\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 252/390, D loss: 0.746, G loss: 0.739\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 253/390, D loss: 0.735, G loss: 0.734\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 5/200, Batch: 254/390, D loss: 0.729, G loss: 0.738\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 255/390, D loss: 0.737, G loss: 0.738\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 256/390, D loss: 0.737, G loss: 0.726\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 257/390, D loss: 0.728, G loss: 0.726\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 258/390, D loss: 0.723, G loss: 0.723\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 259/390, D loss: 0.721, G loss: 0.729\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 260/390, D loss: 0.716, G loss: 0.728\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 261/390, D loss: 0.723, G loss: 0.731\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 5/200, Batch: 262/390, D loss: 0.715, G loss: 0.715\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 5/200, Batch: 263/390, D loss: 0.728, G loss: 0.712\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 264/390, D loss: 0.716, G loss: 0.702\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 265/390, D loss: 0.695, G loss: 0.704\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 266/390, D loss: 0.707, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 267/390, D loss: 0.705, G loss: 0.702\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 268/390, D loss: 0.716, G loss: 0.701\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 269/390, D loss: 0.705, G loss: 0.693\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 270/390, D loss: 0.709, G loss: 0.695\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 271/390, D loss: 0.714, G loss: 0.699\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 272/390, D loss: 0.709, G loss: 0.700\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 273/390, D loss: 0.704, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 274/390, D loss: 0.710, G loss: 0.711\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 275/390, D loss: 0.696, G loss: 0.704\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 276/390, D loss: 0.708, G loss: 0.705\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 277/390, D loss: 0.706, G loss: 0.703\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 278/390, D loss: 0.707, G loss: 0.703\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 279/390, D loss: 0.705, G loss: 0.709\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 280/390, D loss: 0.705, G loss: 0.701\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 281/390, D loss: 0.694, G loss: 0.697\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 5/200, Batch: 282/390, D loss: 0.690, G loss: 0.690\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 283/390, D loss: 0.699, G loss: 0.691\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 5/200, Batch: 284/390, D loss: 0.698, G loss: 0.688\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 285/390, D loss: 0.685, G loss: 0.680\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 286/390, D loss: 0.697, G loss: 0.675\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 287/390, D loss: 0.699, G loss: 0.674\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 288/390, D loss: 0.676, G loss: 0.682\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 289/390, D loss: 0.674, G loss: 0.679\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 290/390, D loss: 0.690, G loss: 0.690\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 291/390, D loss: 0.683, G loss: 0.693\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 292/390, D loss: 0.690, G loss: 0.689\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 293/390, D loss: 0.677, G loss: 0.691\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 294/390, D loss: 0.679, G loss: 0.694\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 5/200, Batch: 295/390, D loss: 0.674, G loss: 0.695\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 296/390, D loss: 0.674, G loss: 0.699\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 297/390, D loss: 0.695, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 298/390, D loss: 0.694, G loss: 0.689\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 299/390, D loss: 0.687, G loss: 0.677\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 5/200, Batch: 300/390, D loss: 0.696, G loss: 0.683\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 301/390, D loss: 0.679, G loss: 0.680\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 302/390, D loss: 0.677, G loss: 0.684\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 303/390, D loss: 0.686, G loss: 0.689\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 304/390, D loss: 0.686, G loss: 0.679\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 305/390, D loss: 0.688, G loss: 0.689\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 306/390, D loss: 0.690, G loss: 0.696\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 307/390, D loss: 0.689, G loss: 0.699\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 308/390, D loss: 0.690, G loss: 0.699\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 309/390, D loss: 0.689, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 310/390, D loss: 0.685, G loss: 0.691\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 311/390, D loss: 0.684, G loss: 0.692\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 312/390, D loss: 0.693, G loss: 0.685\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 313/390, D loss: 0.683, G loss: 0.687\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 314/390, D loss: 0.699, G loss: 0.679\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 315/390, D loss: 0.692, G loss: 0.679\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 316/390, D loss: 0.675, G loss: 0.683\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 317/390, D loss: 0.680, G loss: 0.681\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 318/390, D loss: 0.686, G loss: 0.681\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 5/200, Batch: 319/390, D loss: 0.693, G loss: 0.686\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 320/390, D loss: 0.699, G loss: 0.690\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 321/390, D loss: 0.687, G loss: 0.691\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 322/390, D loss: 0.682, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 323/390, D loss: 0.682, G loss: 0.703\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 5/200, Batch: 324/390, D loss: 0.682, G loss: 0.712\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 5/200, Batch: 325/390, D loss: 0.694, G loss: 0.710\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 326/390, D loss: 0.692, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 327/390, D loss: 0.710, G loss: 0.700\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 328/390, D loss: 0.705, G loss: 0.694\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 5/200, Batch: 329/390, D loss: 0.702, G loss: 0.699\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 330/390, D loss: 0.690, G loss: 0.694\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 331/390, D loss: 0.698, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 332/390, D loss: 0.707, G loss: 0.696\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 333/390, D loss: 0.699, G loss: 0.704\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 334/390, D loss: 0.691, G loss: 0.701\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 335/390, D loss: 0.704, G loss: 0.714\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 336/390, D loss: 0.700, G loss: 0.707\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 337/390, D loss: 0.705, G loss: 0.720\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 5/200, Batch: 338/390, D loss: 0.695, G loss: 0.714\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 5/200, Batch: 339/390, D loss: 0.695, G loss: 0.722\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 340/390, D loss: 0.713, G loss: 0.722\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 341/390, D loss: 0.707, G loss: 0.730\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 342/390, D loss: 0.704, G loss: 0.729\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 5/200, Batch: 343/390, D loss: 0.712, G loss: 0.728\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 344/390, D loss: 0.718, G loss: 0.724\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 345/390, D loss: 0.719, G loss: 0.723\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 346/390, D loss: 0.689, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 347/390, D loss: 0.714, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 348/390, D loss: 0.707, G loss: 0.721\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 349/390, D loss: 0.704, G loss: 0.703\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 350/390, D loss: 0.714, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 351/390, D loss: 0.709, G loss: 0.696\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 352/390, D loss: 0.705, G loss: 0.708\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 5/200, Batch: 353/390, D loss: 0.700, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 354/390, D loss: 0.698, G loss: 0.704\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 355/390, D loss: 0.703, G loss: 0.708\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 356/390, D loss: 0.719, G loss: 0.715\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 357/390, D loss: 0.702, G loss: 0.724\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 358/390, D loss: 0.707, G loss: 0.723\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 359/390, D loss: 0.693, G loss: 0.716\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 360/390, D loss: 0.705, G loss: 0.715\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 361/390, D loss: 0.704, G loss: 0.718\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 362/390, D loss: 0.699, G loss: 0.731\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 5/200, Batch: 363/390, D loss: 0.697, G loss: 0.721\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 5/200, Batch: 364/390, D loss: 0.707, G loss: 0.702\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 365/390, D loss: 0.689, G loss: 0.700\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 366/390, D loss: 0.689, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 367/390, D loss: 0.699, G loss: 0.685\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 5/200, Batch: 368/390, D loss: 0.703, G loss: 0.687\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 369/390, D loss: 0.692, G loss: 0.682\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 370/390, D loss: 0.697, G loss: 0.684\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 371/390, D loss: 0.704, G loss: 0.687\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 372/390, D loss: 0.700, G loss: 0.687\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 5/200, Batch: 373/390, D loss: 0.699, G loss: 0.693\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 374/390, D loss: 0.685, G loss: 0.699\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 375/390, D loss: 0.706, G loss: 0.709\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 5/200, Batch: 376/390, D loss: 0.701, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 377/390, D loss: 0.703, G loss: 0.716\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 5/200, Batch: 378/390, D loss: 0.697, G loss: 0.729\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 379/390, D loss: 0.711, G loss: 0.719\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 380/390, D loss: 0.695, G loss: 0.719\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 381/390, D loss: 0.708, G loss: 0.705\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 5/200, Batch: 382/390, D loss: 0.702, G loss: 0.702\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch: 5/200, Batch: 383/390, D loss: 0.691, G loss: 0.696\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 5/200, Batch: 384/390, D loss: 0.683, G loss: 0.682\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 5/200, Batch: 385/390, D loss: 0.699, G loss: 0.683\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 5/200, Batch: 386/390, D loss: 0.678, G loss: 0.677\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 5/200, Batch: 387/390, D loss: 0.692, G loss: 0.681\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 5/200, Batch: 388/390, D loss: 0.682, G loss: 0.679\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 5/200, Batch: 389/390, D loss: 0.687, G loss: 0.684\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 5/200, Batch: 390/390, D loss: 0.671, G loss: 0.692\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 1/390, D loss: 0.692, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 2/390, D loss: 0.678, G loss: 0.707\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 3/390, D loss: 0.676, G loss: 0.702\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 4/390, D loss: 0.675, G loss: 0.708\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 5/390, D loss: 0.679, G loss: 0.699\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 6/390, D loss: 0.674, G loss: 0.684\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 7/390, D loss: 0.677, G loss: 0.685\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 8/390, D loss: 0.674, G loss: 0.686\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 9/390, D loss: 0.690, G loss: 0.682\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 10/390, D loss: 0.693, G loss: 0.692\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 6/200, Batch: 11/390, D loss: 0.690, G loss: 0.712\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 12/390, D loss: 0.677, G loss: 0.697\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 13/390, D loss: 0.679, G loss: 0.691\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 14/390, D loss: 0.689, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 15/390, D loss: 0.680, G loss: 0.714\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 6/200, Batch: 16/390, D loss: 0.705, G loss: 0.710\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 17/390, D loss: 0.687, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 18/390, D loss: 0.690, G loss: 0.711\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 19/390, D loss: 0.686, G loss: 0.700\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 20/390, D loss: 0.674, G loss: 0.704\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 21/390, D loss: 0.683, G loss: 0.703\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 6/200, Batch: 22/390, D loss: 0.708, G loss: 0.684\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 23/390, D loss: 0.695, G loss: 0.687\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 24/390, D loss: 0.685, G loss: 0.674\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 6/200, Batch: 25/390, D loss: 0.689, G loss: 0.676\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 26/390, D loss: 0.691, G loss: 0.679\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 27/390, D loss: 0.680, G loss: 0.682\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 28/390, D loss: 0.672, G loss: 0.688\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 29/390, D loss: 0.692, G loss: 0.698\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 6/200, Batch: 30/390, D loss: 0.685, G loss: 0.686\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 31/390, D loss: 0.698, G loss: 0.691\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 32/390, D loss: 0.682, G loss: 0.688\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 33/390, D loss: 0.699, G loss: 0.686\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 34/390, D loss: 0.678, G loss: 0.690\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 35/390, D loss: 0.686, G loss: 0.703\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 36/390, D loss: 0.682, G loss: 0.695\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 37/390, D loss: 0.690, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 38/390, D loss: 0.695, G loss: 0.705\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 39/390, D loss: 0.701, G loss: 0.709\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 40/390, D loss: 0.706, G loss: 0.716\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 41/390, D loss: 0.703, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 42/390, D loss: 0.692, G loss: 0.711\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 43/390, D loss: 0.695, G loss: 0.711\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 44/390, D loss: 0.709, G loss: 0.707\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 45/390, D loss: 0.704, G loss: 0.727\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 46/390, D loss: 0.704, G loss: 0.720\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 47/390, D loss: 0.701, G loss: 0.724\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 48/390, D loss: 0.717, G loss: 0.718\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 49/390, D loss: 0.704, G loss: 0.711\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 50/390, D loss: 0.719, G loss: 0.727\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 51/390, D loss: 0.717, G loss: 0.720\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 52/390, D loss: 0.706, G loss: 0.714\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 6/200, Batch: 53/390, D loss: 0.700, G loss: 0.716\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 54/390, D loss: 0.715, G loss: 0.728\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 55/390, D loss: 0.710, G loss: 0.728\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 56/390, D loss: 0.724, G loss: 0.721\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 57/390, D loss: 0.718, G loss: 0.727\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 58/390, D loss: 0.724, G loss: 0.736\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 59/390, D loss: 0.708, G loss: 0.731\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 60/390, D loss: 0.702, G loss: 0.733\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 61/390, D loss: 0.722, G loss: 0.723\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 6/200, Batch: 62/390, D loss: 0.712, G loss: 0.725\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 6/200, Batch: 63/390, D loss: 0.716, G loss: 0.720\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 64/390, D loss: 0.712, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 65/390, D loss: 0.711, G loss: 0.736\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 66/390, D loss: 0.711, G loss: 0.736\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 67/390, D loss: 0.705, G loss: 0.731\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 68/390, D loss: 0.720, G loss: 0.751\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 69/390, D loss: 0.745, G loss: 0.741\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 70/390, D loss: 0.702, G loss: 0.748\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 71/390, D loss: 0.733, G loss: 0.729\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 72/390, D loss: 0.717, G loss: 0.733\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 73/390, D loss: 0.701, G loss: 0.725\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 74/390, D loss: 0.700, G loss: 0.717\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 75/390, D loss: 0.697, G loss: 0.707\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 76/390, D loss: 0.698, G loss: 0.702\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 77/390, D loss: 0.699, G loss: 0.688\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 78/390, D loss: 0.693, G loss: 0.702\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 79/390, D loss: 0.695, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 80/390, D loss: 0.701, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 81/390, D loss: 0.697, G loss: 0.712\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 82/390, D loss: 0.698, G loss: 0.726\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 83/390, D loss: 0.695, G loss: 0.740\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 84/390, D loss: 0.698, G loss: 0.744\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 6/200, Batch: 85/390, D loss: 0.719, G loss: 0.754\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 86/390, D loss: 0.705, G loss: 0.757\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 87/390, D loss: 0.698, G loss: 0.765\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 88/390, D loss: 0.714, G loss: 0.761\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 89/390, D loss: 0.729, G loss: 0.752\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 6/200, Batch: 90/390, D loss: 0.693, G loss: 0.736\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 91/390, D loss: 0.689, G loss: 0.717\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 92/390, D loss: 0.706, G loss: 0.693\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 93/390, D loss: 0.696, G loss: 0.686\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 94/390, D loss: 0.705, G loss: 0.672\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 95/390, D loss: 0.681, G loss: 0.664\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 96/390, D loss: 0.677, G loss: 0.657\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 97/390, D loss: 0.698, G loss: 0.669\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 98/390, D loss: 0.688, G loss: 0.667\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 99/390, D loss: 0.694, G loss: 0.701\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 100/390, D loss: 0.692, G loss: 0.730\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 101/390, D loss: 0.694, G loss: 0.749\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 102/390, D loss: 0.688, G loss: 0.803\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 103/390, D loss: 0.692, G loss: 0.791\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 104/390, D loss: 0.702, G loss: 0.781\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 105/390, D loss: 0.680, G loss: 0.750\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 106/390, D loss: 0.709, G loss: 0.718\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 107/390, D loss: 0.681, G loss: 0.698\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 108/390, D loss: 0.692, G loss: 0.696\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 109/390, D loss: 0.691, G loss: 0.674\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 110/390, D loss: 0.721, G loss: 0.666\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 111/390, D loss: 0.687, G loss: 0.657\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 112/390, D loss: 0.687, G loss: 0.660\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 113/390, D loss: 0.680, G loss: 0.666\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 6/200, Batch: 114/390, D loss: 0.675, G loss: 0.673\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 115/390, D loss: 0.688, G loss: 0.678\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 116/390, D loss: 0.683, G loss: 0.689\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 117/390, D loss: 0.674, G loss: 0.713\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 118/390, D loss: 0.693, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 119/390, D loss: 0.693, G loss: 0.716\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 6/200, Batch: 120/390, D loss: 0.690, G loss: 0.730\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 121/390, D loss: 0.687, G loss: 0.737\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 122/390, D loss: 0.687, G loss: 0.736\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 6/200, Batch: 123/390, D loss: 0.687, G loss: 0.743\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 6/200, Batch: 124/390, D loss: 0.734, G loss: 0.745\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 125/390, D loss: 0.683, G loss: 0.734\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 126/390, D loss: 0.703, G loss: 0.724\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 127/390, D loss: 0.702, G loss: 0.714\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 6/200, Batch: 128/390, D loss: 0.697, G loss: 0.701\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 129/390, D loss: 0.695, G loss: 0.705\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 6/200, Batch: 130/390, D loss: 0.686, G loss: 0.686\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 131/390, D loss: 0.690, G loss: 0.688\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 132/390, D loss: 0.679, G loss: 0.687\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 133/390, D loss: 0.703, G loss: 0.682\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 134/390, D loss: 0.686, G loss: 0.688\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 135/390, D loss: 0.691, G loss: 0.688\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 136/390, D loss: 0.677, G loss: 0.687\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 137/390, D loss: 0.682, G loss: 0.702\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 138/390, D loss: 0.692, G loss: 0.706\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 139/390, D loss: 0.676, G loss: 0.703\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 140/390, D loss: 0.680, G loss: 0.710\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 141/390, D loss: 0.694, G loss: 0.711\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 142/390, D loss: 0.698, G loss: 0.733\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 6/200, Batch: 143/390, D loss: 0.686, G loss: 0.712\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 144/390, D loss: 0.698, G loss: 0.716\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 145/390, D loss: 0.701, G loss: 0.724\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 146/390, D loss: 0.697, G loss: 0.711\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 147/390, D loss: 0.702, G loss: 0.724\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 148/390, D loss: 0.695, G loss: 0.719\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 149/390, D loss: 0.686, G loss: 0.728\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 6/200, Batch: 150/390, D loss: 0.712, G loss: 0.731\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 151/390, D loss: 0.706, G loss: 0.728\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 152/390, D loss: 0.682, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 153/390, D loss: 0.691, G loss: 0.712\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 154/390, D loss: 0.709, G loss: 0.706\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 6/200, Batch: 155/390, D loss: 0.708, G loss: 0.695\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 156/390, D loss: 0.696, G loss: 0.681\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 6/200, Batch: 157/390, D loss: 0.690, G loss: 0.684\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 158/390, D loss: 0.669, G loss: 0.682\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 6/200, Batch: 159/390, D loss: 0.693, G loss: 0.676\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 160/390, D loss: 0.669, G loss: 0.687\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 161/390, D loss: 0.682, G loss: 0.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 162/390, D loss: 0.688, G loss: 0.689\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 163/390, D loss: 0.688, G loss: 0.692\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 164/390, D loss: 0.684, G loss: 0.700\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 165/390, D loss: 0.691, G loss: 0.704\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 166/390, D loss: 0.692, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 167/390, D loss: 0.680, G loss: 0.704\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 168/390, D loss: 0.685, G loss: 0.695\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 169/390, D loss: 0.662, G loss: 0.704\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 170/390, D loss: 0.680, G loss: 0.694\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 171/390, D loss: 0.667, G loss: 0.700\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 172/390, D loss: 0.684, G loss: 0.691\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 6/200, Batch: 173/390, D loss: 0.682, G loss: 0.682\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 174/390, D loss: 0.682, G loss: 0.684\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 175/390, D loss: 0.668, G loss: 0.687\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 6/200, Batch: 176/390, D loss: 0.684, G loss: 0.678\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 177/390, D loss: 0.678, G loss: 0.677\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 178/390, D loss: 0.682, G loss: 0.674\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 179/390, D loss: 0.677, G loss: 0.687\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 180/390, D loss: 0.686, G loss: 0.683\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 181/390, D loss: 0.682, G loss: 0.683\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 182/390, D loss: 0.682, G loss: 0.694\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 183/390, D loss: 0.684, G loss: 0.681\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 184/390, D loss: 0.680, G loss: 0.694\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 185/390, D loss: 0.682, G loss: 0.687\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 186/390, D loss: 0.679, G loss: 0.699\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 187/390, D loss: 0.682, G loss: 0.686\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 188/390, D loss: 0.669, G loss: 0.701\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 6/200, Batch: 189/390, D loss: 0.690, G loss: 0.702\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 190/390, D loss: 0.667, G loss: 0.717\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 191/390, D loss: 0.682, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 192/390, D loss: 0.684, G loss: 0.709\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 193/390, D loss: 0.692, G loss: 0.690\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 194/390, D loss: 0.704, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 195/390, D loss: 0.684, G loss: 0.704\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 196/390, D loss: 0.695, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 197/390, D loss: 0.694, G loss: 0.692\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 198/390, D loss: 0.676, G loss: 0.691\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 199/390, D loss: 0.695, G loss: 0.716\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 200/390, D loss: 0.692, G loss: 0.707\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 201/390, D loss: 0.697, G loss: 0.714\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 6/200, Batch: 202/390, D loss: 0.694, G loss: 0.718\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 203/390, D loss: 0.688, G loss: 0.717\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 204/390, D loss: 0.707, G loss: 0.718\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 205/390, D loss: 0.705, G loss: 0.719\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 206/390, D loss: 0.695, G loss: 0.726\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 207/390, D loss: 0.681, G loss: 0.720\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 6/200, Batch: 208/390, D loss: 0.706, G loss: 0.712\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 6/200, Batch: 209/390, D loss: 0.716, G loss: 0.710\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 210/390, D loss: 0.710, G loss: 0.709\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 211/390, D loss: 0.712, G loss: 0.710\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 6/200, Batch: 212/390, D loss: 0.704, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 213/390, D loss: 0.724, G loss: 0.705\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 214/390, D loss: 0.698, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 215/390, D loss: 0.699, G loss: 0.705\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 216/390, D loss: 0.681, G loss: 0.702\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 217/390, D loss: 0.700, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 218/390, D loss: 0.692, G loss: 0.694\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 219/390, D loss: 0.704, G loss: 0.706\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 220/390, D loss: 0.689, G loss: 0.707\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 221/390, D loss: 0.699, G loss: 0.712\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 222/390, D loss: 0.694, G loss: 0.698\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 223/390, D loss: 0.704, G loss: 0.698\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 224/390, D loss: 0.695, G loss: 0.688\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 6/200, Batch: 225/390, D loss: 0.704, G loss: 0.710\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 226/390, D loss: 0.695, G loss: 0.708\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 227/390, D loss: 0.707, G loss: 0.712\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 228/390, D loss: 0.722, G loss: 0.703\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 229/390, D loss: 0.724, G loss: 0.710\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 230/390, D loss: 0.695, G loss: 0.716\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 6/200, Batch: 231/390, D loss: 0.697, G loss: 0.701\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 232/390, D loss: 0.687, G loss: 0.701\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch: 6/200, Batch: 233/390, D loss: 0.704, G loss: 0.710\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 6/200, Batch: 234/390, D loss: 0.697, G loss: 0.702\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 6/200, Batch: 235/390, D loss: 0.710, G loss: 0.723\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 236/390, D loss: 0.685, G loss: 0.689\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 237/390, D loss: 0.721, G loss: 0.705\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 238/390, D loss: 0.683, G loss: 0.701\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 239/390, D loss: 0.700, G loss: 0.690\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 240/390, D loss: 0.699, G loss: 0.694\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 241/390, D loss: 0.704, G loss: 0.696\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Epoch: 6/200, Batch: 242/390, D loss: 0.685, G loss: 0.689\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 243/390, D loss: 0.694, G loss: 0.704\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 244/390, D loss: 0.694, G loss: 0.701\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 245/390, D loss: 0.704, G loss: 0.701\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 246/390, D loss: 0.703, G loss: 0.699\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 6/200, Batch: 247/390, D loss: 0.681, G loss: 0.710\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 6/200, Batch: 248/390, D loss: 0.695, G loss: 0.710\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 249/390, D loss: 0.694, G loss: 0.711\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 250/390, D loss: 0.704, G loss: 0.710\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 251/390, D loss: 0.684, G loss: 0.711\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 252/390, D loss: 0.700, G loss: 0.716\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 6/200, Batch: 253/390, D loss: 0.702, G loss: 0.700\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 254/390, D loss: 0.699, G loss: 0.704\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 6/200, Batch: 255/390, D loss: 0.708, G loss: 0.693\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 256/390, D loss: 0.704, G loss: 0.699\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 257/390, D loss: 0.690, G loss: 0.689\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 258/390, D loss: 0.701, G loss: 0.689\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 259/390, D loss: 0.686, G loss: 0.697\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 260/390, D loss: 0.697, G loss: 0.685\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 261/390, D loss: 0.694, G loss: 0.696\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 262/390, D loss: 0.708, G loss: 0.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 263/390, D loss: 0.688, G loss: 0.688\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 264/390, D loss: 0.691, G loss: 0.683\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 265/390, D loss: 0.681, G loss: 0.702\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 266/390, D loss: 0.687, G loss: 0.711\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 267/390, D loss: 0.703, G loss: 0.705\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 268/390, D loss: 0.700, G loss: 0.697\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 269/390, D loss: 0.682, G loss: 0.708\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 270/390, D loss: 0.688, G loss: 0.695\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 271/390, D loss: 0.678, G loss: 0.690\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 272/390, D loss: 0.700, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 273/390, D loss: 0.697, G loss: 0.687\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 274/390, D loss: 0.683, G loss: 0.671\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 275/390, D loss: 0.685, G loss: 0.689\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 6/200, Batch: 276/390, D loss: 0.699, G loss: 0.693\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 6/200, Batch: 277/390, D loss: 0.679, G loss: 0.674\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 278/390, D loss: 0.674, G loss: 0.695\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 279/390, D loss: 0.681, G loss: 0.690\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 280/390, D loss: 0.682, G loss: 0.701\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 281/390, D loss: 0.698, G loss: 0.708\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 6/200, Batch: 282/390, D loss: 0.697, G loss: 0.701\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 283/390, D loss: 0.697, G loss: 0.704\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 284/390, D loss: 0.701, G loss: 0.703\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 285/390, D loss: 0.701, G loss: 0.692\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 286/390, D loss: 0.698, G loss: 0.704\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 287/390, D loss: 0.675, G loss: 0.695\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 288/390, D loss: 0.686, G loss: 0.689\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 289/390, D loss: 0.691, G loss: 0.693\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 290/390, D loss: 0.686, G loss: 0.695\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 291/390, D loss: 0.687, G loss: 0.687\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 292/390, D loss: 0.689, G loss: 0.693\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 6/200, Batch: 293/390, D loss: 0.688, G loss: 0.694\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 6/200, Batch: 294/390, D loss: 0.685, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 295/390, D loss: 0.701, G loss: 0.698\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 296/390, D loss: 0.687, G loss: 0.709\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 297/390, D loss: 0.680, G loss: 0.706\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 298/390, D loss: 0.691, G loss: 0.701\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 299/390, D loss: 0.683, G loss: 0.695\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 300/390, D loss: 0.670, G loss: 0.681\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 301/390, D loss: 0.673, G loss: 0.697\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 302/390, D loss: 0.678, G loss: 0.688\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 303/390, D loss: 0.675, G loss: 0.695\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 6/200, Batch: 304/390, D loss: 0.671, G loss: 0.689\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 305/390, D loss: 0.692, G loss: 0.695\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 306/390, D loss: 0.682, G loss: 0.696\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 307/390, D loss: 0.685, G loss: 0.696\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 308/390, D loss: 0.690, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 309/390, D loss: 0.690, G loss: 0.706\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 6/200, Batch: 310/390, D loss: 0.689, G loss: 0.708\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 311/390, D loss: 0.686, G loss: 0.719\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 312/390, D loss: 0.674, G loss: 0.706\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 313/390, D loss: 0.706, G loss: 0.704\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 314/390, D loss: 0.692, G loss: 0.705\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 315/390, D loss: 0.697, G loss: 0.709\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 316/390, D loss: 0.699, G loss: 0.694\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 317/390, D loss: 0.692, G loss: 0.696\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 318/390, D loss: 0.678, G loss: 0.691\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 319/390, D loss: 0.682, G loss: 0.687\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 320/390, D loss: 0.683, G loss: 0.685\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 321/390, D loss: 0.702, G loss: 0.683\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 322/390, D loss: 0.697, G loss: 0.701\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 323/390, D loss: 0.699, G loss: 0.695\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 324/390, D loss: 0.695, G loss: 0.704\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 6/200, Batch: 325/390, D loss: 0.697, G loss: 0.704\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 326/390, D loss: 0.690, G loss: 0.709\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 327/390, D loss: 0.700, G loss: 0.726\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 328/390, D loss: 0.695, G loss: 0.725\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 329/390, D loss: 0.698, G loss: 0.704\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 6/200, Batch: 330/390, D loss: 0.687, G loss: 0.723\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 331/390, D loss: 0.695, G loss: 0.716\n",
      "2/2 [==============================] - 0s 19ms/step\n",
      "Epoch: 6/200, Batch: 332/390, D loss: 0.691, G loss: 0.705\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 333/390, D loss: 0.695, G loss: 0.704\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 334/390, D loss: 0.696, G loss: 0.694\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 335/390, D loss: 0.704, G loss: 0.688\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 336/390, D loss: 0.701, G loss: 0.685\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 6/200, Batch: 337/390, D loss: 0.700, G loss: 0.691\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 338/390, D loss: 0.676, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 339/390, D loss: 0.702, G loss: 0.709\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 340/390, D loss: 0.700, G loss: 0.699\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 341/390, D loss: 0.686, G loss: 0.700\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 342/390, D loss: 0.692, G loss: 0.730\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 343/390, D loss: 0.712, G loss: 0.714\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 6/200, Batch: 344/390, D loss: 0.682, G loss: 0.731\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 345/390, D loss: 0.681, G loss: 0.722\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 346/390, D loss: 0.686, G loss: 0.729\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 347/390, D loss: 0.670, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 348/390, D loss: 0.689, G loss: 0.700\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 349/390, D loss: 0.704, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 350/390, D loss: 0.691, G loss: 0.678\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 351/390, D loss: 0.684, G loss: 0.676\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 352/390, D loss: 0.696, G loss: 0.672\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 353/390, D loss: 0.705, G loss: 0.686\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 354/390, D loss: 0.699, G loss: 0.679\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 355/390, D loss: 0.687, G loss: 0.696\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 356/390, D loss: 0.702, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 357/390, D loss: 0.701, G loss: 0.723\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 6/200, Batch: 358/390, D loss: 0.699, G loss: 0.737\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 359/390, D loss: 0.703, G loss: 0.738\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 360/390, D loss: 0.705, G loss: 0.744\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 361/390, D loss: 0.701, G loss: 0.752\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 362/390, D loss: 0.705, G loss: 0.739\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 363/390, D loss: 0.721, G loss: 0.744\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 364/390, D loss: 0.721, G loss: 0.727\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 365/390, D loss: 0.719, G loss: 0.719\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 366/390, D loss: 0.707, G loss: 0.706\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 6/200, Batch: 367/390, D loss: 0.677, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 368/390, D loss: 0.679, G loss: 0.688\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 6/200, Batch: 369/390, D loss: 0.692, G loss: 0.679\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 370/390, D loss: 0.690, G loss: 0.674\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 371/390, D loss: 0.702, G loss: 0.671\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 372/390, D loss: 0.688, G loss: 0.682\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 373/390, D loss: 0.687, G loss: 0.676\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 374/390, D loss: 0.698, G loss: 0.698\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 6/200, Batch: 375/390, D loss: 0.696, G loss: 0.715\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 6/200, Batch: 376/390, D loss: 0.700, G loss: 0.727\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 6/200, Batch: 377/390, D loss: 0.702, G loss: 0.735\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 378/390, D loss: 0.706, G loss: 0.744\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 379/390, D loss: 0.681, G loss: 0.738\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 380/390, D loss: 0.698, G loss: 0.726\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 381/390, D loss: 0.671, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 382/390, D loss: 0.686, G loss: 0.711\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 6/200, Batch: 383/390, D loss: 0.691, G loss: 0.698\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 6/200, Batch: 384/390, D loss: 0.709, G loss: 0.687\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 385/390, D loss: 0.690, G loss: 0.684\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 386/390, D loss: 0.674, G loss: 0.674\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 6/200, Batch: 387/390, D loss: 0.678, G loss: 0.684\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 6/200, Batch: 388/390, D loss: 0.683, G loss: 0.675\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 6/200, Batch: 389/390, D loss: 0.688, G loss: 0.678\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 6/200, Batch: 390/390, D loss: 0.689, G loss: 0.681\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 1/390, D loss: 0.689, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 2/390, D loss: 0.687, G loss: 0.710\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 3/390, D loss: 0.699, G loss: 0.712\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 4/390, D loss: 0.701, G loss: 0.728\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 5/390, D loss: 0.699, G loss: 0.739\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 7/200, Batch: 6/390, D loss: 0.700, G loss: 0.738\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 7/200, Batch: 7/390, D loss: 0.696, G loss: 0.734\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 8/390, D loss: 0.692, G loss: 0.743\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 9/390, D loss: 0.701, G loss: 0.734\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 10/390, D loss: 0.701, G loss: 0.737\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 11/390, D loss: 0.716, G loss: 0.719\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 12/390, D loss: 0.705, G loss: 0.715\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 13/390, D loss: 0.706, G loss: 0.707\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 7/200, Batch: 14/390, D loss: 0.692, G loss: 0.695\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 7/200, Batch: 15/390, D loss: 0.714, G loss: 0.692\n",
      "2/2 [==============================] - 0s 701us/step\n",
      "Epoch: 7/200, Batch: 16/390, D loss: 0.712, G loss: 0.689\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 7/200, Batch: 17/390, D loss: 0.694, G loss: 0.682\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 18/390, D loss: 0.696, G loss: 0.678\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 7/200, Batch: 19/390, D loss: 0.711, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 20/390, D loss: 0.698, G loss: 0.705\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 7/200, Batch: 21/390, D loss: 0.700, G loss: 0.711\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 22/390, D loss: 0.699, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 23/390, D loss: 0.703, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 24/390, D loss: 0.711, G loss: 0.712\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 25/390, D loss: 0.698, G loss: 0.740\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 26/390, D loss: 0.691, G loss: 0.727\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 27/390, D loss: 0.685, G loss: 0.721\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 28/390, D loss: 0.699, G loss: 0.727\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 29/390, D loss: 0.715, G loss: 0.704\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 30/390, D loss: 0.699, G loss: 0.716\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 31/390, D loss: 0.713, G loss: 0.696\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 32/390, D loss: 0.700, G loss: 0.702\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 7/200, Batch: 33/390, D loss: 0.683, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 34/390, D loss: 0.693, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 35/390, D loss: 0.695, G loss: 0.703\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 36/390, D loss: 0.703, G loss: 0.695\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 37/390, D loss: 0.692, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 38/390, D loss: 0.710, G loss: 0.704\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 39/390, D loss: 0.702, G loss: 0.710\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 40/390, D loss: 0.703, G loss: 0.719\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 41/390, D loss: 0.721, G loss: 0.716\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 42/390, D loss: 0.693, G loss: 0.716\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 43/390, D loss: 0.708, G loss: 0.728\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 44/390, D loss: 0.697, G loss: 0.733\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 7/200, Batch: 45/390, D loss: 0.701, G loss: 0.717\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 46/390, D loss: 0.703, G loss: 0.729\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 7/200, Batch: 47/390, D loss: 0.689, G loss: 0.732\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 7/200, Batch: 48/390, D loss: 0.707, G loss: 0.722\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 49/390, D loss: 0.691, G loss: 0.715\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 50/390, D loss: 0.702, G loss: 0.704\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 51/390, D loss: 0.711, G loss: 0.709\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 52/390, D loss: 0.692, G loss: 0.697\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 53/390, D loss: 0.689, G loss: 0.689\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 54/390, D loss: 0.691, G loss: 0.701\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 55/390, D loss: 0.689, G loss: 0.683\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 56/390, D loss: 0.699, G loss: 0.683\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 57/390, D loss: 0.689, G loss: 0.691\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 58/390, D loss: 0.690, G loss: 0.686\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 59/390, D loss: 0.696, G loss: 0.683\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 7/200, Batch: 60/390, D loss: 0.674, G loss: 0.688\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 61/390, D loss: 0.668, G loss: 0.691\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 7/200, Batch: 62/390, D loss: 0.692, G loss: 0.687\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 63/390, D loss: 0.688, G loss: 0.691\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 64/390, D loss: 0.671, G loss: 0.702\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 65/390, D loss: 0.679, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 66/390, D loss: 0.682, G loss: 0.721\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 7/200, Batch: 67/390, D loss: 0.682, G loss: 0.721\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 68/390, D loss: 0.708, G loss: 0.726\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 69/390, D loss: 0.688, G loss: 0.725\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 70/390, D loss: 0.697, G loss: 0.710\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 7/200, Batch: 71/390, D loss: 0.678, G loss: 0.694\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 7/200, Batch: 72/390, D loss: 0.684, G loss: 0.684\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 73/390, D loss: 0.674, G loss: 0.679\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 7/200, Batch: 74/390, D loss: 0.694, G loss: 0.673\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 75/390, D loss: 0.680, G loss: 0.669\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 76/390, D loss: 0.687, G loss: 0.678\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 77/390, D loss: 0.673, G loss: 0.674\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 78/390, D loss: 0.663, G loss: 0.674\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 79/390, D loss: 0.672, G loss: 0.689\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 80/390, D loss: 0.693, G loss: 0.699\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 81/390, D loss: 0.676, G loss: 0.720\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 82/390, D loss: 0.693, G loss: 0.711\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 83/390, D loss: 0.707, G loss: 0.729\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 84/390, D loss: 0.690, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 85/390, D loss: 0.692, G loss: 0.725\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 7/200, Batch: 86/390, D loss: 0.701, G loss: 0.709\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 87/390, D loss: 0.707, G loss: 0.705\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 88/390, D loss: 0.696, G loss: 0.698\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 89/390, D loss: 0.697, G loss: 0.692\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 90/390, D loss: 0.696, G loss: 0.690\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 91/390, D loss: 0.693, G loss: 0.692\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 92/390, D loss: 0.686, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 93/390, D loss: 0.689, G loss: 0.698\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 94/390, D loss: 0.716, G loss: 0.696\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 95/390, D loss: 0.689, G loss: 0.701\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 96/390, D loss: 0.713, G loss: 0.703\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 97/390, D loss: 0.704, G loss: 0.706\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 98/390, D loss: 0.690, G loss: 0.706\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 99/390, D loss: 0.704, G loss: 0.723\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 100/390, D loss: 0.715, G loss: 0.716\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 101/390, D loss: 0.717, G loss: 0.713\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 102/390, D loss: 0.715, G loss: 0.725\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 103/390, D loss: 0.725, G loss: 0.734\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 104/390, D loss: 0.723, G loss: 0.726\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 105/390, D loss: 0.701, G loss: 0.725\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 106/390, D loss: 0.725, G loss: 0.724\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 107/390, D loss: 0.700, G loss: 0.718\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 108/390, D loss: 0.709, G loss: 0.727\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 7/200, Batch: 109/390, D loss: 0.706, G loss: 0.715\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 110/390, D loss: 0.690, G loss: 0.703\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 111/390, D loss: 0.710, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 112/390, D loss: 0.703, G loss: 0.701\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 113/390, D loss: 0.706, G loss: 0.703\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 114/390, D loss: 0.704, G loss: 0.702\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 115/390, D loss: 0.715, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 116/390, D loss: 0.695, G loss: 0.710\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 117/390, D loss: 0.717, G loss: 0.699\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 7/200, Batch: 118/390, D loss: 0.696, G loss: 0.723\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 119/390, D loss: 0.699, G loss: 0.709\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 120/390, D loss: 0.710, G loss: 0.723\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 121/390, D loss: 0.713, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 122/390, D loss: 0.694, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 123/390, D loss: 0.698, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 124/390, D loss: 0.722, G loss: 0.713\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 125/390, D loss: 0.704, G loss: 0.702\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 126/390, D loss: 0.703, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 127/390, D loss: 0.704, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 128/390, D loss: 0.693, G loss: 0.701\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 129/390, D loss: 0.697, G loss: 0.701\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 130/390, D loss: 0.696, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 131/390, D loss: 0.684, G loss: 0.693\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 7/200, Batch: 132/390, D loss: 0.695, G loss: 0.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 133/390, D loss: 0.680, G loss: 0.691\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 134/390, D loss: 0.686, G loss: 0.689\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 135/390, D loss: 0.683, G loss: 0.689\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 136/390, D loss: 0.678, G loss: 0.692\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 137/390, D loss: 0.693, G loss: 0.702\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 138/390, D loss: 0.685, G loss: 0.697\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 139/390, D loss: 0.695, G loss: 0.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 140/390, D loss: 0.690, G loss: 0.700\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 7/200, Batch: 141/390, D loss: 0.692, G loss: 0.718\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 7/200, Batch: 142/390, D loss: 0.699, G loss: 0.716\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 7/200, Batch: 143/390, D loss: 0.701, G loss: 0.724\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 144/390, D loss: 0.685, G loss: 0.720\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 7/200, Batch: 145/390, D loss: 0.684, G loss: 0.726\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 146/390, D loss: 0.704, G loss: 0.716\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 147/390, D loss: 0.687, G loss: 0.714\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 148/390, D loss: 0.694, G loss: 0.698\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 7/200, Batch: 149/390, D loss: 0.712, G loss: 0.691\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 150/390, D loss: 0.688, G loss: 0.687\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 151/390, D loss: 0.692, G loss: 0.691\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 152/390, D loss: 0.690, G loss: 0.679\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 153/390, D loss: 0.693, G loss: 0.683\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 7/200, Batch: 154/390, D loss: 0.695, G loss: 0.690\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 155/390, D loss: 0.692, G loss: 0.688\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 156/390, D loss: 0.689, G loss: 0.690\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 7/200, Batch: 157/390, D loss: 0.693, G loss: 0.710\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 158/390, D loss: 0.708, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 159/390, D loss: 0.700, G loss: 0.709\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 160/390, D loss: 0.696, G loss: 0.707\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 7/200, Batch: 161/390, D loss: 0.692, G loss: 0.708\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 162/390, D loss: 0.707, G loss: 0.707\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 7/200, Batch: 163/390, D loss: 0.687, G loss: 0.703\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 7/200, Batch: 164/390, D loss: 0.674, G loss: 0.698\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 7/200, Batch: 165/390, D loss: 0.687, G loss: 0.693\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 166/390, D loss: 0.676, G loss: 0.685\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 167/390, D loss: 0.687, G loss: 0.688\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 7/200, Batch: 168/390, D loss: 0.692, G loss: 0.691\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 7/200, Batch: 169/390, D loss: 0.700, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 170/390, D loss: 0.710, G loss: 0.695\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 171/390, D loss: 0.689, G loss: 0.707\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 172/390, D loss: 0.684, G loss: 0.697\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 7/200, Batch: 173/390, D loss: 0.700, G loss: 0.708\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 7/200, Batch: 174/390, D loss: 0.696, G loss: 0.710\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 175/390, D loss: 0.683, G loss: 0.711\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 7/200, Batch: 176/390, D loss: 0.698, G loss: 0.712\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 177/390, D loss: 0.688, G loss: 0.710\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 178/390, D loss: 0.700, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 179/390, D loss: 0.695, G loss: 0.701\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 7/200, Batch: 180/390, D loss: 0.691, G loss: 0.695\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 181/390, D loss: 0.699, G loss: 0.702\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 182/390, D loss: 0.684, G loss: 0.697\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 7/200, Batch: 183/390, D loss: 0.697, G loss: 0.709\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 184/390, D loss: 0.706, G loss: 0.708\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 7/200, Batch: 185/390, D loss: 0.700, G loss: 0.714\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 7/200, Batch: 186/390, D loss: 0.706, G loss: 0.707\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 7/200, Batch: 187/390, D loss: 0.698, G loss: 0.705\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 188/390, D loss: 0.705, G loss: 0.697\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 189/390, D loss: 0.693, G loss: 0.697\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 190/390, D loss: 0.697, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 191/390, D loss: 0.681, G loss: 0.688\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 192/390, D loss: 0.684, G loss: 0.688\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 193/390, D loss: 0.695, G loss: 0.694\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 7/200, Batch: 194/390, D loss: 0.684, G loss: 0.690\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 7/200, Batch: 195/390, D loss: 0.704, G loss: 0.705\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 196/390, D loss: 0.698, G loss: 0.710\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 197/390, D loss: 0.681, G loss: 0.705\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 7/200, Batch: 198/390, D loss: 0.700, G loss: 0.720\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 199/390, D loss: 0.699, G loss: 0.714\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 200/390, D loss: 0.709, G loss: 0.710\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 201/390, D loss: 0.689, G loss: 0.704\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 202/390, D loss: 0.701, G loss: 0.697\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 7/200, Batch: 203/390, D loss: 0.697, G loss: 0.690\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 204/390, D loss: 0.696, G loss: 0.694\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 205/390, D loss: 0.700, G loss: 0.689\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 206/390, D loss: 0.690, G loss: 0.702\n",
      "2/2 [==============================] - 0s 705us/step\n",
      "Epoch: 7/200, Batch: 207/390, D loss: 0.699, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 208/390, D loss: 0.694, G loss: 0.716\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 209/390, D loss: 0.712, G loss: 0.703\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 210/390, D loss: 0.695, G loss: 0.703\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 211/390, D loss: 0.691, G loss: 0.711\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 212/390, D loss: 0.686, G loss: 0.711\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 213/390, D loss: 0.694, G loss: 0.714\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 214/390, D loss: 0.688, G loss: 0.692\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 215/390, D loss: 0.694, G loss: 0.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 216/390, D loss: 0.687, G loss: 0.686\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 217/390, D loss: 0.699, G loss: 0.677\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 218/390, D loss: 0.698, G loss: 0.690\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 219/390, D loss: 0.700, G loss: 0.694\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 220/390, D loss: 0.688, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 221/390, D loss: 0.691, G loss: 0.699\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 222/390, D loss: 0.692, G loss: 0.711\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 223/390, D loss: 0.702, G loss: 0.716\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 7/200, Batch: 224/390, D loss: 0.700, G loss: 0.720\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 225/390, D loss: 0.693, G loss: 0.712\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 226/390, D loss: 0.702, G loss: 0.705\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 227/390, D loss: 0.698, G loss: 0.708\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 7/200, Batch: 228/390, D loss: 0.676, G loss: 0.694\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 229/390, D loss: 0.679, G loss: 0.693\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 230/390, D loss: 0.709, G loss: 0.679\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 231/390, D loss: 0.680, G loss: 0.671\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 232/390, D loss: 0.689, G loss: 0.684\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 233/390, D loss: 0.692, G loss: 0.683\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 234/390, D loss: 0.687, G loss: 0.695\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 7/200, Batch: 235/390, D loss: 0.694, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 236/390, D loss: 0.704, G loss: 0.707\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 237/390, D loss: 0.682, G loss: 0.709\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 238/390, D loss: 0.684, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 239/390, D loss: 0.681, G loss: 0.703\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 240/390, D loss: 0.696, G loss: 0.692\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 241/390, D loss: 0.680, G loss: 0.688\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 242/390, D loss: 0.677, G loss: 0.684\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 7/200, Batch: 243/390, D loss: 0.673, G loss: 0.677\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 244/390, D loss: 0.689, G loss: 0.683\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 7/200, Batch: 245/390, D loss: 0.688, G loss: 0.685\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 246/390, D loss: 0.696, G loss: 0.694\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 247/390, D loss: 0.690, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 248/390, D loss: 0.692, G loss: 0.703\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 249/390, D loss: 0.692, G loss: 0.713\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 250/390, D loss: 0.682, G loss: 0.710\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 251/390, D loss: 0.693, G loss: 0.708\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 252/390, D loss: 0.704, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 253/390, D loss: 0.685, G loss: 0.700\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 254/390, D loss: 0.697, G loss: 0.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 255/390, D loss: 0.691, G loss: 0.695\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 256/390, D loss: 0.696, G loss: 0.688\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 257/390, D loss: 0.687, G loss: 0.692\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 7/200, Batch: 258/390, D loss: 0.691, G loss: 0.699\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 7/200, Batch: 259/390, D loss: 0.698, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 260/390, D loss: 0.692, G loss: 0.706\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 261/390, D loss: 0.697, G loss: 0.723\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 262/390, D loss: 0.693, G loss: 0.742\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 7/200, Batch: 263/390, D loss: 0.704, G loss: 0.741\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 264/390, D loss: 0.697, G loss: 0.733\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 7/200, Batch: 265/390, D loss: 0.702, G loss: 0.723\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 266/390, D loss: 0.699, G loss: 0.698\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 267/390, D loss: 0.698, G loss: 0.688\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 7/200, Batch: 268/390, D loss: 0.704, G loss: 0.669\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 7/200, Batch: 269/390, D loss: 0.683, G loss: 0.671\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 270/390, D loss: 0.691, G loss: 0.682\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 271/390, D loss: 0.695, G loss: 0.688\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 272/390, D loss: 0.688, G loss: 0.702\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 7/200, Batch: 273/390, D loss: 0.693, G loss: 0.703\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 274/390, D loss: 0.692, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 275/390, D loss: 0.696, G loss: 0.724\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 7/200, Batch: 276/390, D loss: 0.694, G loss: 0.720\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 277/390, D loss: 0.689, G loss: 0.702\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 278/390, D loss: 0.702, G loss: 0.703\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 7/200, Batch: 279/390, D loss: 0.697, G loss: 0.686\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 280/390, D loss: 0.681, G loss: 0.682\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 281/390, D loss: 0.682, G loss: 0.682\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 282/390, D loss: 0.669, G loss: 0.681\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 283/390, D loss: 0.681, G loss: 0.683\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 284/390, D loss: 0.683, G loss: 0.684\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 285/390, D loss: 0.681, G loss: 0.679\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 286/390, D loss: 0.673, G loss: 0.686\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 7/200, Batch: 287/390, D loss: 0.677, G loss: 0.691\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 288/390, D loss: 0.685, G loss: 0.695\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 289/390, D loss: 0.683, G loss: 0.696\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 7/200, Batch: 290/390, D loss: 0.681, G loss: 0.686\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 291/390, D loss: 0.682, G loss: 0.693\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 292/390, D loss: 0.682, G loss: 0.696\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 293/390, D loss: 0.673, G loss: 0.691\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 294/390, D loss: 0.687, G loss: 0.692\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 295/390, D loss: 0.685, G loss: 0.688\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 296/390, D loss: 0.690, G loss: 0.691\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 7/200, Batch: 297/390, D loss: 0.680, G loss: 0.688\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 298/390, D loss: 0.678, G loss: 0.687\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 299/390, D loss: 0.679, G loss: 0.687\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 7/200, Batch: 300/390, D loss: 0.688, G loss: 0.692\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 301/390, D loss: 0.692, G loss: 0.696\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 302/390, D loss: 0.683, G loss: 0.687\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 303/390, D loss: 0.685, G loss: 0.685\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 304/390, D loss: 0.676, G loss: 0.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 305/390, D loss: 0.684, G loss: 0.692\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 306/390, D loss: 0.692, G loss: 0.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 307/390, D loss: 0.682, G loss: 0.693\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 308/390, D loss: 0.678, G loss: 0.693\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 7/200, Batch: 309/390, D loss: 0.675, G loss: 0.686\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 310/390, D loss: 0.691, G loss: 0.693\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 311/390, D loss: 0.692, G loss: 0.699\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 7/200, Batch: 312/390, D loss: 0.691, G loss: 0.689\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 313/390, D loss: 0.686, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 314/390, D loss: 0.687, G loss: 0.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 315/390, D loss: 0.687, G loss: 0.682\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 316/390, D loss: 0.681, G loss: 0.689\n",
      "2/2 [==============================] - 0s 453us/step\n",
      "Epoch: 7/200, Batch: 317/390, D loss: 0.693, G loss: 0.684\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 318/390, D loss: 0.687, G loss: 0.687\n",
      "2/2 [==============================] - 0s 451us/step\n",
      "Epoch: 7/200, Batch: 319/390, D loss: 0.688, G loss: 0.691\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 320/390, D loss: 0.697, G loss: 0.691\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 321/390, D loss: 0.687, G loss: 0.705\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 322/390, D loss: 0.704, G loss: 0.711\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 323/390, D loss: 0.688, G loss: 0.722\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 7/200, Batch: 324/390, D loss: 0.690, G loss: 0.722\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 7/200, Batch: 325/390, D loss: 0.698, G loss: 0.723\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 7/200, Batch: 326/390, D loss: 0.708, G loss: 0.721\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Epoch: 7/200, Batch: 327/390, D loss: 0.706, G loss: 0.714\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 7/200, Batch: 328/390, D loss: 0.696, G loss: 0.698\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 329/390, D loss: 0.694, G loss: 0.696\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 330/390, D loss: 0.701, G loss: 0.682\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 331/390, D loss: 0.696, G loss: 0.681\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 332/390, D loss: 0.700, G loss: 0.679\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 333/390, D loss: 0.692, G loss: 0.685\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 334/390, D loss: 0.707, G loss: 0.696\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 335/390, D loss: 0.702, G loss: 0.723\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 336/390, D loss: 0.708, G loss: 0.737\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 337/390, D loss: 0.699, G loss: 0.747\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 338/390, D loss: 0.696, G loss: 0.746\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 339/390, D loss: 0.694, G loss: 0.744\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 340/390, D loss: 0.702, G loss: 0.735\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 7/200, Batch: 341/390, D loss: 0.706, G loss: 0.717\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 342/390, D loss: 0.693, G loss: 0.693\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 343/390, D loss: 0.689, G loss: 0.681\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 7/200, Batch: 344/390, D loss: 0.688, G loss: 0.676\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 345/390, D loss: 0.701, G loss: 0.670\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 7/200, Batch: 346/390, D loss: 0.690, G loss: 0.670\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 7/200, Batch: 347/390, D loss: 0.702, G loss: 0.686\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 348/390, D loss: 0.696, G loss: 0.709\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 7/200, Batch: 349/390, D loss: 0.719, G loss: 0.727\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 7/200, Batch: 350/390, D loss: 0.710, G loss: 0.740\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 351/390, D loss: 0.712, G loss: 0.753\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 352/390, D loss: 0.712, G loss: 0.747\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 353/390, D loss: 0.700, G loss: 0.744\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 354/390, D loss: 0.697, G loss: 0.742\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 7/200, Batch: 355/390, D loss: 0.703, G loss: 0.730\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 356/390, D loss: 0.696, G loss: 0.725\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 7/200, Batch: 357/390, D loss: 0.707, G loss: 0.703\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 358/390, D loss: 0.702, G loss: 0.698\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch: 7/200, Batch: 359/390, D loss: 0.703, G loss: 0.682\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 360/390, D loss: 0.709, G loss: 0.675\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 361/390, D loss: 0.702, G loss: 0.684\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 362/390, D loss: 0.707, G loss: 0.675\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 363/390, D loss: 0.699, G loss: 0.686\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 364/390, D loss: 0.710, G loss: 0.700\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 365/390, D loss: 0.697, G loss: 0.702\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 366/390, D loss: 0.704, G loss: 0.712\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 7/200, Batch: 367/390, D loss: 0.704, G loss: 0.727\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 7/200, Batch: 368/390, D loss: 0.695, G loss: 0.725\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 7/200, Batch: 369/390, D loss: 0.700, G loss: 0.724\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 370/390, D loss: 0.695, G loss: 0.720\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 371/390, D loss: 0.709, G loss: 0.711\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 372/390, D loss: 0.699, G loss: 0.707\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 373/390, D loss: 0.699, G loss: 0.698\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 7/200, Batch: 374/390, D loss: 0.698, G loss: 0.704\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 375/390, D loss: 0.700, G loss: 0.701\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 7/200, Batch: 376/390, D loss: 0.684, G loss: 0.693\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 377/390, D loss: 0.684, G loss: 0.686\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 378/390, D loss: 0.694, G loss: 0.686\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 379/390, D loss: 0.679, G loss: 0.680\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 380/390, D loss: 0.689, G loss: 0.685\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 7/200, Batch: 381/390, D loss: 0.692, G loss: 0.688\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 382/390, D loss: 0.681, G loss: 0.681\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 383/390, D loss: 0.678, G loss: 0.687\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 384/390, D loss: 0.686, G loss: 0.691\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 7/200, Batch: 385/390, D loss: 0.689, G loss: 0.695\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 386/390, D loss: 0.692, G loss: 0.704\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 387/390, D loss: 0.679, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 388/390, D loss: 0.673, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 7/200, Batch: 389/390, D loss: 0.706, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 7/200, Batch: 390/390, D loss: 0.692, G loss: 0.699\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 1/390, D loss: 0.684, G loss: 0.699\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 2/390, D loss: 0.680, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 3/390, D loss: 0.683, G loss: 0.700\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 4/390, D loss: 0.689, G loss: 0.689\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 5/390, D loss: 0.687, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 6/390, D loss: 0.691, G loss: 0.689\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 7/390, D loss: 0.704, G loss: 0.693\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 8/200, Batch: 8/390, D loss: 0.682, G loss: 0.690\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 9/390, D loss: 0.671, G loss: 0.683\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 10/390, D loss: 0.687, G loss: 0.683\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 11/390, D loss: 0.695, G loss: 0.690\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 12/390, D loss: 0.680, G loss: 0.695\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 13/390, D loss: 0.690, G loss: 0.700\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 14/390, D loss: 0.701, G loss: 0.688\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 15/390, D loss: 0.687, G loss: 0.694\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 16/390, D loss: 0.691, G loss: 0.710\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 17/390, D loss: 0.686, G loss: 0.709\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 18/390, D loss: 0.691, G loss: 0.698\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 19/390, D loss: 0.690, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 20/390, D loss: 0.688, G loss: 0.699\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 21/390, D loss: 0.694, G loss: 0.707\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 22/390, D loss: 0.686, G loss: 0.707\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 23/390, D loss: 0.692, G loss: 0.711\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 24/390, D loss: 0.682, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 25/390, D loss: 0.682, G loss: 0.705\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 26/390, D loss: 0.692, G loss: 0.710\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 8/200, Batch: 27/390, D loss: 0.689, G loss: 0.704\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 8/200, Batch: 28/390, D loss: 0.675, G loss: 0.699\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 29/390, D loss: 0.676, G loss: 0.692\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 30/390, D loss: 0.681, G loss: 0.689\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 31/390, D loss: 0.687, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 32/390, D loss: 0.690, G loss: 0.699\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 8/200, Batch: 33/390, D loss: 0.703, G loss: 0.709\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 34/390, D loss: 0.700, G loss: 0.716\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 8/200, Batch: 35/390, D loss: 0.693, G loss: 0.717\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 36/390, D loss: 0.697, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 37/390, D loss: 0.700, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 38/390, D loss: 0.704, G loss: 0.714\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 39/390, D loss: 0.710, G loss: 0.710\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 40/390, D loss: 0.720, G loss: 0.712\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 41/390, D loss: 0.718, G loss: 0.709\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 42/390, D loss: 0.689, G loss: 0.702\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 8/200, Batch: 43/390, D loss: 0.706, G loss: 0.700\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 44/390, D loss: 0.709, G loss: 0.701\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 45/390, D loss: 0.726, G loss: 0.704\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 46/390, D loss: 0.704, G loss: 0.701\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 8/200, Batch: 47/390, D loss: 0.680, G loss: 0.704\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 48/390, D loss: 0.708, G loss: 0.721\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 8/200, Batch: 49/390, D loss: 0.703, G loss: 0.724\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 50/390, D loss: 0.707, G loss: 0.737\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 51/390, D loss: 0.701, G loss: 0.722\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 52/390, D loss: 0.690, G loss: 0.727\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 53/390, D loss: 0.713, G loss: 0.700\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 8/200, Batch: 54/390, D loss: 0.708, G loss: 0.705\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 55/390, D loss: 0.706, G loss: 0.694\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 56/390, D loss: 0.704, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 57/390, D loss: 0.706, G loss: 0.705\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 58/390, D loss: 0.699, G loss: 0.704\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 59/390, D loss: 0.707, G loss: 0.715\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 60/390, D loss: 0.707, G loss: 0.722\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 8/200, Batch: 61/390, D loss: 0.706, G loss: 0.720\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 8/200, Batch: 62/390, D loss: 0.707, G loss: 0.720\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 8/200, Batch: 63/390, D loss: 0.704, G loss: 0.726\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 64/390, D loss: 0.703, G loss: 0.730\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 65/390, D loss: 0.709, G loss: 0.730\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 66/390, D loss: 0.709, G loss: 0.724\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 67/390, D loss: 0.706, G loss: 0.725\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 68/390, D loss: 0.696, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 69/390, D loss: 0.698, G loss: 0.716\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 70/390, D loss: 0.701, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 71/390, D loss: 0.698, G loss: 0.708\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 72/390, D loss: 0.706, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 73/390, D loss: 0.694, G loss: 0.701\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 74/390, D loss: 0.701, G loss: 0.700\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 75/390, D loss: 0.692, G loss: 0.694\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 76/390, D loss: 0.689, G loss: 0.704\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 77/390, D loss: 0.703, G loss: 0.699\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 78/390, D loss: 0.695, G loss: 0.701\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 79/390, D loss: 0.708, G loss: 0.707\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 80/390, D loss: 0.691, G loss: 0.706\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Epoch: 8/200, Batch: 81/390, D loss: 0.697, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 82/390, D loss: 0.698, G loss: 0.701\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 83/390, D loss: 0.684, G loss: 0.704\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 84/390, D loss: 0.676, G loss: 0.704\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 85/390, D loss: 0.691, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 86/390, D loss: 0.682, G loss: 0.702\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 8/200, Batch: 87/390, D loss: 0.686, G loss: 0.696\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 88/390, D loss: 0.687, G loss: 0.699\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 89/390, D loss: 0.681, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 90/390, D loss: 0.695, G loss: 0.707\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 8/200, Batch: 91/390, D loss: 0.687, G loss: 0.704\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 92/390, D loss: 0.700, G loss: 0.706\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 8/200, Batch: 93/390, D loss: 0.686, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 94/390, D loss: 0.685, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 95/390, D loss: 0.696, G loss: 0.728\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 96/390, D loss: 0.686, G loss: 0.726\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 97/390, D loss: 0.685, G loss: 0.708\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 98/390, D loss: 0.698, G loss: 0.733\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 99/390, D loss: 0.712, G loss: 0.730\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 100/390, D loss: 0.709, G loss: 0.745\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 101/390, D loss: 0.704, G loss: 0.722\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 8/200, Batch: 102/390, D loss: 0.715, G loss: 0.715\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 8/200, Batch: 103/390, D loss: 0.706, G loss: 0.720\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 104/390, D loss: 0.695, G loss: 0.695\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 105/390, D loss: 0.715, G loss: 0.704\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 8/200, Batch: 106/390, D loss: 0.696, G loss: 0.694\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 107/390, D loss: 0.693, G loss: 0.699\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 108/390, D loss: 0.703, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 109/390, D loss: 0.694, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 110/390, D loss: 0.691, G loss: 0.718\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Epoch: 8/200, Batch: 111/390, D loss: 0.690, G loss: 0.710\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 112/390, D loss: 0.695, G loss: 0.715\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 113/390, D loss: 0.699, G loss: 0.707\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 114/390, D loss: 0.699, G loss: 0.704\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 115/390, D loss: 0.685, G loss: 0.696\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 116/390, D loss: 0.679, G loss: 0.684\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 8/200, Batch: 117/390, D loss: 0.674, G loss: 0.680\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 118/390, D loss: 0.675, G loss: 0.681\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 119/390, D loss: 0.687, G loss: 0.677\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 120/390, D loss: 0.690, G loss: 0.679\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 8/200, Batch: 121/390, D loss: 0.687, G loss: 0.674\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch: 8/200, Batch: 122/390, D loss: 0.691, G loss: 0.681\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 123/390, D loss: 0.681, G loss: 0.687\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 124/390, D loss: 0.690, G loss: 0.688\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 125/390, D loss: 0.686, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 126/390, D loss: 0.692, G loss: 0.707\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 127/390, D loss: 0.681, G loss: 0.716\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 128/390, D loss: 0.696, G loss: 0.721\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 129/390, D loss: 0.700, G loss: 0.721\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 130/390, D loss: 0.690, G loss: 0.722\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 131/390, D loss: 0.691, G loss: 0.715\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 8/200, Batch: 132/390, D loss: 0.695, G loss: 0.722\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 133/390, D loss: 0.695, G loss: 0.714\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 134/390, D loss: 0.677, G loss: 0.710\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 135/390, D loss: 0.700, G loss: 0.709\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 136/390, D loss: 0.686, G loss: 0.703\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 137/390, D loss: 0.697, G loss: 0.700\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 8/200, Batch: 138/390, D loss: 0.690, G loss: 0.700\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 139/390, D loss: 0.680, G loss: 0.701\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 8/200, Batch: 140/390, D loss: 0.690, G loss: 0.695\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 141/390, D loss: 0.695, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 142/390, D loss: 0.701, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 143/390, D loss: 0.697, G loss: 0.696\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 144/390, D loss: 0.689, G loss: 0.695\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 145/390, D loss: 0.702, G loss: 0.696\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 146/390, D loss: 0.692, G loss: 0.696\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 8/200, Batch: 147/390, D loss: 0.687, G loss: 0.703\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 148/390, D loss: 0.690, G loss: 0.706\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 149/390, D loss: 0.696, G loss: 0.697\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 150/390, D loss: 0.686, G loss: 0.705\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 151/390, D loss: 0.689, G loss: 0.705\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 152/390, D loss: 0.688, G loss: 0.701\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 153/390, D loss: 0.682, G loss: 0.689\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 154/390, D loss: 0.671, G loss: 0.685\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 155/390, D loss: 0.687, G loss: 0.680\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 8/200, Batch: 156/390, D loss: 0.668, G loss: 0.682\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 157/390, D loss: 0.675, G loss: 0.681\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 158/390, D loss: 0.682, G loss: 0.676\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 159/390, D loss: 0.676, G loss: 0.696\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 160/390, D loss: 0.683, G loss: 0.701\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 161/390, D loss: 0.685, G loss: 0.720\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 162/390, D loss: 0.686, G loss: 0.728\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 8/200, Batch: 163/390, D loss: 0.690, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 164/390, D loss: 0.678, G loss: 0.705\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 165/390, D loss: 0.693, G loss: 0.699\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 166/390, D loss: 0.689, G loss: 0.701\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 167/390, D loss: 0.678, G loss: 0.693\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 168/390, D loss: 0.689, G loss: 0.706\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 169/390, D loss: 0.702, G loss: 0.710\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 170/390, D loss: 0.706, G loss: 0.714\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 8/200, Batch: 171/390, D loss: 0.685, G loss: 0.716\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 172/390, D loss: 0.709, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 173/390, D loss: 0.700, G loss: 0.705\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 174/390, D loss: 0.689, G loss: 0.716\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 8/200, Batch: 175/390, D loss: 0.703, G loss: 0.718\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 176/390, D loss: 0.699, G loss: 0.721\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 177/390, D loss: 0.705, G loss: 0.726\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 178/390, D loss: 0.709, G loss: 0.730\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 179/390, D loss: 0.705, G loss: 0.743\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 180/390, D loss: 0.707, G loss: 0.736\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 181/390, D loss: 0.708, G loss: 0.730\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 182/390, D loss: 0.714, G loss: 0.722\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 8/200, Batch: 183/390, D loss: 0.684, G loss: 0.706\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 8/200, Batch: 184/390, D loss: 0.685, G loss: 0.708\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 185/390, D loss: 0.694, G loss: 0.694\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 186/390, D loss: 0.686, G loss: 0.691\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 187/390, D loss: 0.684, G loss: 0.690\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 188/390, D loss: 0.687, G loss: 0.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 189/390, D loss: 0.697, G loss: 0.686\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 190/390, D loss: 0.700, G loss: 0.702\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 191/390, D loss: 0.685, G loss: 0.701\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 192/390, D loss: 0.692, G loss: 0.690\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 193/390, D loss: 0.679, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 194/390, D loss: 0.674, G loss: 0.697\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 8/200, Batch: 195/390, D loss: 0.681, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 196/390, D loss: 0.688, G loss: 0.695\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 197/390, D loss: 0.687, G loss: 0.686\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 198/390, D loss: 0.683, G loss: 0.691\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 199/390, D loss: 0.685, G loss: 0.701\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 200/390, D loss: 0.683, G loss: 0.698\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 201/390, D loss: 0.690, G loss: 0.691\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 202/390, D loss: 0.699, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 203/390, D loss: 0.691, G loss: 0.708\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 204/390, D loss: 0.687, G loss: 0.696\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 205/390, D loss: 0.697, G loss: 0.703\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 206/390, D loss: 0.697, G loss: 0.691\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 207/390, D loss: 0.689, G loss: 0.684\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 208/390, D loss: 0.683, G loss: 0.683\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 209/390, D loss: 0.679, G loss: 0.687\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 8/200, Batch: 210/390, D loss: 0.675, G loss: 0.695\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 211/390, D loss: 0.686, G loss: 0.696\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 8/200, Batch: 212/390, D loss: 0.685, G loss: 0.708\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 213/390, D loss: 0.676, G loss: 0.714\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 8/200, Batch: 214/390, D loss: 0.685, G loss: 0.712\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 215/390, D loss: 0.686, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 216/390, D loss: 0.690, G loss: 0.719\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 8/200, Batch: 217/390, D loss: 0.690, G loss: 0.712\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 8/200, Batch: 218/390, D loss: 0.688, G loss: 0.714\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 219/390, D loss: 0.683, G loss: 0.708\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 220/390, D loss: 0.689, G loss: 0.700\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 8/200, Batch: 221/390, D loss: 0.685, G loss: 0.707\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 222/390, D loss: 0.683, G loss: 0.705\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 223/390, D loss: 0.693, G loss: 0.700\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 224/390, D loss: 0.681, G loss: 0.702\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 225/390, D loss: 0.681, G loss: 0.702\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 8/200, Batch: 226/390, D loss: 0.679, G loss: 0.707\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 227/390, D loss: 0.689, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 228/390, D loss: 0.685, G loss: 0.702\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 229/390, D loss: 0.689, G loss: 0.716\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 230/390, D loss: 0.690, G loss: 0.711\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 231/390, D loss: 0.692, G loss: 0.714\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 8/200, Batch: 232/390, D loss: 0.697, G loss: 0.723\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 8/200, Batch: 233/390, D loss: 0.695, G loss: 0.721\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 234/390, D loss: 0.694, G loss: 0.711\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 235/390, D loss: 0.707, G loss: 0.708\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 236/390, D loss: 0.689, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 237/390, D loss: 0.693, G loss: 0.711\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 238/390, D loss: 0.686, G loss: 0.709\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 239/390, D loss: 0.700, G loss: 0.706\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 240/390, D loss: 0.706, G loss: 0.697\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 241/390, D loss: 0.704, G loss: 0.692\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 8/200, Batch: 242/390, D loss: 0.701, G loss: 0.678\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 243/390, D loss: 0.719, G loss: 0.689\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 244/390, D loss: 0.685, G loss: 0.704\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 8/200, Batch: 245/390, D loss: 0.691, G loss: 0.717\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 246/390, D loss: 0.699, G loss: 0.735\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 8/200, Batch: 247/390, D loss: 0.701, G loss: 0.752\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 248/390, D loss: 0.702, G loss: 0.764\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 249/390, D loss: 0.690, G loss: 0.747\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 250/390, D loss: 0.729, G loss: 0.716\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 8/200, Batch: 251/390, D loss: 0.710, G loss: 0.733\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 252/390, D loss: 0.723, G loss: 0.737\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 253/390, D loss: 0.709, G loss: 0.732\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 8/200, Batch: 254/390, D loss: 0.712, G loss: 0.742\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 255/390, D loss: 0.701, G loss: 0.746\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 256/390, D loss: 0.703, G loss: 0.745\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 257/390, D loss: 0.716, G loss: 0.741\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 8/200, Batch: 258/390, D loss: 0.714, G loss: 0.736\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 8/200, Batch: 259/390, D loss: 0.701, G loss: 0.736\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 260/390, D loss: 0.708, G loss: 0.735\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 261/390, D loss: 0.707, G loss: 0.723\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 262/390, D loss: 0.690, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 263/390, D loss: 0.702, G loss: 0.724\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 264/390, D loss: 0.687, G loss: 0.723\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 265/390, D loss: 0.692, G loss: 0.719\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 266/390, D loss: 0.693, G loss: 0.726\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 8/200, Batch: 267/390, D loss: 0.692, G loss: 0.725\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 268/390, D loss: 0.672, G loss: 0.730\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 269/390, D loss: 0.675, G loss: 0.719\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 270/390, D loss: 0.659, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 271/390, D loss: 0.689, G loss: 0.684\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 272/390, D loss: 0.659, G loss: 0.678\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 273/390, D loss: 0.661, G loss: 0.687\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 274/390, D loss: 0.663, G loss: 0.685\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 8/200, Batch: 275/390, D loss: 0.649, G loss: 0.695\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 276/390, D loss: 0.646, G loss: 0.693\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 277/390, D loss: 0.632, G loss: 0.672\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 8/200, Batch: 278/390, D loss: 0.651, G loss: 0.656\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 279/390, D loss: 0.618, G loss: 0.629\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 280/390, D loss: 0.645, G loss: 0.616\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 281/390, D loss: 0.648, G loss: 0.638\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 282/390, D loss: 0.655, G loss: 0.663\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 283/390, D loss: 0.669, G loss: 0.683\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 284/390, D loss: 0.687, G loss: 0.696\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 285/390, D loss: 0.696, G loss: 0.717\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 8/200, Batch: 286/390, D loss: 0.696, G loss: 0.732\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 287/390, D loss: 0.704, G loss: 0.750\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 288/390, D loss: 0.708, G loss: 0.755\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 8/200, Batch: 289/390, D loss: 0.713, G loss: 0.751\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 290/390, D loss: 0.714, G loss: 0.759\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 8/200, Batch: 291/390, D loss: 0.731, G loss: 0.755\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 292/390, D loss: 0.736, G loss: 0.740\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 293/390, D loss: 0.730, G loss: 0.740\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 294/390, D loss: 0.726, G loss: 0.731\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 295/390, D loss: 0.720, G loss: 0.727\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 296/390, D loss: 0.706, G loss: 0.744\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 297/390, D loss: 0.736, G loss: 0.753\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 298/390, D loss: 0.727, G loss: 0.769\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 299/390, D loss: 0.727, G loss: 0.787\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 300/390, D loss: 0.726, G loss: 0.800\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 301/390, D loss: 0.704, G loss: 0.798\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 302/390, D loss: 0.710, G loss: 0.791\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 303/390, D loss: 0.709, G loss: 0.766\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 304/390, D loss: 0.713, G loss: 0.763\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 305/390, D loss: 0.693, G loss: 0.747\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 306/390, D loss: 0.710, G loss: 0.754\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 8/200, Batch: 307/390, D loss: 0.708, G loss: 0.760\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 308/390, D loss: 0.723, G loss: 0.763\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 8/200, Batch: 309/390, D loss: 0.719, G loss: 0.781\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 310/390, D loss: 0.715, G loss: 0.793\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 311/390, D loss: 0.725, G loss: 0.795\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 8/200, Batch: 312/390, D loss: 0.714, G loss: 0.812\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 313/390, D loss: 0.710, G loss: 0.817\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 314/390, D loss: 0.692, G loss: 0.817\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 315/390, D loss: 0.703, G loss: 0.808\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 316/390, D loss: 0.720, G loss: 0.783\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 317/390, D loss: 0.718, G loss: 0.722\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 318/390, D loss: 0.752, G loss: 0.690\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 319/390, D loss: 0.704, G loss: 0.653\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 320/390, D loss: 0.691, G loss: 0.649\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 321/390, D loss: 0.691, G loss: 0.666\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 322/390, D loss: 0.668, G loss: 0.689\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 323/390, D loss: 0.680, G loss: 0.710\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 324/390, D loss: 0.649, G loss: 0.744\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 325/390, D loss: 0.660, G loss: 0.743\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 326/390, D loss: 0.662, G loss: 0.737\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 327/390, D loss: 0.647, G loss: 0.701\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 328/390, D loss: 0.680, G loss: 0.656\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 329/390, D loss: 0.645, G loss: 0.625\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 330/390, D loss: 0.666, G loss: 0.611\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 331/390, D loss: 0.665, G loss: 0.616\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 332/390, D loss: 0.669, G loss: 0.627\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 333/390, D loss: 0.683, G loss: 0.663\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 334/390, D loss: 0.698, G loss: 0.690\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 335/390, D loss: 0.700, G loss: 0.715\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 336/390, D loss: 0.680, G loss: 0.750\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 337/390, D loss: 0.690, G loss: 0.756\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 338/390, D loss: 0.703, G loss: 0.765\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 8/200, Batch: 339/390, D loss: 0.709, G loss: 0.769\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 340/390, D loss: 0.717, G loss: 0.745\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 341/390, D loss: 0.716, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 342/390, D loss: 0.681, G loss: 0.717\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 343/390, D loss: 0.686, G loss: 0.702\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 344/390, D loss: 0.691, G loss: 0.685\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 8/200, Batch: 345/390, D loss: 0.697, G loss: 0.689\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 346/390, D loss: 0.687, G loss: 0.686\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 347/390, D loss: 0.713, G loss: 0.710\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 8/200, Batch: 348/390, D loss: 0.714, G loss: 0.733\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 349/390, D loss: 0.703, G loss: 0.767\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 350/390, D loss: 0.693, G loss: 0.770\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 351/390, D loss: 0.685, G loss: 0.758\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 8/200, Batch: 352/390, D loss: 0.694, G loss: 0.753\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 353/390, D loss: 0.699, G loss: 0.741\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 354/390, D loss: 0.677, G loss: 0.747\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 355/390, D loss: 0.694, G loss: 0.729\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 356/390, D loss: 0.660, G loss: 0.723\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 357/390, D loss: 0.661, G loss: 0.704\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 358/390, D loss: 0.670, G loss: 0.692\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 359/390, D loss: 0.645, G loss: 0.661\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 360/390, D loss: 0.640, G loss: 0.651\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 361/390, D loss: 0.622, G loss: 0.626\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 8/200, Batch: 362/390, D loss: 0.611, G loss: 0.608\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 363/390, D loss: 0.628, G loss: 0.612\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 364/390, D loss: 0.614, G loss: 0.607\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 365/390, D loss: 0.617, G loss: 0.617\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 366/390, D loss: 0.613, G loss: 0.627\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 367/390, D loss: 0.618, G loss: 0.644\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 368/390, D loss: 0.628, G loss: 0.658\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 369/390, D loss: 0.616, G loss: 0.677\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 8/200, Batch: 370/390, D loss: 0.633, G loss: 0.690\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 371/390, D loss: 0.621, G loss: 0.706\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 372/390, D loss: 0.611, G loss: 0.711\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 373/390, D loss: 0.617, G loss: 0.706\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 8/200, Batch: 374/390, D loss: 0.651, G loss: 0.714\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 375/390, D loss: 0.630, G loss: 0.703\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 8/200, Batch: 376/390, D loss: 0.651, G loss: 0.694\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 377/390, D loss: 0.655, G loss: 0.677\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 378/390, D loss: 0.642, G loss: 0.686\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 8/200, Batch: 379/390, D loss: 0.670, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 380/390, D loss: 0.681, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 381/390, D loss: 0.678, G loss: 0.725\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 8/200, Batch: 382/390, D loss: 0.688, G loss: 0.721\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 383/390, D loss: 0.708, G loss: 0.741\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 8/200, Batch: 384/390, D loss: 0.700, G loss: 0.738\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 8/200, Batch: 385/390, D loss: 0.678, G loss: 0.738\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 386/390, D loss: 0.691, G loss: 0.727\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 8/200, Batch: 387/390, D loss: 0.688, G loss: 0.713\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 8/200, Batch: 388/390, D loss: 0.667, G loss: 0.707\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 8/200, Batch: 389/390, D loss: 0.665, G loss: 0.717\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 8/200, Batch: 390/390, D loss: 0.670, G loss: 0.703\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 9/200, Batch: 1/390, D loss: 0.685, G loss: 0.721\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 2/390, D loss: 0.680, G loss: 0.736\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 3/390, D loss: 0.687, G loss: 0.754\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 4/390, D loss: 0.684, G loss: 0.757\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 5/390, D loss: 0.682, G loss: 0.768\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 6/390, D loss: 0.697, G loss: 0.757\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 7/390, D loss: 0.701, G loss: 0.754\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 8/390, D loss: 0.697, G loss: 0.747\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 9/390, D loss: 0.710, G loss: 0.718\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 10/390, D loss: 0.732, G loss: 0.717\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 11/390, D loss: 0.736, G loss: 0.732\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 12/390, D loss: 0.729, G loss: 0.740\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 13/390, D loss: 0.724, G loss: 0.776\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 14/390, D loss: 0.761, G loss: 0.827\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 15/390, D loss: 0.736, G loss: 0.836\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 16/390, D loss: 0.778, G loss: 0.848\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 17/390, D loss: 0.764, G loss: 0.823\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 9/200, Batch: 18/390, D loss: 0.785, G loss: 0.838\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 19/390, D loss: 0.769, G loss: 0.870\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 20/390, D loss: 0.792, G loss: 0.897\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 21/390, D loss: 0.768, G loss: 0.904\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 22/390, D loss: 0.768, G loss: 0.877\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 23/390, D loss: 0.773, G loss: 0.852\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 24/390, D loss: 0.757, G loss: 0.826\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 25/390, D loss: 0.766, G loss: 0.784\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 9/200, Batch: 26/390, D loss: 0.743, G loss: 0.770\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 27/390, D loss: 0.744, G loss: 0.741\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 9/200, Batch: 28/390, D loss: 0.756, G loss: 0.722\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 29/390, D loss: 0.752, G loss: 0.729\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 30/390, D loss: 0.749, G loss: 0.744\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 31/390, D loss: 0.733, G loss: 0.769\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 32/390, D loss: 0.734, G loss: 0.771\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 33/390, D loss: 0.744, G loss: 0.773\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 34/390, D loss: 0.719, G loss: 0.770\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 35/390, D loss: 0.713, G loss: 0.754\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 36/390, D loss: 0.717, G loss: 0.733\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 37/390, D loss: 0.723, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 38/390, D loss: 0.695, G loss: 0.717\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 39/390, D loss: 0.689, G loss: 0.718\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 40/390, D loss: 0.715, G loss: 0.710\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 41/390, D loss: 0.690, G loss: 0.714\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 42/390, D loss: 0.690, G loss: 0.709\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 43/390, D loss: 0.693, G loss: 0.703\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 44/390, D loss: 0.673, G loss: 0.703\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 45/390, D loss: 0.677, G loss: 0.697\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 46/390, D loss: 0.687, G loss: 0.696\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 47/390, D loss: 0.675, G loss: 0.691\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 48/390, D loss: 0.660, G loss: 0.694\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 49/390, D loss: 0.667, G loss: 0.687\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 50/390, D loss: 0.658, G loss: 0.679\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Epoch: 9/200, Batch: 51/390, D loss: 0.668, G loss: 0.672\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 52/390, D loss: 0.650, G loss: 0.681\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 9/200, Batch: 53/390, D loss: 0.661, G loss: 0.670\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 9/200, Batch: 54/390, D loss: 0.679, G loss: 0.678\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 55/390, D loss: 0.659, G loss: 0.668\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 9/200, Batch: 56/390, D loss: 0.673, G loss: 0.674\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 57/390, D loss: 0.676, G loss: 0.685\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 58/390, D loss: 0.658, G loss: 0.682\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 59/390, D loss: 0.671, G loss: 0.672\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 60/390, D loss: 0.665, G loss: 0.682\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 61/390, D loss: 0.672, G loss: 0.683\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 62/390, D loss: 0.678, G loss: 0.685\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 63/390, D loss: 0.659, G loss: 0.681\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 64/390, D loss: 0.654, G loss: 0.678\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 65/390, D loss: 0.635, G loss: 0.680\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 66/390, D loss: 0.667, G loss: 0.682\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 67/390, D loss: 0.640, G loss: 0.681\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 68/390, D loss: 0.650, G loss: 0.682\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 9/200, Batch: 69/390, D loss: 0.635, G loss: 0.684\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 70/390, D loss: 0.642, G loss: 0.673\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 71/390, D loss: 0.630, G loss: 0.675\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 72/390, D loss: 0.639, G loss: 0.669\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 73/390, D loss: 0.633, G loss: 0.663\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 74/390, D loss: 0.656, G loss: 0.663\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 75/390, D loss: 0.632, G loss: 0.664\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 76/390, D loss: 0.646, G loss: 0.669\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 9/200, Batch: 77/390, D loss: 0.641, G loss: 0.673\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 78/390, D loss: 0.651, G loss: 0.684\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 9/200, Batch: 79/390, D loss: 0.663, G loss: 0.694\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 80/390, D loss: 0.669, G loss: 0.692\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 81/390, D loss: 0.682, G loss: 0.703\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 82/390, D loss: 0.668, G loss: 0.695\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 83/390, D loss: 0.667, G loss: 0.707\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 84/390, D loss: 0.662, G loss: 0.712\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 85/390, D loss: 0.657, G loss: 0.715\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 86/390, D loss: 0.638, G loss: 0.716\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 87/390, D loss: 0.660, G loss: 0.707\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 88/390, D loss: 0.685, G loss: 0.730\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 89/390, D loss: 0.672, G loss: 0.719\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 90/390, D loss: 0.668, G loss: 0.714\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 91/390, D loss: 0.670, G loss: 0.714\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 92/390, D loss: 0.671, G loss: 0.725\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 93/390, D loss: 0.670, G loss: 0.727\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 94/390, D loss: 0.669, G loss: 0.724\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 95/390, D loss: 0.676, G loss: 0.727\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 9/200, Batch: 96/390, D loss: 0.671, G loss: 0.728\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 97/390, D loss: 0.650, G loss: 0.719\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 98/390, D loss: 0.672, G loss: 0.696\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 99/390, D loss: 0.647, G loss: 0.668\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 100/390, D loss: 0.679, G loss: 0.663\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 101/390, D loss: 0.673, G loss: 0.657\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 102/390, D loss: 0.687, G loss: 0.687\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 103/390, D loss: 0.692, G loss: 0.706\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 104/390, D loss: 0.692, G loss: 0.723\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 105/390, D loss: 0.719, G loss: 0.761\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 9/200, Batch: 106/390, D loss: 0.705, G loss: 0.776\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 107/390, D loss: 0.706, G loss: 0.789\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 108/390, D loss: 0.723, G loss: 0.768\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 9/200, Batch: 109/390, D loss: 0.707, G loss: 0.805\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 110/390, D loss: 0.696, G loss: 0.792\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 111/390, D loss: 0.732, G loss: 0.775\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 112/390, D loss: 0.746, G loss: 0.746\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 9/200, Batch: 113/390, D loss: 0.714, G loss: 0.746\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 114/390, D loss: 0.737, G loss: 0.723\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 9/200, Batch: 115/390, D loss: 0.734, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 116/390, D loss: 0.719, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 117/390, D loss: 0.726, G loss: 0.715\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 118/390, D loss: 0.736, G loss: 0.727\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 119/390, D loss: 0.709, G loss: 0.750\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 120/390, D loss: 0.721, G loss: 0.764\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 121/390, D loss: 0.722, G loss: 0.780\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 122/390, D loss: 0.719, G loss: 0.795\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 123/390, D loss: 0.706, G loss: 0.809\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 124/390, D loss: 0.723, G loss: 0.792\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 125/390, D loss: 0.720, G loss: 0.782\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 126/390, D loss: 0.710, G loss: 0.773\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 127/390, D loss: 0.697, G loss: 0.749\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 128/390, D loss: 0.706, G loss: 0.741\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 129/390, D loss: 0.729, G loss: 0.711\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 130/390, D loss: 0.681, G loss: 0.702\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 131/390, D loss: 0.713, G loss: 0.700\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 132/390, D loss: 0.721, G loss: 0.708\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 133/390, D loss: 0.713, G loss: 0.718\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 134/390, D loss: 0.703, G loss: 0.740\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 135/390, D loss: 0.723, G loss: 0.754\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 9/200, Batch: 136/390, D loss: 0.717, G loss: 0.775\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 137/390, D loss: 0.719, G loss: 0.778\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 138/390, D loss: 0.720, G loss: 0.789\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 9/200, Batch: 139/390, D loss: 0.734, G loss: 0.783\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 9/200, Batch: 140/390, D loss: 0.723, G loss: 0.768\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 9/200, Batch: 141/390, D loss: 0.728, G loss: 0.766\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 9/200, Batch: 142/390, D loss: 0.719, G loss: 0.750\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 9/200, Batch: 143/390, D loss: 0.720, G loss: 0.757\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 9/200, Batch: 144/390, D loss: 0.733, G loss: 0.741\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 145/390, D loss: 0.709, G loss: 0.734\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch: 9/200, Batch: 146/390, D loss: 0.721, G loss: 0.713\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 147/390, D loss: 0.716, G loss: 0.705\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 148/390, D loss: 0.705, G loss: 0.717\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 9/200, Batch: 149/390, D loss: 0.713, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 150/390, D loss: 0.706, G loss: 0.724\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch: 9/200, Batch: 151/390, D loss: 0.702, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 152/390, D loss: 0.707, G loss: 0.731\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 153/390, D loss: 0.707, G loss: 0.733\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 154/390, D loss: 0.719, G loss: 0.736\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 9/200, Batch: 155/390, D loss: 0.708, G loss: 0.735\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 156/390, D loss: 0.706, G loss: 0.730\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 9/200, Batch: 157/390, D loss: 0.699, G loss: 0.722\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 158/390, D loss: 0.707, G loss: 0.716\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 159/390, D loss: 0.696, G loss: 0.711\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 160/390, D loss: 0.695, G loss: 0.714\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 161/390, D loss: 0.709, G loss: 0.700\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 162/390, D loss: 0.691, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 163/390, D loss: 0.685, G loss: 0.709\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 164/390, D loss: 0.680, G loss: 0.706\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 165/390, D loss: 0.685, G loss: 0.693\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 9/200, Batch: 166/390, D loss: 0.671, G loss: 0.690\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 167/390, D loss: 0.671, G loss: 0.693\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 168/390, D loss: 0.671, G loss: 0.696\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 169/390, D loss: 0.663, G loss: 0.690\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 170/390, D loss: 0.680, G loss: 0.692\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 171/390, D loss: 0.675, G loss: 0.694\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 172/390, D loss: 0.651, G loss: 0.695\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 173/390, D loss: 0.677, G loss: 0.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 174/390, D loss: 0.655, G loss: 0.695\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 175/390, D loss: 0.658, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 176/390, D loss: 0.672, G loss: 0.694\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 177/390, D loss: 0.664, G loss: 0.711\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 9/200, Batch: 178/390, D loss: 0.666, G loss: 0.702\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 179/390, D loss: 0.667, G loss: 0.703\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 180/390, D loss: 0.664, G loss: 0.700\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 9/200, Batch: 181/390, D loss: 0.676, G loss: 0.696\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 182/390, D loss: 0.678, G loss: 0.688\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 183/390, D loss: 0.655, G loss: 0.686\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 9/200, Batch: 184/390, D loss: 0.670, G loss: 0.675\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 185/390, D loss: 0.657, G loss: 0.677\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 186/390, D loss: 0.660, G loss: 0.670\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 187/390, D loss: 0.681, G loss: 0.677\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 9/200, Batch: 188/390, D loss: 0.647, G loss: 0.677\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch: 9/200, Batch: 189/390, D loss: 0.664, G loss: 0.688\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 190/390, D loss: 0.659, G loss: 0.686\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 191/390, D loss: 0.654, G loss: 0.692\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 9/200, Batch: 192/390, D loss: 0.654, G loss: 0.699\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 193/390, D loss: 0.663, G loss: 0.701\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 194/390, D loss: 0.663, G loss: 0.706\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 195/390, D loss: 0.654, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 196/390, D loss: 0.677, G loss: 0.695\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 197/390, D loss: 0.654, G loss: 0.692\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 198/390, D loss: 0.654, G loss: 0.688\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 199/390, D loss: 0.653, G loss: 0.686\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 200/390, D loss: 0.638, G loss: 0.678\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 201/390, D loss: 0.653, G loss: 0.681\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 202/390, D loss: 0.655, G loss: 0.667\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 203/390, D loss: 0.657, G loss: 0.666\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 9/200, Batch: 204/390, D loss: 0.670, G loss: 0.666\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 205/390, D loss: 0.654, G loss: 0.668\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 206/390, D loss: 0.657, G loss: 0.670\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 207/390, D loss: 0.668, G loss: 0.685\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 208/390, D loss: 0.674, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 209/390, D loss: 0.678, G loss: 0.719\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 210/390, D loss: 0.686, G loss: 0.731\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 211/390, D loss: 0.684, G loss: 0.748\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 212/390, D loss: 0.669, G loss: 0.755\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 213/390, D loss: 0.691, G loss: 0.747\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 214/390, D loss: 0.704, G loss: 0.731\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 215/390, D loss: 0.684, G loss: 0.734\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 9/200, Batch: 216/390, D loss: 0.680, G loss: 0.715\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 217/390, D loss: 0.702, G loss: 0.706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 218/390, D loss: 0.705, G loss: 0.694\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 219/390, D loss: 0.685, G loss: 0.695\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 220/390, D loss: 0.704, G loss: 0.701\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 221/390, D loss: 0.694, G loss: 0.710\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 222/390, D loss: 0.707, G loss: 0.712\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 223/390, D loss: 0.699, G loss: 0.722\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 224/390, D loss: 0.708, G loss: 0.734\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 225/390, D loss: 0.709, G loss: 0.745\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 226/390, D loss: 0.703, G loss: 0.760\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 227/390, D loss: 0.698, G loss: 0.767\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 228/390, D loss: 0.699, G loss: 0.778\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 229/390, D loss: 0.704, G loss: 0.776\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 9/200, Batch: 230/390, D loss: 0.708, G loss: 0.758\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 231/390, D loss: 0.705, G loss: 0.752\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 9/200, Batch: 232/390, D loss: 0.701, G loss: 0.750\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 233/390, D loss: 0.694, G loss: 0.722\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 234/390, D loss: 0.700, G loss: 0.726\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 235/390, D loss: 0.703, G loss: 0.706\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 9/200, Batch: 236/390, D loss: 0.712, G loss: 0.701\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 237/390, D loss: 0.684, G loss: 0.706\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 9/200, Batch: 238/390, D loss: 0.714, G loss: 0.709\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 239/390, D loss: 0.710, G loss: 0.711\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 240/390, D loss: 0.702, G loss: 0.715\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 241/390, D loss: 0.699, G loss: 0.728\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 242/390, D loss: 0.696, G loss: 0.723\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 243/390, D loss: 0.702, G loss: 0.733\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 9/200, Batch: 244/390, D loss: 0.691, G loss: 0.749\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 245/390, D loss: 0.707, G loss: 0.732\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 246/390, D loss: 0.689, G loss: 0.752\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 247/390, D loss: 0.697, G loss: 0.746\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 248/390, D loss: 0.696, G loss: 0.748\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 249/390, D loss: 0.685, G loss: 0.744\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 250/390, D loss: 0.694, G loss: 0.720\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 251/390, D loss: 0.711, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 252/390, D loss: 0.692, G loss: 0.712\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 253/390, D loss: 0.693, G loss: 0.710\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 254/390, D loss: 0.696, G loss: 0.697\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 255/390, D loss: 0.686, G loss: 0.703\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 256/390, D loss: 0.692, G loss: 0.705\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 257/390, D loss: 0.687, G loss: 0.705\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 9/200, Batch: 258/390, D loss: 0.690, G loss: 0.714\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 259/390, D loss: 0.702, G loss: 0.723\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 260/390, D loss: 0.684, G loss: 0.731\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 261/390, D loss: 0.706, G loss: 0.732\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 262/390, D loss: 0.694, G loss: 0.730\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 263/390, D loss: 0.692, G loss: 0.730\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 264/390, D loss: 0.684, G loss: 0.724\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 265/390, D loss: 0.712, G loss: 0.726\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 9/200, Batch: 266/390, D loss: 0.709, G loss: 0.724\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 267/390, D loss: 0.697, G loss: 0.716\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 9/200, Batch: 268/390, D loss: 0.691, G loss: 0.717\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 269/390, D loss: 0.707, G loss: 0.711\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 270/390, D loss: 0.702, G loss: 0.708\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 271/390, D loss: 0.703, G loss: 0.710\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 9/200, Batch: 272/390, D loss: 0.692, G loss: 0.703\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 9/200, Batch: 273/390, D loss: 0.705, G loss: 0.721\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 274/390, D loss: 0.685, G loss: 0.715\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 9/200, Batch: 275/390, D loss: 0.704, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 276/390, D loss: 0.695, G loss: 0.733\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 277/390, D loss: 0.687, G loss: 0.738\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 278/390, D loss: 0.704, G loss: 0.742\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 279/390, D loss: 0.690, G loss: 0.742\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 280/390, D loss: 0.707, G loss: 0.755\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 281/390, D loss: 0.701, G loss: 0.754\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 282/390, D loss: 0.699, G loss: 0.736\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 283/390, D loss: 0.701, G loss: 0.727\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 284/390, D loss: 0.684, G loss: 0.719\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 9/200, Batch: 285/390, D loss: 0.711, G loss: 0.711\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 286/390, D loss: 0.688, G loss: 0.702\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 287/390, D loss: 0.695, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 288/390, D loss: 0.688, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 289/390, D loss: 0.697, G loss: 0.711\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 290/390, D loss: 0.684, G loss: 0.715\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 291/390, D loss: 0.677, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 292/390, D loss: 0.683, G loss: 0.728\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 293/390, D loss: 0.673, G loss: 0.729\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 294/390, D loss: 0.683, G loss: 0.716\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 295/390, D loss: 0.694, G loss: 0.704\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 296/390, D loss: 0.702, G loss: 0.703\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 297/390, D loss: 0.677, G loss: 0.695\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 9/200, Batch: 298/390, D loss: 0.702, G loss: 0.699\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 299/390, D loss: 0.697, G loss: 0.694\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 300/390, D loss: 0.708, G loss: 0.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 301/390, D loss: 0.699, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 302/390, D loss: 0.688, G loss: 0.701\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 303/390, D loss: 0.693, G loss: 0.681\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 304/390, D loss: 0.669, G loss: 0.672\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 305/390, D loss: 0.694, G loss: 0.673\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 306/390, D loss: 0.690, G loss: 0.697\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 307/390, D loss: 0.705, G loss: 0.736\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 308/390, D loss: 0.702, G loss: 0.792\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 309/390, D loss: 0.705, G loss: 0.792\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 9/200, Batch: 310/390, D loss: 0.702, G loss: 0.799\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 311/390, D loss: 0.699, G loss: 0.745\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 312/390, D loss: 0.724, G loss: 0.719\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 313/390, D loss: 0.701, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 314/390, D loss: 0.661, G loss: 0.680\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 315/390, D loss: 0.674, G loss: 0.679\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 316/390, D loss: 0.651, G loss: 0.664\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 317/390, D loss: 0.642, G loss: 0.663\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 318/390, D loss: 0.655, G loss: 0.678\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 319/390, D loss: 0.658, G loss: 0.687\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 320/390, D loss: 0.650, G loss: 0.696\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 321/390, D loss: 0.656, G loss: 0.697\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 322/390, D loss: 0.679, G loss: 0.702\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 323/390, D loss: 0.678, G loss: 0.697\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 324/390, D loss: 0.650, G loss: 0.703\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch: 9/200, Batch: 325/390, D loss: 0.648, G loss: 0.701\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 326/390, D loss: 0.658, G loss: 0.691\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 9/200, Batch: 327/390, D loss: 0.657, G loss: 0.699\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 9/200, Batch: 328/390, D loss: 0.639, G loss: 0.692\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 9/200, Batch: 329/390, D loss: 0.652, G loss: 0.689\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 9/200, Batch: 330/390, D loss: 0.652, G loss: 0.695\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 331/390, D loss: 0.638, G loss: 0.687\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 332/390, D loss: 0.639, G loss: 0.679\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 9/200, Batch: 333/390, D loss: 0.633, G loss: 0.662\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 334/390, D loss: 0.626, G loss: 0.665\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 335/390, D loss: 0.666, G loss: 0.657\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 336/390, D loss: 0.669, G loss: 0.647\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 9/200, Batch: 337/390, D loss: 0.663, G loss: 0.661\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 338/390, D loss: 0.670, G loss: 0.676\n",
      "2/2 [==============================] - 0s 713us/step\n",
      "Epoch: 9/200, Batch: 339/390, D loss: 0.685, G loss: 0.683\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 340/390, D loss: 0.685, G loss: 0.701\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 341/390, D loss: 0.689, G loss: 0.727\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 342/390, D loss: 0.688, G loss: 0.742\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 343/390, D loss: 0.701, G loss: 0.740\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 344/390, D loss: 0.701, G loss: 0.763\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 9/200, Batch: 345/390, D loss: 0.701, G loss: 0.746\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 9/200, Batch: 346/390, D loss: 0.723, G loss: 0.736\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 347/390, D loss: 0.719, G loss: 0.727\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 348/390, D loss: 0.720, G loss: 0.727\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 349/390, D loss: 0.717, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 350/390, D loss: 0.715, G loss: 0.709\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 9/200, Batch: 351/390, D loss: 0.705, G loss: 0.725\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 352/390, D loss: 0.710, G loss: 0.735\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 353/390, D loss: 0.712, G loss: 0.767\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 9/200, Batch: 354/390, D loss: 0.732, G loss: 0.803\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 355/390, D loss: 0.728, G loss: 0.817\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 9/200, Batch: 356/390, D loss: 0.726, G loss: 0.826\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 9/200, Batch: 357/390, D loss: 0.708, G loss: 0.802\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 358/390, D loss: 0.717, G loss: 0.788\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 9/200, Batch: 359/390, D loss: 0.707, G loss: 0.758\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 9/200, Batch: 360/390, D loss: 0.730, G loss: 0.733\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 361/390, D loss: 0.714, G loss: 0.750\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 9/200, Batch: 362/390, D loss: 0.729, G loss: 0.763\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 9/200, Batch: 363/390, D loss: 0.738, G loss: 0.785\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 364/390, D loss: 0.731, G loss: 0.797\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 9/200, Batch: 365/390, D loss: 0.722, G loss: 0.796\n",
      "2/2 [==============================] - 0s 346us/step\n",
      "Epoch: 9/200, Batch: 366/390, D loss: 0.713, G loss: 0.797\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 367/390, D loss: 0.734, G loss: 0.794\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 368/390, D loss: 0.731, G loss: 0.746\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Epoch: 9/200, Batch: 369/390, D loss: 0.726, G loss: 0.734\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 370/390, D loss: 0.729, G loss: 0.725\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 371/390, D loss: 0.733, G loss: 0.715\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 9/200, Batch: 372/390, D loss: 0.721, G loss: 0.716\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch: 9/200, Batch: 373/390, D loss: 0.728, G loss: 0.712\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 374/390, D loss: 0.719, G loss: 0.732\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch: 9/200, Batch: 375/390, D loss: 0.724, G loss: 0.743\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 376/390, D loss: 0.727, G loss: 0.748\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 9/200, Batch: 377/390, D loss: 0.720, G loss: 0.730\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Epoch: 9/200, Batch: 378/390, D loss: 0.699, G loss: 0.704\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 9/200, Batch: 379/390, D loss: 0.716, G loss: 0.679\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 380/390, D loss: 0.712, G loss: 0.685\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 9/200, Batch: 381/390, D loss: 0.726, G loss: 0.669\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 9/200, Batch: 382/390, D loss: 0.733, G loss: 0.687\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 9/200, Batch: 383/390, D loss: 0.740, G loss: 0.714\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 384/390, D loss: 0.742, G loss: 0.746\n",
      "2/2 [==============================] - 0s 892us/step\n",
      "Epoch: 9/200, Batch: 385/390, D loss: 0.750, G loss: 0.781\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 386/390, D loss: 0.766, G loss: 0.795\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 387/390, D loss: 0.759, G loss: 0.821\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 9/200, Batch: 388/390, D loss: 0.750, G loss: 0.790\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 389/390, D loss: 0.756, G loss: 0.780\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 9/200, Batch: 390/390, D loss: 0.755, G loss: 0.765\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 1/390, D loss: 0.737, G loss: 0.750\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 2/390, D loss: 0.745, G loss: 0.740\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 3/390, D loss: 0.723, G loss: 0.749\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 4/390, D loss: 0.726, G loss: 0.733\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 5/390, D loss: 0.708, G loss: 0.720\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 6/390, D loss: 0.704, G loss: 0.713\n",
      "2/2 [==============================] - 0s 19ms/step\n",
      "Epoch: 10/200, Batch: 7/390, D loss: 0.708, G loss: 0.703\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 8/390, D loss: 0.721, G loss: 0.686\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 9/390, D loss: 0.724, G loss: 0.688\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 10/200, Batch: 10/390, D loss: 0.683, G loss: 0.677\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 10/200, Batch: 11/390, D loss: 0.686, G loss: 0.674\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 12/390, D loss: 0.693, G loss: 0.674\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 13/390, D loss: 0.676, G loss: 0.679\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 14/390, D loss: 0.667, G loss: 0.678\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 15/390, D loss: 0.660, G loss: 0.683\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 10/200, Batch: 16/390, D loss: 0.672, G loss: 0.682\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 10/200, Batch: 17/390, D loss: 0.676, G loss: 0.692\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 18/390, D loss: 0.659, G loss: 0.689\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 19/390, D loss: 0.650, G loss: 0.685\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 10/200, Batch: 20/390, D loss: 0.661, G loss: 0.683\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 21/390, D loss: 0.660, G loss: 0.680\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 22/390, D loss: 0.645, G loss: 0.686\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 23/390, D loss: 0.645, G loss: 0.678\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 24/390, D loss: 0.652, G loss: 0.670\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 25/390, D loss: 0.646, G loss: 0.675\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 10/200, Batch: 26/390, D loss: 0.653, G loss: 0.668\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 27/390, D loss: 0.643, G loss: 0.677\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 10/200, Batch: 28/390, D loss: 0.642, G loss: 0.677\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 10/200, Batch: 29/390, D loss: 0.642, G loss: 0.682\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 10/200, Batch: 30/390, D loss: 0.647, G loss: 0.680\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 31/390, D loss: 0.634, G loss: 0.686\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 32/390, D loss: 0.628, G loss: 0.685\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 33/390, D loss: 0.630, G loss: 0.690\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 34/390, D loss: 0.631, G loss: 0.691\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 35/390, D loss: 0.642, G loss: 0.702\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 36/390, D loss: 0.637, G loss: 0.697\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 37/390, D loss: 0.644, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 38/390, D loss: 0.648, G loss: 0.699\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 39/390, D loss: 0.650, G loss: 0.702\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 40/390, D loss: 0.657, G loss: 0.716\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 10/200, Batch: 41/390, D loss: 0.658, G loss: 0.722\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 42/390, D loss: 0.665, G loss: 0.705\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 43/390, D loss: 0.651, G loss: 0.727\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 44/390, D loss: 0.667, G loss: 0.720\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 10/200, Batch: 45/390, D loss: 0.694, G loss: 0.711\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 46/390, D loss: 0.693, G loss: 0.705\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 47/390, D loss: 0.686, G loss: 0.714\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 48/390, D loss: 0.713, G loss: 0.700\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 49/390, D loss: 0.709, G loss: 0.700\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 10/200, Batch: 50/390, D loss: 0.704, G loss: 0.686\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 51/390, D loss: 0.732, G loss: 0.692\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 52/390, D loss: 0.720, G loss: 0.720\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 53/390, D loss: 0.713, G loss: 0.741\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 54/390, D loss: 0.719, G loss: 0.799\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 55/390, D loss: 0.724, G loss: 0.863\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 56/390, D loss: 0.711, G loss: 0.865\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 57/390, D loss: 0.712, G loss: 0.816\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 58/390, D loss: 0.700, G loss: 0.762\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 59/390, D loss: 0.700, G loss: 0.766\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 60/390, D loss: 0.719, G loss: 0.864\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 61/390, D loss: 0.705, G loss: 0.956\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 10/200, Batch: 62/390, D loss: 0.724, G loss: 0.955\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 63/390, D loss: 0.725, G loss: 0.938\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 64/390, D loss: 0.693, G loss: 0.907\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 65/390, D loss: 0.723, G loss: 0.936\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 66/390, D loss: 0.721, G loss: 0.903\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 67/390, D loss: 0.711, G loss: 0.790\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 68/390, D loss: 0.709, G loss: 0.749\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 69/390, D loss: 0.731, G loss: 0.744\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 70/390, D loss: 0.744, G loss: 0.779\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 71/390, D loss: 0.752, G loss: 0.822\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 72/390, D loss: 0.756, G loss: 0.858\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 73/390, D loss: 0.755, G loss: 0.860\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 74/390, D loss: 0.759, G loss: 0.786\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 75/390, D loss: 0.777, G loss: 0.726\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 76/390, D loss: 0.769, G loss: 0.693\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 10/200, Batch: 77/390, D loss: 0.740, G loss: 0.680\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 78/390, D loss: 0.754, G loss: 0.677\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 10/200, Batch: 79/390, D loss: 0.751, G loss: 0.673\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 10/200, Batch: 80/390, D loss: 0.731, G loss: 0.686\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 10/200, Batch: 81/390, D loss: 0.725, G loss: 0.689\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 10/200, Batch: 82/390, D loss: 0.745, G loss: 0.691\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 83/390, D loss: 0.740, G loss: 0.690\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 84/390, D loss: 0.702, G loss: 0.691\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 85/390, D loss: 0.695, G loss: 0.679\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 86/390, D loss: 0.700, G loss: 0.676\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 87/390, D loss: 0.694, G loss: 0.674\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 88/390, D loss: 0.702, G loss: 0.674\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 10/200, Batch: 89/390, D loss: 0.701, G loss: 0.669\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 90/390, D loss: 0.688, G loss: 0.657\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 91/390, D loss: 0.694, G loss: 0.665\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 92/390, D loss: 0.705, G loss: 0.670\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 93/390, D loss: 0.697, G loss: 0.666\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 94/390, D loss: 0.679, G loss: 0.674\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 95/390, D loss: 0.708, G loss: 0.675\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 96/390, D loss: 0.679, G loss: 0.672\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 97/390, D loss: 0.681, G loss: 0.680\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 98/390, D loss: 0.707, G loss: 0.682\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 99/390, D loss: 0.675, G loss: 0.687\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 100/390, D loss: 0.667, G loss: 0.680\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 101/390, D loss: 0.658, G loss: 0.681\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 102/390, D loss: 0.681, G loss: 0.673\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 103/390, D loss: 0.656, G loss: 0.675\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 104/390, D loss: 0.654, G loss: 0.669\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 105/390, D loss: 0.646, G loss: 0.667\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 106/390, D loss: 0.634, G loss: 0.658\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 107/390, D loss: 0.638, G loss: 0.648\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 108/390, D loss: 0.638, G loss: 0.653\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 109/390, D loss: 0.643, G loss: 0.650\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 110/390, D loss: 0.632, G loss: 0.649\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 111/390, D loss: 0.621, G loss: 0.654\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 112/390, D loss: 0.627, G loss: 0.660\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 113/390, D loss: 0.637, G loss: 0.655\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 114/390, D loss: 0.618, G loss: 0.644\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 115/390, D loss: 0.639, G loss: 0.648\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 116/390, D loss: 0.634, G loss: 0.652\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 10/200, Batch: 117/390, D loss: 0.642, G loss: 0.657\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 118/390, D loss: 0.645, G loss: 0.665\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 10/200, Batch: 119/390, D loss: 0.644, G loss: 0.640\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 120/390, D loss: 0.638, G loss: 0.666\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 121/390, D loss: 0.634, G loss: 0.675\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 122/390, D loss: 0.634, G loss: 0.670\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 123/390, D loss: 0.624, G loss: 0.678\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 124/390, D loss: 0.643, G loss: 0.674\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 10/200, Batch: 125/390, D loss: 0.648, G loss: 0.671\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 126/390, D loss: 0.647, G loss: 0.679\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 127/390, D loss: 0.641, G loss: 0.671\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 128/390, D loss: 0.635, G loss: 0.670\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 10/200, Batch: 129/390, D loss: 0.638, G loss: 0.674\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 130/390, D loss: 0.659, G loss: 0.678\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 10/200, Batch: 131/390, D loss: 0.662, G loss: 0.684\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 132/390, D loss: 0.663, G loss: 0.702\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Epoch: 10/200, Batch: 133/390, D loss: 0.674, G loss: 0.706\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 134/390, D loss: 0.676, G loss: 0.715\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 10/200, Batch: 135/390, D loss: 0.689, G loss: 0.712\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 136/390, D loss: 0.684, G loss: 0.717\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 10/200, Batch: 137/390, D loss: 0.685, G loss: 0.735\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 10/200, Batch: 138/390, D loss: 0.703, G loss: 0.738\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 10/200, Batch: 139/390, D loss: 0.684, G loss: 0.754\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 140/390, D loss: 0.686, G loss: 0.774\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 141/390, D loss: 0.702, G loss: 0.801\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 142/390, D loss: 0.704, G loss: 0.834\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 143/390, D loss: 0.681, G loss: 0.833\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 144/390, D loss: 0.679, G loss: 0.817\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 145/390, D loss: 0.690, G loss: 0.792\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 146/390, D loss: 0.666, G loss: 0.751\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 10/200, Batch: 147/390, D loss: 0.702, G loss: 0.717\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 148/390, D loss: 0.667, G loss: 0.699\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 149/390, D loss: 0.682, G loss: 0.689\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 150/390, D loss: 0.714, G loss: 0.681\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 151/390, D loss: 0.702, G loss: 0.695\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 152/390, D loss: 0.706, G loss: 0.709\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 153/390, D loss: 0.711, G loss: 0.734\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 154/390, D loss: 0.704, G loss: 0.760\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 155/390, D loss: 0.711, G loss: 0.782\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 156/390, D loss: 0.717, G loss: 0.816\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 157/390, D loss: 0.710, G loss: 0.839\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 158/390, D loss: 0.715, G loss: 0.819\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 159/390, D loss: 0.712, G loss: 0.778\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 160/390, D loss: 0.714, G loss: 0.765\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 161/390, D loss: 0.713, G loss: 0.734\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 162/390, D loss: 0.696, G loss: 0.735\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 163/390, D loss: 0.726, G loss: 0.725\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 10/200, Batch: 164/390, D loss: 0.714, G loss: 0.703\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 165/390, D loss: 0.706, G loss: 0.712\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 10/200, Batch: 166/390, D loss: 0.709, G loss: 0.704\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 167/390, D loss: 0.735, G loss: 0.705\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 168/390, D loss: 0.725, G loss: 0.720\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 169/390, D loss: 0.727, G loss: 0.735\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 170/390, D loss: 0.736, G loss: 0.746\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 10/200, Batch: 171/390, D loss: 0.725, G loss: 0.759\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 172/390, D loss: 0.727, G loss: 0.778\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 173/390, D loss: 0.746, G loss: 0.765\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 174/390, D loss: 0.755, G loss: 0.764\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 175/390, D loss: 0.727, G loss: 0.782\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 176/390, D loss: 0.728, G loss: 0.778\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 177/390, D loss: 0.756, G loss: 0.772\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 178/390, D loss: 0.738, G loss: 0.759\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 179/390, D loss: 0.748, G loss: 0.759\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 180/390, D loss: 0.744, G loss: 0.753\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 181/390, D loss: 0.744, G loss: 0.761\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 182/390, D loss: 0.754, G loss: 0.751\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 10/200, Batch: 183/390, D loss: 0.743, G loss: 0.764\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 184/390, D loss: 0.749, G loss: 0.753\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 185/390, D loss: 0.742, G loss: 0.760\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 10/200, Batch: 186/390, D loss: 0.739, G loss: 0.757\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 10/200, Batch: 187/390, D loss: 0.738, G loss: 0.771\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 188/390, D loss: 0.731, G loss: 0.783\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 10/200, Batch: 189/390, D loss: 0.728, G loss: 0.810\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 190/390, D loss: 0.740, G loss: 0.800\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 191/390, D loss: 0.715, G loss: 0.822\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 192/390, D loss: 0.734, G loss: 0.801\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 193/390, D loss: 0.714, G loss: 0.791\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 194/390, D loss: 0.715, G loss: 0.761\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 195/390, D loss: 0.705, G loss: 0.739\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 196/390, D loss: 0.721, G loss: 0.744\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 197/390, D loss: 0.701, G loss: 0.722\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 198/390, D loss: 0.698, G loss: 0.721\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 199/390, D loss: 0.704, G loss: 0.716\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 200/390, D loss: 0.705, G loss: 0.717\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 201/390, D loss: 0.699, G loss: 0.711\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 202/390, D loss: 0.697, G loss: 0.710\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 203/390, D loss: 0.694, G loss: 0.697\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 10/200, Batch: 204/390, D loss: 0.695, G loss: 0.696\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 205/390, D loss: 0.671, G loss: 0.696\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 206/390, D loss: 0.683, G loss: 0.695\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 10/200, Batch: 207/390, D loss: 0.701, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 208/390, D loss: 0.672, G loss: 0.707\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 209/390, D loss: 0.682, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 210/390, D loss: 0.682, G loss: 0.703\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 10/200, Batch: 211/390, D loss: 0.682, G loss: 0.705\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 212/390, D loss: 0.688, G loss: 0.712\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 213/390, D loss: 0.693, G loss: 0.717\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 214/390, D loss: 0.679, G loss: 0.727\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 215/390, D loss: 0.691, G loss: 0.720\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 216/390, D loss: 0.696, G loss: 0.733\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 10/200, Batch: 217/390, D loss: 0.702, G loss: 0.710\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 218/390, D loss: 0.681, G loss: 0.702\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 219/390, D loss: 0.701, G loss: 0.687\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 220/390, D loss: 0.693, G loss: 0.695\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 221/390, D loss: 0.676, G loss: 0.684\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 222/390, D loss: 0.685, G loss: 0.698\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 223/390, D loss: 0.674, G loss: 0.708\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 224/390, D loss: 0.690, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 225/390, D loss: 0.702, G loss: 0.711\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 10/200, Batch: 226/390, D loss: 0.688, G loss: 0.696\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 227/390, D loss: 0.681, G loss: 0.697\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 228/390, D loss: 0.716, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 229/390, D loss: 0.712, G loss: 0.693\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 10/200, Batch: 230/390, D loss: 0.675, G loss: 0.681\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 10/200, Batch: 231/390, D loss: 0.715, G loss: 0.687\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 232/390, D loss: 0.691, G loss: 0.716\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 233/390, D loss: 0.701, G loss: 0.727\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 234/390, D loss: 0.691, G loss: 0.787\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 235/390, D loss: 0.707, G loss: 0.780\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 10/200, Batch: 236/390, D loss: 0.694, G loss: 0.791\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 237/390, D loss: 0.734, G loss: 0.774\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 238/390, D loss: 0.737, G loss: 0.741\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 10/200, Batch: 239/390, D loss: 0.717, G loss: 0.716\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 240/390, D loss: 0.715, G loss: 0.707\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 241/390, D loss: 0.701, G loss: 0.692\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 242/390, D loss: 0.682, G loss: 0.673\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 243/390, D loss: 0.709, G loss: 0.682\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 244/390, D loss: 0.712, G loss: 0.674\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 245/390, D loss: 0.702, G loss: 0.683\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 10/200, Batch: 246/390, D loss: 0.698, G loss: 0.688\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 247/390, D loss: 0.684, G loss: 0.698\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 248/390, D loss: 0.696, G loss: 0.714\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 249/390, D loss: 0.697, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 250/390, D loss: 0.693, G loss: 0.731\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 10/200, Batch: 251/390, D loss: 0.701, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 252/390, D loss: 0.704, G loss: 0.732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 253/390, D loss: 0.694, G loss: 0.735\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 254/390, D loss: 0.703, G loss: 0.733\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 255/390, D loss: 0.698, G loss: 0.745\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 256/390, D loss: 0.711, G loss: 0.748\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 257/390, D loss: 0.690, G loss: 0.740\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 258/390, D loss: 0.705, G loss: 0.734\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 259/390, D loss: 0.692, G loss: 0.728\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 260/390, D loss: 0.703, G loss: 0.717\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 261/390, D loss: 0.703, G loss: 0.726\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 262/390, D loss: 0.707, G loss: 0.712\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 263/390, D loss: 0.705, G loss: 0.723\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 264/390, D loss: 0.699, G loss: 0.716\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 10/200, Batch: 265/390, D loss: 0.677, G loss: 0.736\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 266/390, D loss: 0.691, G loss: 0.729\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 267/390, D loss: 0.672, G loss: 0.719\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 268/390, D loss: 0.693, G loss: 0.717\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 269/390, D loss: 0.694, G loss: 0.707\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 270/390, D loss: 0.673, G loss: 0.690\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 271/390, D loss: 0.669, G loss: 0.683\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 272/390, D loss: 0.670, G loss: 0.677\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 273/390, D loss: 0.671, G loss: 0.675\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 274/390, D loss: 0.666, G loss: 0.692\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 275/390, D loss: 0.678, G loss: 0.706\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 276/390, D loss: 0.669, G loss: 0.715\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 277/390, D loss: 0.674, G loss: 0.723\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 278/390, D loss: 0.668, G loss: 0.725\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 279/390, D loss: 0.681, G loss: 0.728\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 280/390, D loss: 0.676, G loss: 0.726\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 281/390, D loss: 0.668, G loss: 0.746\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 282/390, D loss: 0.692, G loss: 0.737\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 283/390, D loss: 0.676, G loss: 0.734\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 284/390, D loss: 0.664, G loss: 0.692\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 285/390, D loss: 0.695, G loss: 0.669\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 286/390, D loss: 0.691, G loss: 0.671\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 10/200, Batch: 287/390, D loss: 0.679, G loss: 0.676\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 288/390, D loss: 0.680, G loss: 0.675\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 289/390, D loss: 0.697, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 290/390, D loss: 0.702, G loss: 0.723\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 291/390, D loss: 0.692, G loss: 0.745\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 292/390, D loss: 0.686, G loss: 0.764\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 293/390, D loss: 0.697, G loss: 0.772\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 294/390, D loss: 0.690, G loss: 0.761\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 295/390, D loss: 0.710, G loss: 0.751\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 10/200, Batch: 296/390, D loss: 0.689, G loss: 0.753\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 297/390, D loss: 0.721, G loss: 0.736\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 298/390, D loss: 0.703, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 299/390, D loss: 0.688, G loss: 0.716\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 300/390, D loss: 0.725, G loss: 0.723\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 10/200, Batch: 301/390, D loss: 0.673, G loss: 0.710\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 302/390, D loss: 0.699, G loss: 0.710\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 303/390, D loss: 0.712, G loss: 0.735\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 304/390, D loss: 0.718, G loss: 0.726\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 305/390, D loss: 0.696, G loss: 0.742\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 10/200, Batch: 306/390, D loss: 0.721, G loss: 0.738\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 307/390, D loss: 0.720, G loss: 0.753\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 308/390, D loss: 0.722, G loss: 0.759\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 309/390, D loss: 0.726, G loss: 0.765\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 310/390, D loss: 0.715, G loss: 0.777\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 311/390, D loss: 0.730, G loss: 0.763\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 312/390, D loss: 0.716, G loss: 0.761\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 313/390, D loss: 0.744, G loss: 0.758\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 314/390, D loss: 0.738, G loss: 0.744\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 315/390, D loss: 0.729, G loss: 0.754\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 316/390, D loss: 0.731, G loss: 0.750\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 317/390, D loss: 0.736, G loss: 0.751\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 318/390, D loss: 0.730, G loss: 0.757\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 10/200, Batch: 319/390, D loss: 0.737, G loss: 0.752\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 320/390, D loss: 0.723, G loss: 0.762\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 321/390, D loss: 0.724, G loss: 0.748\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 322/390, D loss: 0.724, G loss: 0.749\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 323/390, D loss: 0.719, G loss: 0.768\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 324/390, D loss: 0.716, G loss: 0.767\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 325/390, D loss: 0.717, G loss: 0.760\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 326/390, D loss: 0.709, G loss: 0.769\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 327/390, D loss: 0.747, G loss: 0.762\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 10/200, Batch: 328/390, D loss: 0.720, G loss: 0.767\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 329/390, D loss: 0.711, G loss: 0.750\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 330/390, D loss: 0.710, G loss: 0.744\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 331/390, D loss: 0.702, G loss: 0.748\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 332/390, D loss: 0.697, G loss: 0.746\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 333/390, D loss: 0.685, G loss: 0.735\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 334/390, D loss: 0.698, G loss: 0.750\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch: 10/200, Batch: 335/390, D loss: 0.700, G loss: 0.751\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 336/390, D loss: 0.706, G loss: 0.746\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch: 10/200, Batch: 337/390, D loss: 0.689, G loss: 0.748\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 338/390, D loss: 0.700, G loss: 0.741\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 339/390, D loss: 0.708, G loss: 0.743\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 340/390, D loss: 0.692, G loss: 0.727\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 341/390, D loss: 0.677, G loss: 0.728\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 342/390, D loss: 0.699, G loss: 0.717\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 343/390, D loss: 0.646, G loss: 0.700\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 344/390, D loss: 0.683, G loss: 0.687\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 345/390, D loss: 0.670, G loss: 0.677\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 10/200, Batch: 346/390, D loss: 0.686, G loss: 0.672\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 347/390, D loss: 0.682, G loss: 0.679\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 348/390, D loss: 0.678, G loss: 0.684\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 349/390, D loss: 0.687, G loss: 0.682\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 350/390, D loss: 0.671, G loss: 0.686\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 351/390, D loss: 0.665, G loss: 0.696\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 352/390, D loss: 0.688, G loss: 0.705\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 353/390, D loss: 0.672, G loss: 0.697\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 354/390, D loss: 0.667, G loss: 0.700\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 355/390, D loss: 0.676, G loss: 0.691\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 356/390, D loss: 0.664, G loss: 0.673\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 357/390, D loss: 0.664, G loss: 0.644\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 358/390, D loss: 0.656, G loss: 0.644\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 359/390, D loss: 0.672, G loss: 0.656\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 360/390, D loss: 0.675, G loss: 0.652\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 361/390, D loss: 0.700, G loss: 0.660\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 362/390, D loss: 0.677, G loss: 0.684\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 363/390, D loss: 0.669, G loss: 0.703\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 364/390, D loss: 0.673, G loss: 0.716\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 365/390, D loss: 0.699, G loss: 0.713\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 366/390, D loss: 0.692, G loss: 0.709\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 367/390, D loss: 0.705, G loss: 0.714\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 368/390, D loss: 0.706, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 369/390, D loss: 0.661, G loss: 0.700\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 370/390, D loss: 0.700, G loss: 0.697\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 10/200, Batch: 371/390, D loss: 0.677, G loss: 0.710\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 10/200, Batch: 372/390, D loss: 0.664, G loss: 0.694\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 373/390, D loss: 0.698, G loss: 0.692\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 374/390, D loss: 0.725, G loss: 0.679\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 375/390, D loss: 0.690, G loss: 0.705\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 376/390, D loss: 0.700, G loss: 0.702\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 377/390, D loss: 0.691, G loss: 0.710\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 378/390, D loss: 0.701, G loss: 0.728\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 10/200, Batch: 379/390, D loss: 0.687, G loss: 0.740\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 380/390, D loss: 0.718, G loss: 0.754\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 10/200, Batch: 381/390, D loss: 0.701, G loss: 0.769\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 382/390, D loss: 0.693, G loss: 0.774\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 10/200, Batch: 383/390, D loss: 0.701, G loss: 0.761\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 384/390, D loss: 0.682, G loss: 0.773\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 385/390, D loss: 0.684, G loss: 0.749\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 386/390, D loss: 0.690, G loss: 0.743\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 10/200, Batch: 387/390, D loss: 0.702, G loss: 0.725\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 10/200, Batch: 388/390, D loss: 0.689, G loss: 0.714\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 10/200, Batch: 389/390, D loss: 0.677, G loss: 0.697\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 10/200, Batch: 390/390, D loss: 0.698, G loss: 0.685\n",
      "4/4 [==============================] - 0s 31ms/step\n",
      ">Accuracy | real: 62%, fake: 20%\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 11/200, Batch: 1/390, D loss: 0.679, G loss: 0.682\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 11/200, Batch: 2/390, D loss: 0.685, G loss: 0.683\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 3/390, D loss: 0.669, G loss: 0.692\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 4/390, D loss: 0.683, G loss: 0.694\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Epoch: 11/200, Batch: 5/390, D loss: 0.684, G loss: 0.707\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 11/200, Batch: 6/390, D loss: 0.687, G loss: 0.714\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 11/200, Batch: 7/390, D loss: 0.682, G loss: 0.719\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 11/200, Batch: 8/390, D loss: 0.683, G loss: 0.725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 9/390, D loss: 0.683, G loss: 0.721\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 11/200, Batch: 10/390, D loss: 0.699, G loss: 0.715\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 11/200, Batch: 11/390, D loss: 0.682, G loss: 0.705\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 12/390, D loss: 0.685, G loss: 0.699\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 11/200, Batch: 13/390, D loss: 0.684, G loss: 0.690\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 14/390, D loss: 0.685, G loss: 0.686\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 15/390, D loss: 0.679, G loss: 0.663\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 16/390, D loss: 0.678, G loss: 0.677\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 17/390, D loss: 0.704, G loss: 0.674\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 18/390, D loss: 0.686, G loss: 0.679\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 11/200, Batch: 19/390, D loss: 0.687, G loss: 0.692\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 11/200, Batch: 20/390, D loss: 0.691, G loss: 0.714\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 11/200, Batch: 21/390, D loss: 0.689, G loss: 0.725\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 11/200, Batch: 22/390, D loss: 0.685, G loss: 0.743\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 11/200, Batch: 23/390, D loss: 0.678, G loss: 0.748\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 24/390, D loss: 0.678, G loss: 0.744\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 11/200, Batch: 25/390, D loss: 0.686, G loss: 0.732\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 26/390, D loss: 0.695, G loss: 0.738\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 11/200, Batch: 27/390, D loss: 0.657, G loss: 0.720\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 28/390, D loss: 0.686, G loss: 0.708\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 11/200, Batch: 29/390, D loss: 0.686, G loss: 0.703\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 11/200, Batch: 30/390, D loss: 0.698, G loss: 0.691\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 11/200, Batch: 31/390, D loss: 0.682, G loss: 0.712\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch: 11/200, Batch: 32/390, D loss: 0.700, G loss: 0.711\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 11/200, Batch: 33/390, D loss: 0.691, G loss: 0.720\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 11/200, Batch: 34/390, D loss: 0.713, G loss: 0.717\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 11/200, Batch: 35/390, D loss: 0.708, G loss: 0.737\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 36/390, D loss: 0.708, G loss: 0.744\n",
      "2/2 [==============================] - 0s 273us/step\n",
      "Epoch: 11/200, Batch: 37/390, D loss: 0.720, G loss: 0.744\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 11/200, Batch: 38/390, D loss: 0.732, G loss: 0.768\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 11/200, Batch: 39/390, D loss: 0.725, G loss: 0.767\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 40/390, D loss: 0.721, G loss: 0.791\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 11/200, Batch: 41/390, D loss: 0.720, G loss: 0.798\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 42/390, D loss: 0.724, G loss: 0.786\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 11/200, Batch: 43/390, D loss: 0.719, G loss: 0.782\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 11/200, Batch: 44/390, D loss: 0.727, G loss: 0.781\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 45/390, D loss: 0.731, G loss: 0.749\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 46/390, D loss: 0.692, G loss: 0.747\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 11/200, Batch: 47/390, D loss: 0.715, G loss: 0.731\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 48/390, D loss: 0.716, G loss: 0.743\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 11/200, Batch: 49/390, D loss: 0.716, G loss: 0.750\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 11/200, Batch: 50/390, D loss: 0.701, G loss: 0.765\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 51/390, D loss: 0.709, G loss: 0.763\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 52/390, D loss: 0.707, G loss: 0.773\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 11/200, Batch: 53/390, D loss: 0.703, G loss: 0.763\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch: 11/200, Batch: 54/390, D loss: 0.697, G loss: 0.745\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 55/390, D loss: 0.708, G loss: 0.746\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 56/390, D loss: 0.706, G loss: 0.728\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 57/390, D loss: 0.699, G loss: 0.727\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 11/200, Batch: 58/390, D loss: 0.715, G loss: 0.719\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch: 11/200, Batch: 59/390, D loss: 0.694, G loss: 0.734\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 60/390, D loss: 0.696, G loss: 0.726\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 11/200, Batch: 61/390, D loss: 0.694, G loss: 0.737\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 11/200, Batch: 62/390, D loss: 0.699, G loss: 0.730\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 63/390, D loss: 0.719, G loss: 0.724\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 64/390, D loss: 0.698, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 65/390, D loss: 0.703, G loss: 0.695\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 11/200, Batch: 66/390, D loss: 0.715, G loss: 0.694\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 11/200, Batch: 67/390, D loss: 0.685, G loss: 0.702\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 68/390, D loss: 0.692, G loss: 0.698\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 69/390, D loss: 0.694, G loss: 0.712\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch: 11/200, Batch: 70/390, D loss: 0.710, G loss: 0.718\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 71/390, D loss: 0.702, G loss: 0.723\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 72/390, D loss: 0.707, G loss: 0.727\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 11/200, Batch: 73/390, D loss: 0.695, G loss: 0.725\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 74/390, D loss: 0.692, G loss: 0.734\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 11/200, Batch: 75/390, D loss: 0.684, G loss: 0.720\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch: 11/200, Batch: 76/390, D loss: 0.694, G loss: 0.708\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 11/200, Batch: 77/390, D loss: 0.698, G loss: 0.708\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 11/200, Batch: 78/390, D loss: 0.667, G loss: 0.702\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 79/390, D loss: 0.687, G loss: 0.697\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch: 11/200, Batch: 80/390, D loss: 0.689, G loss: 0.687\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 11/200, Batch: 81/390, D loss: 0.679, G loss: 0.680\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 11/200, Batch: 82/390, D loss: 0.671, G loss: 0.682\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 11/200, Batch: 83/390, D loss: 0.680, G loss: 0.674\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 11/200, Batch: 84/390, D loss: 0.669, G loss: 0.680\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 85/390, D loss: 0.664, G loss: 0.674\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 86/390, D loss: 0.672, G loss: 0.684\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 11/200, Batch: 87/390, D loss: 0.677, G loss: 0.687\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 88/390, D loss: 0.668, G loss: 0.687\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch: 11/200, Batch: 89/390, D loss: 0.663, G loss: 0.699\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 90/390, D loss: 0.661, G loss: 0.708\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 91/390, D loss: 0.660, G loss: 0.704\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 92/390, D loss: 0.670, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 93/390, D loss: 0.673, G loss: 0.713\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 94/390, D loss: 0.660, G loss: 0.705\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 11/200, Batch: 95/390, D loss: 0.656, G loss: 0.693\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 96/390, D loss: 0.664, G loss: 0.678\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch: 11/200, Batch: 97/390, D loss: 0.651, G loss: 0.667\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 98/390, D loss: 0.661, G loss: 0.656\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 99/390, D loss: 0.654, G loss: 0.653\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 11/200, Batch: 100/390, D loss: 0.666, G loss: 0.660\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 101/390, D loss: 0.659, G loss: 0.675\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 11/200, Batch: 102/390, D loss: 0.657, G loss: 0.683\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 103/390, D loss: 0.660, G loss: 0.700\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 11/200, Batch: 104/390, D loss: 0.663, G loss: 0.724\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch: 11/200, Batch: 105/390, D loss: 0.671, G loss: 0.752\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch: 11/200, Batch: 106/390, D loss: 0.672, G loss: 0.761\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 107/390, D loss: 0.659, G loss: 0.758\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 108/390, D loss: 0.667, G loss: 0.752\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch: 11/200, Batch: 109/390, D loss: 0.684, G loss: 0.744\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch: 11/200, Batch: 110/390, D loss: 0.666, G loss: 0.735\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 11/200, Batch: 111/390, D loss: 0.679, G loss: 0.712\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch: 11/200, Batch: 112/390, D loss: 0.677, G loss: 0.691\n",
      "2/2 [==============================] - 0s 926us/step\n",
      "Epoch: 11/200, Batch: 113/390, D loss: 0.678, G loss: 0.687\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch: 11/200, Batch: 114/390, D loss: 0.693, G loss: 0.675\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch: 11/200, Batch: 115/390, D loss: 0.667, G loss: 0.689\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_real_samples()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m plot_metrics(metrics, epochs)\n",
      "Cell \u001b[1;32mIn [1], line 219\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(bat_per_epo):\n\u001b[0;32m    218\u001b[0m     [X_real, labels_real], y_real \u001b[38;5;241m=\u001b[39m generate_real_samples(dataset, half_batch)\n\u001b[1;32m--> 219\u001b[0m     d_loss1, _ \u001b[38;5;241m=\u001b[39m \u001b[43md_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_real\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_real\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     [X_fake, labels_fake], y_fake \u001b[38;5;241m=\u001b[39m generate_fake_samples(g_model, latent_dim, half_batch)\n\u001b[0;32m    221\u001b[0m     d_loss2, _ \u001b[38;5;241m=\u001b[39m d_model\u001b[38;5;241m.\u001b[39mtrain_on_batch([X_fake, labels_fake], y_fake)\n",
      "File \u001b[1;32mc:\\Users\\zachary\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py:2381\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2377\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[0;32m   2378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[0;32m   2379\u001b[0m     )\n\u001b[0;32m   2380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[1;32m-> 2381\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2383\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mc:\\Users\\zachary\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\zachary\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\zachary\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\zachary\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zachary\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\zachary\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\zachary\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 128\n",
    "# create the discriminator\n",
    "d_model = define_discriminator()\n",
    "d_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "\n",
    "# create the generator\n",
    "g_model = define_generator(latent_dim)\n",
    "g_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "# create the gan\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "gan_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "# train model\n",
    "metrics = train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=128)\n",
    "\n",
    "epochs = range(1, len(metrics['d_loss']) + 1)\n",
    "plot_metrics(metrics, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 358ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_images(generator_model, latent_dim, n_samples, labels):\n",
    "    # Generate points in latent space\n",
    "    latent_points, sample_labels = generate_latent_points(latent_dim, n_samples)\n",
    "    # Update latent points with provided labels\n",
    "    sample_labels[:] = labels\n",
    "    # Generate images\n",
    "    images = generator_model.predict([latent_points, sample_labels])\n",
    "    # Scale from [-1,1] to [0,1]\n",
    "    images = (images + 1) / 2.0\n",
    "    # Plot images\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(int(np.sqrt(n_samples)), int(np.sqrt(n_samples)), 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images[i])\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "generate_images(g_model, latent_dim, n_samples=25, labels = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
