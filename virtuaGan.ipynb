{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a dcgan on cifar10\n",
    "from numpy import ones\n",
    "from numpy.random import randint, randn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import sqrtm\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU, Conv2D, Conv2DTranspose, Embedding, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.datasets.cifar10 import load_data\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Lambda, Permute\n",
    "\n",
    " #Flattened input\n",
    "class VBN(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 epsilon=1e-5,\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_initializer='ones',\n",
    "                 **kwargs):\n",
    "        \n",
    "        self.epsilon = epsilon\n",
    "        self.beta_initializer = beta_initializer\n",
    "        self.gamma_initializer = gamma_initializer\n",
    "        self.batch_size = 128\n",
    "        \n",
    "        self.ref_mean = None\n",
    "        self.ref_mean_sq = None\n",
    "            \n",
    "        super(VBN, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        #Pas convaincu du -1 mdr\n",
    "        self.gamma = self.add_weight(name='gamma', \n",
    "                                      shape=(input_shape[-1],),\n",
    "                                      initializer=self.gamma_initializer,\n",
    "                                      trainable=True)\n",
    "        \n",
    "        self.beta = self.add_weight(name='beta', \n",
    "                                      shape=(input_shape[-1],),\n",
    "                                      initializer=self.beta_initializer,\n",
    "                                      trainable=True)\n",
    "    \n",
    "        super(VBN, self).build(input_shape)  # Be sure to call this at the end\n",
    "    \n",
    "    def call(self, x, training=None):\n",
    "        #Getting training value to know if we are in inference or not\n",
    "        if training is None:\n",
    "            training = K.learning_phase()\n",
    "        if isinstance(training, int):\n",
    "            training = bool(training)       \n",
    "\n",
    "        #If True, we need to update stats (using ref batch)\n",
    "        if self.ref_mean is None or self.ref_mean_sq is None:\n",
    "            self.ref_mean = tf.reduce_mean(x, [0,1,2], keepdims=True, name='new_mean')\n",
    "            self.ref_mean_sq = tf.reduce_mean(tf.square(x), [0,1,2], keepdims=True, name=\"new_mean_sq\") # 0 1 2\n",
    "            return self._normalize(x, self.ref_mean, self.ref_mean_sq)\n",
    "        \n",
    "        #Else, they are set, so we use them\n",
    "        new_coeff = 1./(self.batch_size + 1)\n",
    "        old_coeff = 1 - new_coeff\n",
    "        new_mean = tf.reduce_mean(x, [1,2], keepdims=True, name='new_mean')\n",
    "        new_mean_sq = tf.reduce_mean(tf.square(x), [1,2], keepdims=True, name=\"new_mean_sq\")\n",
    "        mean = new_coeff * new_mean + old_coeff * self.ref_mean\n",
    "        mean_sq = new_coeff * new_mean_sq + old_coeff * self.ref_mean_sq\n",
    "        \n",
    "        out = self._normalize(x, mean, mean_sq)\n",
    "        self.ref_mean = None\n",
    "        self.ref_mean_sq = None\n",
    "        return out\n",
    "        \n",
    "    def _normalize(self, x, mean, mean_sq):\n",
    "        std = tf.sqrt(self.epsilon + mean_sq - tf.square(mean))\n",
    "        beta = tf.reshape(self.beta,[1,1,1,-1])\n",
    "        gamma = tf.reshape(self.gamma,[1,1,1,-1])\n",
    "        \n",
    "        out = (x - mean) / std\n",
    "        out = out * gamma\n",
    "        out = out + beta\n",
    "        return out\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "      \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['epsilon'] =  self.epsilon\n",
    "        config['beta_initializer'] = self.beta_initializer\n",
    "        config[\"gamma_initializer\"] = self.gamma_initializer\n",
    "        return config\n",
    "    \n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(32,32,3), n_classes=10):\n",
    "    # Label input\n",
    "    label_input = Input(shape=(1,))\n",
    "    li = Embedding(n_classes, 50)(label_input)\n",
    "    n_nodes = in_shape[0] * in_shape[1]\n",
    "    li = Dense(n_nodes)(li)\n",
    "    li = Reshape((in_shape[0], in_shape[1], 1))(li)\n",
    "\n",
    "    # Image input\n",
    "    image_input = Input(shape=in_shape)\n",
    "\n",
    "    # Merge inputs\n",
    "    merge = Concatenate()([image_input, li])\n",
    "\n",
    "    # Downsample\n",
    "    fe = Conv2D(64, (3,3), strides=(2,2), padding='same')(merge)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "\n",
    "    # Downsample\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "\n",
    "    # Flatten and output\n",
    "    fe = Flatten()(fe)\n",
    "    fe = Dropout(0.7)(fe)\n",
    "    out_layer = Dense(1, activation='sigmoid')(fe)\n",
    "\n",
    "    # Define model\n",
    "    model = Model([image_input, label_input], out_layer)\n",
    "    return model\n",
    "\n",
    " \n",
    "# define the standalone generator model\n",
    "def define_generator(latent_dim, n_classes=10):\n",
    "    # Label input\n",
    "    label_input = Input(shape=(1,))\n",
    "    li = Embedding(n_classes, 50)(label_input)\n",
    "    n_nodes = 8 * 8\n",
    "    li = Dense(n_nodes)(li)\n",
    "    li = Reshape((8, 8, 1))(li)\n",
    "\n",
    "    # Latent input\n",
    "    latent_input = Input(shape=(latent_dim,))\n",
    "    gen = Dense(256 * 8 * 8)(latent_input)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = Reshape((8, 8, 256))(gen)\n",
    "\n",
    "    # Merge inputs\n",
    "    merge = Concatenate()([gen, li])\n",
    "\n",
    "    # Upsample to 16x16\n",
    "    gen = Conv2DTranspose(256, (4,4), strides=(2,2), padding='same')(merge)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = VBN()(gen)\n",
    "\n",
    "    # Upsample to 32x32\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = VBN()(gen)\n",
    "\n",
    "    # Output layer 32x32x3\n",
    "    out_layer = Conv2D(3, (3,3), activation='tanh', padding='same')(gen)\n",
    "\n",
    "    # Define model\n",
    "    model = Model([latent_input, label_input], out_layer)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model):\n",
    "    d_model.trainable = False\n",
    "    gen_noise, gen_label = g_model.input\n",
    "    gen_output = g_model.output\n",
    "    gan_output = d_model([gen_output, gen_label])\n",
    "    model = Model([gen_noise, gen_label], gan_output)\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model\n",
    "    \n",
    "# load and prepare cifar10 training images\n",
    "def load_real_samples():\n",
    "    (trainX, trainy), (_, _) = load_data()\n",
    "    X = trainX.astype('float32')\n",
    "    X = (X - 127.5) / 127.5\n",
    "    return [X, trainy]\n",
    "\n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # Verify that dataset is a list or tuple with two items\n",
    "    if not isinstance(dataset, (list, tuple)) or len(dataset) != 2:\n",
    "        raise ValueError(\"Expected dataset to be a list or tuple of [images, labels]\")\n",
    "\n",
    "    images, labels = dataset\n",
    "    ix = randint(0, images.shape[0], n_samples)\n",
    "    X, labels = images[ix], labels[ix]\n",
    "    y = ones((n_samples, 1))\n",
    "    return [X, labels], y\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples, n_classes=10):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    labels = randint(0, n_classes, n_samples)\n",
    "    images = g_model.predict([z_input, labels])\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return [images, labels], y\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    labels = randint(0, 10, n_samples)\n",
    "    return [z_input, labels]\n",
    "\n",
    "# create and save a plot of generated images\n",
    "def save_plot(examples, epoch, n=7):\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    examples = (examples + 1) / 2.0\n",
    "    # plot images\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(examples[i])\n",
    "        # save plot to file\n",
    "        filename = 'generated_plot_e%03d.png' % (epoch+1)\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "\n",
    "def calculate_fid(dataset, generated_images):\n",
    "    real_images = dataset[0]  # Extracting real images from dataset\n",
    "    generated_images = np.array(generated_images[0]) \n",
    "    # Flatten images to 2D\n",
    "    real_images_2d = real_images.reshape(real_images.shape[0], -1)\n",
    "    generated_images_2d = generated_images.reshape(generated_images.shape[0], -1)\n",
    "\n",
    "    # Calculate the mean and covariance of real and generated images\n",
    "    mu1, sigma1 = real_images_2d.mean(axis=0), np.cov(real_images_2d, rowvar=False)\n",
    "    mu2, sigma2 = generated_images_2d.mean(axis=0), np.cov(generated_images_2d, rowvar=False)\n",
    "\n",
    "    # Calculate the sum of the squared difference of the means\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "\n",
    "    # Calculate sqrt of product of covariances\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    \n",
    "    # Check for imaginary numbers and convert to real\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "\n",
    "    # Calculate FID\n",
    "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid\n",
    "\n",
    "\n",
    "def calculate_precision_recall(dataset, generated_images):\n",
    "    real_images = dataset[0]  # Extracting real images from dataset\n",
    "\n",
    "    # Ensure generated_images is a numpy array\n",
    "    generated_images = np.array(generated_images[0])  # Extracting only images from generated samples\n",
    "\n",
    "    # Ensure the same number of samples in both sets\n",
    "    min_samples = min(real_images.shape[0], generated_images.shape[0])\n",
    "    real_images = real_images[:min_samples]\n",
    "    generated_images = generated_images[:min_samples]\n",
    "\n",
    "    # Flatten images\n",
    "    real_images_2d = real_images.reshape(min_samples, -1)\n",
    "    generated_images_2d = generated_images.reshape(min_samples, -1)\n",
    "\n",
    "    # Binarize images (assuming values are in 0-255 range)\n",
    "    threshold = 128\n",
    "    real_images_binarized = (real_images_2d > threshold).astype(int)\n",
    "    generated_images_binarized = (generated_images_2d > threshold).astype(int)\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision = precision_score(real_images_binarized, generated_images_binarized, average='micro', zero_division=0)\n",
    "    recall = recall_score(real_images_binarized, generated_images_binarized, average='micro', zero_division=0)\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "# evaluate the discriminator, plot generated images, save generator model\n",
    "def summarize_performance(g_model, d_model, dataset, latent_dim, n_samples=100):\n",
    "    # Prepare real samples\n",
    "    [X_real, labels_real], y_real = generate_real_samples(dataset, n_samples)\n",
    "    # Evaluate discriminator on real examples\n",
    "    _, acc_real = d_model.evaluate([X_real, labels_real], y_real, verbose=0)\n",
    "    \n",
    "    # Prepare fake examples\n",
    "    [x_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # Evaluate discriminator on fake examples\n",
    "    _, acc_fake = d_model.evaluate([x_fake, labels_fake], y_fake, verbose=0)\n",
    "    \n",
    "    # Summarize discriminator performance\n",
    "    print(f'>Accuracy | real: {acc_real*100:.0f}%, fake: {acc_fake*100:.0f}%')\n",
    "    return acc_real, acc_fake\n",
    "    \n",
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch):\n",
    "    metrics = {'acc_real': [], 'acc_fake': [], 'd_loss': [], 'g_loss': [], 'fid': [], 'precision': [], 'recall': []}\n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epo):\n",
    "            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
    "            d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
    "            [X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            d_loss2, _ = d_model.train_on_batch([X_fake, labels_fake], y_fake)\n",
    "            [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = np.ones((n_batch, 1))\n",
    "            g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "            print(f'Epoch: {i+1}/{n_epochs}, Batch: {j+1}/{bat_per_epo}, D loss: {d_loss1:.3f}, G loss: {g_loss:.3f}')\n",
    "        # evaluate\n",
    "        if (i+1) % 5 == 0:\n",
    "            acc_real, acc_fake = summarize_performance(g_model, d_model, dataset, latent_dim)\n",
    "            generated_fake_images, _ = generate_fake_samples(g_model, latent_dim, 100)\n",
    "            fid = calculate_fid(dataset, generated_fake_images)\n",
    "            precision, recall = calculate_precision_recall(dataset, generated_fake_images)\n",
    "            metrics['acc_real'].append(acc_real)\n",
    "            metrics['acc_fake'].append(acc_fake)\n",
    "            metrics['d_loss'].append((d_loss1 + d_loss2) / 2)\n",
    "            metrics['g_loss'].append(g_loss)\n",
    "            metrics['fid'].append(fid)\n",
    "            metrics['precision'].append(precision)\n",
    "            metrics['recall'].append(recall)\n",
    "        if (i+1) % 10 == 0:\n",
    "            d_model.save_weights('model/discriminator_model_virtual.h5')\n",
    "            g_model.save_weights('model/generator_model_virtual.h5')  \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics, epochs):\n",
    "    # Plotting Loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, metrics['acc_real'], label='Accuracy Real')\n",
    "    plt.plot(epochs, metrics['acc_fake'], label='Accuracy Fake')\n",
    "    plt.title('Discriminator Accuracy During Training')\n",
    "    plt.xlabel('Eval')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, metrics['d_loss'], label='Discriminator Loss')\n",
    "    plt.plot(epochs, metrics['g_loss'], label='Generator Loss')\n",
    "    plt.title('Discriminator and Generator Loss During Training')\n",
    "    plt.xlabel('Eval')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting FID, sFID, Class-aware-FID, and MiFID\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, metrics['fid'], label='FID')\n",
    "    plt.title('FID During Training')\n",
    "    plt.xlabel('Eval')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<tf.Tensor 'vbn_2/new_mean:0' shape=(1, 1, 1, 256) dtype=float32> is out of scope and cannot be used here. Use return values, explicit Python locals or TensorFlow collections to access it.\nPlease see https://www.tensorflow.org/guide/function#all_outputs_of_a_tffunction_must_be_return_values for more information.\n\n<tf.Tensor 'vbn_2/new_mean:0' shape=(1, 1, 1, 256) dtype=float32> was defined here:\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3046, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3101, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3306, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3488, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3548, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_3048\\3160050400.py\", line 8, in <module>\n      g_model = define_generator(latent_dim)\n    File \"C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_3048\\1671772212.py\", line 151, in define_generator\n      gen = VBN()(gen)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1011, in __call__\n      return self._functional_construction_call(\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 2498, in _functional_construction_call\n      outputs = self._keras_tensor_symbolic_call(\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 2345, in _keras_tensor_symbolic_call\n      return self._infer_output_signature(\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 2404, in _infer_output_signature\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_3048\\2893464449.py\", line 59, in call\n      if self.ref_mean is None or self.ref_mean_sq is None:\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 1363, in if_stmt\n      _py_if_stmt(cond, body, orelse)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 1416, in _py_if_stmt\n      return body() if cond else orelse()\n    File \"C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_3048\\2893464449.py\", line 60, in call\n      self.ref_mean = tf.reduce_mean(x, [0,1,2], keepdims=True, name='new_mean')\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1176, in op_dispatch_handler\n      return dispatch_target(*args, **kwargs)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2640, in reduce_mean\n      gen_math_ops.mean(\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 6285, in mean\n      _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 797, in _apply_op_helper\n      op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 735, in _create_op_internal\n      return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3800, in _create_op_internal\n      ret = Operation(\n\nThe tensor <tf.Tensor 'vbn_2/new_mean:0' shape=(1, 1, 1, 256) dtype=float32> cannot be accessed from here, because it was defined in FuncGraph(name=vbn_2_scratch_graph, id=2251464527152), which is out of scope.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_real_samples()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m plot_metrics(metrics, epochs)\n",
      "Cell \u001b[1;32mIn[4], line 306\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch)\u001b[0m\n\u001b[0;32m    304\u001b[0m [X_real, labels_real], y_real \u001b[38;5;241m=\u001b[39m generate_real_samples(dataset, half_batch)\n\u001b[0;32m    305\u001b[0m d_loss1, _ \u001b[38;5;241m=\u001b[39m d_model\u001b[38;5;241m.\u001b[39mtrain_on_batch([X_real, labels_real], y_real)\n\u001b[1;32m--> 306\u001b[0m [X_fake, labels_fake], y_fake \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_fake_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhalf_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m d_loss2, _ \u001b[38;5;241m=\u001b[39m d_model\u001b[38;5;241m.\u001b[39mtrain_on_batch([X_fake, labels_fake], y_fake)\n\u001b[0;32m    308\u001b[0m [z_input, labels_input] \u001b[38;5;241m=\u001b[39m generate_latent_points(latent_dim, n_batch)\n",
      "Cell \u001b[1;32mIn[4], line 201\u001b[0m, in \u001b[0;36mgenerate_fake_samples\u001b[1;34m(g_model, latent_dim, n_samples, n_classes)\u001b[0m\n\u001b[0;32m    199\u001b[0m z_input \u001b[38;5;241m=\u001b[39m x_input\u001b[38;5;241m.\u001b[39mreshape(n_samples, latent_dim)\n\u001b[0;32m    200\u001b[0m labels \u001b[38;5;241m=\u001b[39m randint(\u001b[38;5;241m0\u001b[39m, n_classes, n_samples)\n\u001b[1;32m--> 201\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mg_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mz_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n_samples, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [images, labels], y\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: <tf.Tensor 'vbn_2/new_mean:0' shape=(1, 1, 1, 256) dtype=float32> is out of scope and cannot be used here. Use return values, explicit Python locals or TensorFlow collections to access it.\nPlease see https://www.tensorflow.org/guide/function#all_outputs_of_a_tffunction_must_be_return_values for more information.\n\n<tf.Tensor 'vbn_2/new_mean:0' shape=(1, 1, 1, 256) dtype=float32> was defined here:\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3046, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3101, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3306, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3488, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3548, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_3048\\3160050400.py\", line 8, in <module>\n      g_model = define_generator(latent_dim)\n    File \"C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_3048\\1671772212.py\", line 151, in define_generator\n      gen = VBN()(gen)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1011, in __call__\n      return self._functional_construction_call(\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 2498, in _functional_construction_call\n      outputs = self._keras_tensor_symbolic_call(\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 2345, in _keras_tensor_symbolic_call\n      return self._infer_output_signature(\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 2404, in _infer_output_signature\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_3048\\2893464449.py\", line 59, in call\n      if self.ref_mean is None or self.ref_mean_sq is None:\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 1363, in if_stmt\n      _py_if_stmt(cond, body, orelse)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 1416, in _py_if_stmt\n      return body() if cond else orelse()\n    File \"C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_3048\\2893464449.py\", line 60, in call\n      self.ref_mean = tf.reduce_mean(x, [0,1,2], keepdims=True, name='new_mean')\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1176, in op_dispatch_handler\n      return dispatch_target(*args, **kwargs)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2640, in reduce_mean\n      gen_math_ops.mean(\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 6285, in mean\n      _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 797, in _apply_op_helper\n      op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 735, in _create_op_internal\n      return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3800, in _create_op_internal\n      ret = Operation(\n\nThe tensor <tf.Tensor 'vbn_2/new_mean:0' shape=(1, 1, 1, 256) dtype=float32> cannot be accessed from here, because it was defined in FuncGraph(name=vbn_2_scratch_graph, id=2251464527152), which is out of scope."
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 128\n",
    "# create the discriminator\n",
    "d_model = define_discriminator()\n",
    "d_model.compile(loss='binary_crossentropy', optimizer=SGD(learning_rate=0.0002, momentum=0.5), metrics=['accuracy'])\n",
    "\n",
    "# create the generator\n",
    "g_model = define_generator(latent_dim)\n",
    "g_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "# create the gan\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "gan_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "# train model\n",
    "metrics = train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=128)\n",
    "\n",
    "epochs = range(1, len(metrics['d_loss']) + 1)\n",
    "plot_metrics(metrics, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(generator_model, latent_dim, n_samples, labels):\n",
    "    # Generate points in latent space\n",
    "    latent_points, sample_labels = generate_latent_points(latent_dim, n_samples)\n",
    "    # Update latent points with provided labels\n",
    "    sample_labels[:] = labels\n",
    "    # Generate images\n",
    "    images = generator_model.predict([latent_points, sample_labels])\n",
    "    # Scale from [-1,1] to [0,1]\n",
    "    images = (images + 1) / 2.0\n",
    "    # Plot images\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(int(np.sqrt(n_samples)), int(np.sqrt(n_samples)), 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images[i])\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "generate_images(g_model, latent_dim, n_samples=25, labels = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
